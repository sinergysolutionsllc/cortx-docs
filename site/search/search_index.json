{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"CORTX_PLATFORM_FDD/","title":"CORTX Platform - Functional &amp; Technical Design Document","text":"<p>Version: 1.0.0 Date: 2025-09-30 Status: Living Document Organization: Sinergy Solutions LLC</p>"},{"location":"CORTX_PLATFORM_FDD/#1-executive-summary","title":"1. Executive Summary","text":""},{"location":"CORTX_PLATFORM_FDD/#11-platform-purpose","title":"1.1 Platform Purpose","text":"<p>CORTX (Compliance Operations &amp; Rule-based Transformation Execution) is an AI-powered orchestration and compliance automation platform designed for highly regulated industries. CORTX enables organizations to automate complex business processes while maintaining strict compliance with regulatory frameworks including FedRAMP, HIPAA, NIST 800-53, and SOC 2.</p>"},{"location":"CORTX_PLATFORM_FDD/#12-core-value-proposition","title":"1.2 Core Value Proposition","text":"<ul> <li>Compliance-First Architecture: Built-in audit trails, immutable logging, and regulatory control mapping</li> <li>AI Orchestration: Intelligent workflow execution with LLM-powered explanations and recommendations</li> <li>Hierarchical RAG: 4-level knowledge architecture (Platform \u2192 Suite \u2192 Module \u2192 Entity) with scoped retrieval and specificity boosts</li> <li>RulePack/WorkflowPack Model: Externalized, version-controlled compliance logic (JSON/YAML artifacts)</li> <li>Multi-Tenant SaaS: Schema-per-tenant isolation with dedicated and on-prem deployment options</li> <li>Marketplace Ecosystem: \"GitHub for Compliance Workflows\" with Pack sharing and certification</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#13-platform-architecture","title":"1.3 Platform Architecture","text":"<p>CORTX operates as a microservices platform with three architectural layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     CORTX ECOSYSTEM                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Design Layer                                                   \u2502\n\u2502  \u251c\u2500\u2500 BPM Designer (Visual workflow builder)                     \u2502\n\u2502  \u251c\u2500\u2500 AI Assistant (Natural language \u2192 workflows)                \u2502\n\u2502  \u2514\u2500\u2500 Designer \u2194 Platform RAG (UI hooks into svc-rag)           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Execution Layer (Platform Services)                            \u2502\n\u2502  \u251c\u2500\u2500 Gateway (8080)         - API routing, rate limiting        \u2502\n\u2502  \u251c\u2500\u2500 Identity (8082)        - Auth &amp; authorization (JWT)        \u2502\n\u2502  \u251c\u2500\u2500 AI Broker (8085)       - LLM routing, RAG, inference       \u2502\n\u2502  \u251c\u2500\u2500 Schemas (8084)         - Schema registry &amp; validation      \u2502\n\u2502  \u251c\u2500\u2500 Validation (8083)      - RulePack execution engine         \u2502\n\u2502  \u251c\u2500\u2500 Compliance (8135)      - Audit logging, trails             \u2502\n\u2502  \u251c\u2500\u2500 Ledger (8136)         - Append-only, hash-chained events  \u2502\n\u2502  \u251c\u2500\u2500 OCR (8137)            - Doc \u2192 text/fields (Tesseract/DocAI)\u2502\n\u2502  \u251c\u2500\u2500 RAG (8138)            - Hierarchical retrieval + indexing  \u2502\n\u2502  \u2514\u2500\u2500 Workflow (8130)        - WorkflowPack orchestration        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Domain Layer (Vertical Suites)                                \u2502\n\u2502  \u251c\u2500\u2500 FedSuite (8081)        - Federal financial compliance      \u2502\n\u2502  \u251c\u2500\u2500 CorpSuite              - Real estate &amp; procurement         \u2502\n\u2502  \u251c\u2500\u2500 MedSuite               - Healthcare compliance             \u2502\n\u2502  \u2514\u2500\u2500 GovSuite               - Government operations             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Infrastructure Layer                                           \u2502\n\u2502  \u251c\u2500\u2500 GCP Cloud Run          - Serverless compute                \u2502\n\u2502  \u251c\u2500\u2500 PostgreSQL/Supabase    - Multi-tenant data                 \u2502\n\u2502  \u251c\u2500\u2500 Redis                  - Event bus, caching                \u2502\n\u2502  \u251c\u2500\u2500 Cloud Storage          - Artifact storage                  \u2502\n\u2502  \u2514\u2500\u2500 Terraform              - Infrastructure as Code            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#14-key-regulatory-frameworks","title":"1.4 Key Regulatory Frameworks","text":"Framework Status Scope FedRAMP Phase I (20x controls) Moderate ATO target Q4 2026 HIPAA Controls implemented 3rd party audit Q1 2026 NIST 800-53 175/325 controls mapped Rev 5 compliance SOC 2 Type II In progress Audit scheduled Q2 2026 FISMA Moderate ready Continuous monitoring active OMB A-136 FedSuite compliant Treasury financial reporting"},{"location":"CORTX_PLATFORM_FDD/#2-functional-requirements","title":"2. Functional Requirements","text":""},{"location":"CORTX_PLATFORM_FDD/#21-platform-capabilities","title":"2.1 Platform Capabilities","text":""},{"location":"CORTX_PLATFORM_FDD/#211-rulepack-execution","title":"2.1.1 RulePack Execution","text":"<ul> <li>Purpose: Execute externalized validation rules and compliance policies</li> <li>Format: JSON-based rule definitions with versioning</li> <li>Features:</li> <li>Safe operators (no eval/exec): <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>in</code>, <code>matches</code>, etc.</li> <li>Severity levels: FATAL (blocking), WARNING (review required), INFO (logged)</li> <li>Field-level validation with contextual error messages</li> <li>Batch processing support (1M+ records)</li> <li>Rule composition and chaining</li> </ul> <p>Example RulePack Structure:</p> <pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"federal-gtas-v1\",\n    \"version\": \"1.0.0\",\n    \"compliance\": [\"OMB-A-136\", \"GTAS-2024\"]\n  },\n  \"rules\": [\n    {\n      \"rule_id\": \"GTAS-001\",\n      \"type\": \"FATAL\",\n      \"field\": \"TAS\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[0-9]{3}-[0-9]{4}$\",\n      \"error_message\": \"Invalid TAS format. Expected: ###-####\"\n    }\n  ]\n}\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#212-workflowpack-orchestration","title":"2.1.2 WorkflowPack Orchestration","text":"<ul> <li>Purpose: Define and execute multi-step business processes</li> <li>Format: YAML-based workflow definitions</li> <li>Features:</li> <li>Node types: Data source, validation, AI inference, decision, approval, data sink</li> <li>Human-in-the-loop approval gates</li> <li>Saga pattern for distributed transactions</li> <li>Automatic compensation on failures</li> <li>Parallel execution support</li> </ul> <p>Example WorkflowPack Structure:</p> <pre><code>workflow_id: gtas-monthly-submission\nversion: 1.0.0\nsteps:\n  - id: ingest\n    type: data-source\n    config:\n      format: csv\n      schema: trial-balance-v1\n\n  - id: validate\n    type: validation\n    config:\n      rulepack: federal-gtas-v1\n      on_failure: halt\n\n  - id: reconcile\n    type: calculation\n    config:\n      formula: sum(debits) - sum(credits)\n\n  - id: approve\n    type: approval\n    config:\n      role: certifying_official\n      timeout_hours: 48\n\n  - id: submit\n    type: data-sink\n    config:\n      endpoint: https://gtas.treasury.gov/api/submit\n      method: POST\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#213-ai-orchestration","title":"2.1.3 AI Orchestration","text":"<ul> <li>Purpose: Provide intelligent assistance and automation</li> <li>Capabilities:</li> <li>Model Router: Select optimal model (cost, speed, compliance)</li> <li>RAG (Retrieval-Augmented Generation): Vector store with compliance knowledge</li> <li>PII Redaction: Automatic sensitive data scrubbing before LLM calls</li> <li>Explainability: Generate plain-language explanations for rule failures</li> <li>Smart Recommendations: Suggest corrections for compliance violations</li> </ul> <p>Supported AI Models: - Production: Google Gemini 1.5 Pro/Flash (via Vertex AI) - Roadmap: Claude 3.5 Sonnet, GPT-4 Turbo, AWS Bedrock, Hugging Face local models</p>"},{"location":"CORTX_PLATFORM_FDD/#214-multi-tenant-architecture","title":"2.1.4 Multi-Tenant Architecture","text":"<ul> <li>Tenant Isolation:</li> <li>PostgreSQL: Schema-per-tenant with Row-Level Security (RLS)</li> <li>Kubernetes: Namespace-per-tenant (enterprise tier)</li> <li>Redis: Key prefixing by tenant ID</li> <li>Storage: GCS buckets with tenant-scoped access</li> <li>Deployment Modes:</li> <li>SaaS Multi-Tenant: Shared platform, schema isolation ($10k/mo base)</li> <li>SaaS Dedicated: Dedicated cluster per tenant ($50k/mo+)</li> <li>On-Prem/Private: Customer infrastructure ($200k/yr license)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#215-rag-retrieval-augmented-generation","title":"2.1.5 RAG (Retrieval-Augmented Generation)","text":"<ul> <li>Purpose: Provide contextual, compliance-aware knowledge retrieval for AI and UI workflows</li> <li>Architecture: 4-level hierarchy (Platform \u2192 Suite \u2192 Module \u2192 Entity) with scope-based retrieval</li> <li>Features:</li> <li>Scoped search: Retrieve knowledge at desired specificity (e.g., suite, module, entity)</li> <li>Boosting: Relevance scoring based on context, recency, and compliance tags</li> <li>Real-time ingestion: New docs, policies, and evidence can be indexed on demand</li> <li>Admin UI: Upload, manage, and visualize knowledge graph</li> <li>Integration: RAG available via API and UI hooks (Designer, AI Assistant)</li> <li>Sample Use Cases:</li> <li>Explain compliance rules with traceable source references</li> <li>Retrieve agency-specific guidance for workflow steps</li> <li>Power AI Assistant with up-to-date, certified knowledge</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#216-ocr-optical-character-recognition","title":"2.1.6 OCR (Optical Character Recognition)","text":"<ul> <li>Purpose: Extract structured data and text from scanned documents and images</li> <li>Features:</li> <li>Multi-engine support: Tesseract (open source), Google DocAI (cloud)</li> <li>Field extraction: Map document zones to schema fields (template-based)</li> <li>Batch processing: Handle large volumes (1000+ docs per batch)</li> <li>Confidence scoring: Per-field and per-page extraction quality</li> <li>Redaction: Mask PII/PHI on output if enabled</li> <li>Supported Formats: PDF, TIFF, PNG, JPEG</li> <li>Sample Use Cases:</li> <li>Ingest scanned financial reports for validation</li> <li>Extract fields from government forms (e.g., SF-133)</li> <li>Pre-process documents for RAG indexing</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#217-ledger-immutable-audit-ledger","title":"2.1.7 Ledger (Immutable Audit Ledger)","text":"<ul> <li>Purpose: Provide tamper-evident, append-only event logging for compliance and audit</li> <li>Features:</li> <li>SHA-256 hash-chain: Each event links to previous for immutability</li> <li>Append-only API: No updates or deletes permitted</li> <li>Periodic verification: Automated detection of drift or tampering</li> <li>Integration: Compliance service logs to ledger for all critical events</li> <li>Export: Downloadable for 3rd party audits</li> <li>Sample Use Cases:</li> <li>Store evidence of workflow execution and approvals</li> <li>Provide audit trail for regulatory certification</li> <li>Detect unauthorized event modification attempts</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#22-user-roles-rbac","title":"2.2 User Roles &amp; RBAC","text":"Role Permissions UI Access PLATFORM_VIEWER Read-only platform status Dashboards, logs PACK_AUTHOR Create/edit RulePacks &amp; WorkflowPacks Designer, testing PACK_REVIEWER Approve packs for deployment Review queue, annotations COMPLIANCE_OFFICER Certify compliance, audit access Audit logs, reports SUITE_OPERATOR Execute workflows, upload data Suite dashboards, data entry SUITE_ADMIN Manage suite configuration Suite settings, integrations PLATFORM_ADMIN Full platform administration All features, tenant management"},{"location":"CORTX_PLATFORM_FDD/#23-audit-compliance-logging","title":"2.3 Audit &amp; Compliance Logging","text":"<p>Required Events (NIST 800-53 AU-2, AU-3): - User authentication (login, logout, failures) - Pack creation, modification, deployment - Workflow execution (start, steps, end, errors) - Data access (read, write, delete) - Permission changes (role grants, revocations) - AI inference calls (model, prompt hash, response) - Configuration changes (platform, tenant, suite)</p> <p>Log Format (JSON):</p> <pre><code>{\n  \"timestamp\": \"2025-09-30T14:23:45Z\",\n  \"event_type\": \"workflow_executed\",\n  \"tenant_id\": \"agency-dod-001\",\n  \"user_id\": \"jane.doe@dod.gov\",\n  \"session_id\": \"sess_abc123\",\n  \"correlation_id\": \"wf_xyz789\",\n  \"details\": {\n    \"workflow_id\": \"gtas-monthly-submission\",\n    \"status\": \"completed\",\n    \"duration_ms\": 3542\n  },\n  \"compliance_tags\": [\"FISMA\", \"GTAS\", \"OMB-A-136\"]\n}\n</code></pre> <p>Retention: - Audit logs: 7 years (regulatory requirement) - Workflow execution logs: 3 years - Access logs: 1 year - Performance logs: 90 days</p>"},{"location":"CORTX_PLATFORM_FDD/#3-technical-architecture","title":"3. Technical Architecture","text":""},{"location":"CORTX_PLATFORM_FDD/#31-platform-services","title":"3.1 Platform Services","text":""},{"location":"CORTX_PLATFORM_FDD/#311-gateway-service-port-8080","title":"3.1.1 Gateway Service (Port 8080)","text":"<p>Technology: FastAPI (Python 3.11), Uvicorn, Redis Purpose: API routing, rate limiting, request/response transformation</p> <p>Capabilities: - Reverse proxy to all platform services - Rate limiting (100 req/sec per tenant, burst 200) - Request authentication (JWT validation) - CORS handling - Request/response logging - Circuit breaker for downstream services</p> <p>Endpoints:</p> <pre><code>GET  /health                    # Health check\nPOST /api/v1/rulepacks/execute  # Execute RulePack\nPOST /api/v1/workflows/execute  # Execute WorkflowPack\nGET  /api/v1/services           # Service discovery\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#312-identity-service-port-8082","title":"3.1.2 Identity Service (Port 8082)","text":"<p>Technology: FastAPI, PostgreSQL, JWT, Supabase Auth Purpose: Authentication, authorization, tenant management</p> <p>Features: - OAuth 2.0 / OpenID Connect support - Multi-factor authentication (MFA) - JWT token issuance (15min access, 7day refresh) - Role-Based Access Control (RBAC) - Tenant onboarding automation</p> <p>Claims in JWT:</p> <pre><code>{\n  \"sub\": \"user_123\",\n  \"tenant_id\": \"agency-dod-001\",\n  \"roles\": [\"SUITE_OPERATOR\", \"PACK_AUTHOR\"],\n  \"permissions\": [\"execute:workflows\", \"create:packs\"],\n  \"exp\": 1696089825\n}\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#313-ai-broker-service-port-8085","title":"3.1.3 AI Broker Service (Port 8085)","text":"<p>Technology: FastAPI, LangChain, Google Vertex AI, Redis (cache) Purpose: AI model orchestration, RAG, PII protection</p> <p>Components: - Model Router: Select model based on cost, latency, compliance requirements - Prompt Manager: Template management with variable injection - RAG Engine: Vector search (384-dim embeddings, cosine similarity) - PII Redactor: Regex + NER-based sensitive data removal</p> <p>RAG Vector Store: - 15+ embedded documents (Treasury rules, HIPAA guidelines, etc.) - Semantic search with keyword boosting - Top-k retrieval (default k=5, threshold=0.5) - Real-time knowledge base updates</p> <p>API Endpoints:</p> <pre><code>POST /api/ai/inference          # Generate AI response\nPOST /api/ai/explain            # Explain rule failure\nPOST /api/ai/generate-workflow  # NL \u2192 WorkflowPack\nGET  /api/ai/models             # Available models\nPOST /api/ai/rag/search         # Search knowledge base\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#314-validation-service-port-8083","title":"3.1.4 Validation Service (Port 8083)","text":"<p>Technology: FastAPI, Pydantic, Safe eval engine Purpose: RulePack execution, data validation</p> <p>Safe Operators (no code injection): - Comparison: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code> - Membership: <code>in</code>, <code>not_in</code> - String: <code>contains</code>, <code>starts_with</code>, <code>ends_with</code>, <code>matches</code> (regex) - Null checks: <code>is_null</code>, <code>is_not_null</code></p> <p>Validation Flow: 1. Load RulePack from registry 2. Parse input data (JSON, CSV, XML) 3. Apply rules sequentially 4. Collect violations (FATAL, WARNING, INFO) 5. Return results with contextual errors</p>"},{"location":"CORTX_PLATFORM_FDD/#315-workflow-service-port-8130","title":"3.1.5 Workflow Service (Port 8130)","text":"<p>Technology: FastAPI, Temporal.io (planned), Redis (current) Purpose: WorkflowPack orchestration, saga pattern</p> <p>Features: - Sequential and parallel step execution - Conditional branching (decision nodes) - Human-in-the-loop approval gates - Automatic compensation on failure - Event-driven cross-suite workflows</p> <p>Saga Pattern (distributed transactions):</p> <pre><code>saga:\n  steps:\n    - id: step1\n      compensate: rollback_step1\n    - id: step2\n      compensate: rollback_step2\n\n  on_failure:\n    - execute: rollback_step2\n    - execute: rollback_step1\n    - notify: failure_alert\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#316-compliance-service-port-8135","title":"3.1.6 Compliance Service (Port 8135)","text":"<p>Technology: FastAPI, PostgreSQL (time-series), Cloud Logging Purpose: Audit logging, compliance reporting</p> <p>Capabilities: - Immutable audit trail (append-only) - Compliance report generation (FISMA, FedRAMP, HIPAA) - NIST 800-53 control evidence collection - Automated compliance attestation - Retention policy enforcement</p>"},{"location":"CORTX_PLATFORM_FDD/#317-schema-service-port-8084","title":"3.1.7 Schema Service (Port 8084)","text":"<p>Technology: FastAPI, JSON Schema, YAML validation Purpose: Schema registry, RulePack/WorkflowPack validation</p> <p>Schemas: - RulePack schema (JSON Schema draft-07) - WorkflowPack schema (YAML with JSON Schema validation) - Data schema registry (for input/output validation) - Version management (semantic versioning)</p>"},{"location":"CORTX_PLATFORM_FDD/#318-rag-service-port-8138","title":"3.1.8 RAG Service (Port 8138)","text":"<p>Technology: FastAPI, Qdrant/Weaviate, LangChain, PostgreSQL Purpose: Hierarchical knowledge retrieval, indexing, and management</p> <p>Features: - 4-level scope: platform, suite, module, entity - Embedding: 384-dim, OpenAI or Vertex AI - Metadata: Compliance tags, source, recency, access control - Scoped search: <code>scope=platform|suite|module|entity</code> - Admin UI: Upload, browse, tag, delete knowledge - Real-time updates: Sync with RulePack/WorkflowPack/Docs</p> <p>API Endpoints:</p> <pre><code>POST /api/rag/query\n{\n  \"query\": \"What is GTAS reporting?\",\n  \"scope\": \"suite\",\n  \"suite_id\": \"fedsuite\",\n  \"top_k\": 5\n}\n\nPOST /api/rag/index\n{\n  \"doc_id\": \"fed-guide-2025\",\n  \"content\": \"...\",\n  \"scope\": \"suite\",\n  \"suite_id\": \"fedsuite\",\n  \"tags\": [\"FedRAMP\", \"GTAS\"]\n}\n\nGET /api/rag/docs?suite_id=fedsuite&amp;scope=suite\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#319-ocr-service-port-8137","title":"3.1.9 OCR Service (Port 8137)","text":"<p>Technology: FastAPI, Tesseract, Google DocAI, Celery Purpose: Document OCR and field extraction</p> <p>Features: - Multi-engine: <code>engine=tesseract|docai</code> - Template-based field mapping (JSON) - Batch and async processing - Output: JSON (text, fields, confidence) - Redaction: Optional PII masking</p> <p>API Endpoints:</p> <pre><code>POST /api/ocr/extract\n{\n  \"engine\": \"docai\",\n  \"files\": [ ... ],\n  \"template_id\": \"sf133-v1\"\n}\n\nGET /api/ocr/results/{job_id}\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#3110-ledger-service-port-8136","title":"3.1.10 Ledger Service (Port 8136)","text":"<p>Technology: FastAPI, PostgreSQL (append-only), SHA-256, Celery Purpose: Tamper-evident, immutable event ledger for compliance</p> <p>Features: - Append-only API (no updates/deletes) - SHA-256 hash-chain per event - Verification endpoint (drift detection) - Export for audit - Integrated with Compliance service</p> <p>API Endpoints:</p> <pre><code>POST /api/ledger/append\n{\n  \"event_type\": \"workflow_executed\",\n  \"payload\": { ... }\n}\n\nGET /api/ledger/verify\nGET /api/ledger/events?since=2025-09-01\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#32-data-flow","title":"3.2 Data Flow","text":"<p>Typical Execution Flow:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Gateway\n    participant Identity\n    participant Workflow\n    participant Validation\n    participant AIBroker\n    participant Compliance\n\n    User-&gt;&gt;Gateway: POST /api/v1/workflows/execute\n    Gateway-&gt;&gt;Identity: Validate JWT\n    Identity--&gt;&gt;Gateway: User context + tenant_id\n    Gateway-&gt;&gt;Workflow: Execute WorkflowPack\n    Workflow-&gt;&gt;Validation: Execute RulePack (step 1)\n    Validation--&gt;&gt;Workflow: Validation results\n    Workflow-&gt;&gt;AIBroker: Get AI recommendation (step 2)\n    AIBroker--&gt;&gt;Workflow: AI response\n    Workflow-&gt;&gt;Compliance: Log execution\n    Workflow--&gt;&gt;Gateway: Workflow results\n    Gateway--&gt;&gt;User: Response with audit trail\n</code></pre> <p>OCR \u2192 RAG \u2192 AI Sequence:</p> <pre><code>sequenceDiagram\n    participant User\n    participant OCR\n    participant RAG\n    participant AI\n    participant Workflow\n\n    User-&gt;&gt;OCR: Upload scanned document\n    OCR-&gt;&gt;OCR: Extract text + fields (Tesseract/DocAI)\n    OCR--&gt;&gt;User: Structured data + confidence\n    OCR-&gt;&gt;RAG: Index extracted content (optional)\n    User-&gt;&gt;RAG: Query knowledge (with context)\n    RAG--&gt;&gt;User: Relevant docs/snippets\n    User-&gt;&gt;AI: Generate explanation/recommendation (with RAG context)\n    AI--&gt;&gt;User: AI response (with source citations)\n    User-&gt;&gt;Workflow: Use OCR/RAG/AI output in process\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#33-security-architecture","title":"3.3 Security Architecture","text":""},{"location":"CORTX_PLATFORM_FDD/#331-network-security","title":"3.3.1 Network Security","text":"<ul> <li>TLS 1.3: All service-to-service communication</li> <li>mTLS: Optional for high-security tenants</li> <li>VPC: Private network for service mesh</li> <li>WAF: Cloud Armor for DDoS protection</li> <li>API Gateway: Rate limiting, IP allowlisting</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#332-data-security","title":"3.3.2 Data Security","text":"<ul> <li>Encryption at Rest: AES-256 for databases, Cloud KMS for keys</li> <li>Encryption in Transit: TLS 1.3 with perfect forward secrecy</li> <li>PII Protection: Automatic redaction before LLM calls</li> <li>Data Minimization: Collect only required fields</li> <li>Right to Deletion: GDPR-compliant data purge</li> <li>Tamper Evidence: Ledger service computes SHA-256 hash-chain for compliance events; periodic verification jobs detect drift</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#333-access-control","title":"3.3.3 Access Control","text":"<ul> <li>RBAC: Role-based with least privilege</li> <li>Attribute-Based: Context-aware policies (time, location, risk)</li> <li>MFA: Required for admin roles</li> <li>Session Management: 15min idle timeout, concurrent session limits</li> <li>Audit: All permission changes logged</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#334-compliance-controls-nist-800-53","title":"3.3.4 Compliance Controls (NIST 800-53)","text":"Control Family Implemented Controls Status AC (Access Control) AC-2, AC-3, AC-7 \u2705 Complete AU (Audit) AU-2, AU-3, AU-12 \u2705 Complete IA (Identification &amp; Auth) IA-2, IA-4, IA-5 \u2705 Complete SC (System &amp; Comm) SC-7, SC-8, SC-13 \u2705 Complete SI (System Integrity) SI-3, SI-4, SI-7 \ud83d\udea7 In Progress CA (Assessment) CA-8 (pen testing) \ud83d\udccb Planned Q1 2026"},{"location":"CORTX_PLATFORM_FDD/#34-deployment-architecture","title":"3.4 Deployment Architecture","text":""},{"location":"CORTX_PLATFORM_FDD/#341-gcp-cloud-run-primary","title":"3.4.1 GCP Cloud Run (Primary)","text":"<pre><code>services:\n  gateway:\n    image: gcr.io/cortx-platform/gateway:latest\n    resources:\n      cpu: 2\n      memory: 4Gi\n    scaling:\n      min_instances: 2\n      max_instances: 100\n      target_cpu: 70%\n\n  ai-broker:\n    image: gcr.io/cortx-platform/ai-broker:latest\n    resources:\n      cpu: 4\n      memory: 8Gi\n    env:\n      - GOOGLE_API_KEY: secret:gemini-api-key\n\n  rag:\n    image: gcr.io/cortx-platform/rag:latest\n    resources:\n      cpu: 2\n      memory: 4Gi\n    env:\n      - QDRANT_URL: http://qdrant:6333\n      - EMBEDDING_MODEL: vertexai\n\n  ocr:\n    image: gcr.io/cortx-platform/ocr:latest\n    resources:\n      cpu: 2\n      memory: 4Gi\n    env:\n      - DOC_AI_KEY: secret:docai-key\n      - OCR_ENGINE: tesseract\n\n  ledger:\n    image: gcr.io/cortx-platform/ledger:latest\n    resources:\n      cpu: 1\n      memory: 2Gi\n    env:\n      - LEDGER_DB_URL: secret:ledger-db-url\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#342-kubernetes-enterpriseon-prem","title":"3.4.2 Kubernetes (Enterprise/On-Prem)","text":"<pre><code>namespaces:\n  - cortx-platform      # Core services\n  - tenant-dod-001      # Dedicated tenant namespace\n  - tenant-hhs-002\n\ningress:\n  nginx:\n    tls: true\n    rate_limit: 1000/min\n\nstorage:\n  class: ssd-persistent\n  backup: daily\n  retention: 30d\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#343-multi-region-planned-phase-2","title":"3.4.3 Multi-Region (Planned Phase 2)","text":"<ul> <li>Primary: us-central1 (Iowa)</li> <li>DR: us-east1 (South Carolina)</li> <li>Replication: Cross-region PostgreSQL, GCS</li> <li>Failover: Automated DNS switching, &lt;5 min RTO</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#4-pack-schemas-governance","title":"4. Pack Schemas &amp; Governance","text":""},{"location":"CORTX_PLATFORM_FDD/#41-rulepack-json-schema","title":"4.1 RulePack JSON Schema","text":"<pre><code>{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"RulePack\",\n  \"type\": \"object\",\n  \"required\": [\"metadata\", \"rules\"],\n  \"properties\": {\n    \"metadata\": {\n      \"type\": \"object\",\n      \"required\": [\"pack_id\", \"version\"],\n      \"properties\": {\n        \"pack_id\": {\"type\": \"string\"},\n        \"version\": {\"type\": \"string\", \"pattern\": \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\"},\n        \"compliance\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"created_by\": {\"type\": \"string\"},\n        \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"}\n      }\n    },\n    \"rules\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"rule_id\", \"type\", \"field\", \"operator\"],\n        \"properties\": {\n          \"rule_id\": {\"type\": \"string\"},\n          \"type\": {\"enum\": [\"FATAL\", \"WARNING\", \"INFO\"]},\n          \"field\": {\"type\": \"string\"},\n          \"operator\": {\"enum\": [\"==\", \"!=\", \"&lt;\", \"&lt;=\", \"&gt;\", \"&gt;=\", \"in\", \"not_in\", \"contains\", \"matches\"]},\n          \"value\": {},\n          \"error_message\": {\"type\": \"string\"}\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#42-workflowpack-yaml-schema","title":"4.2 WorkflowPack YAML Schema","text":"<pre><code>$schema: http://json-schema.org/draft-07/schema#\ntitle: WorkflowPack\ntype: object\nrequired: [workflow_id, version, steps]\nproperties:\n  workflow_id:\n    type: string\n  version:\n    type: string\n    pattern: ^\\d+\\.\\d+\\.\\d+$\n  steps:\n    type: array\n    items:\n      type: object\n      required: [id, type]\n      properties:\n        id: {type: string}\n        type:\n          enum: [data-source, validation, calculation, decision, approval, ai-inference, data-sink]\n        config:\n          type: object\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#43-pack-governance","title":"4.3 Pack Governance","text":"<p>Approval Workflow: 1. Draft: Author creates pack in designer 2. Review: Business analyst reviews functional correctness 3. Compliance: Compliance officer certifies regulatory alignment 4. Testing: QA validates with test data 5. Approval: Admin approves for deployment 6. Deployment: Pack pushed to production registry</p> <p>Versioning: - Semantic versioning: MAJOR.MINOR.PATCH - Breaking changes: MAJOR increment, requires re-certification - Backward-compatible features: MINOR increment - Bug fixes: PATCH increment</p> <p>Marketplace Tiers: - Official: Treasury/IRS verified, free (government funded) - Certified: Community tested, 70/30 revenue split - Community: User contributed, as-is - Private: Agency-specific, enterprise licensing</p>"},{"location":"CORTX_PLATFORM_FDD/#5-integration-points","title":"5. Integration Points","text":""},{"location":"CORTX_PLATFORM_FDD/#51-suite-integration","title":"5.1 Suite Integration","text":"<p>API Contract:</p> <pre><code># Suite registration\nPOST /api/v1/suites/register\n{\n  \"suite_id\": \"fedsuite\",\n  \"base_url\": \"http://fedsuite:8081\",\n  \"capabilities\": [\"gtas\", \"cars\", \"sf133\"],\n  \"health_endpoint\": \"/health\"\n}\n\n# Suite execution\nPOST /api/v1/suites/{suite_id}/execute\n{\n  \"workflow_id\": \"gtas-monthly\",\n  \"input_data\": {...},\n  \"tenant_id\": \"agency-dod-001\"\n}\n</code></pre> <p>Event Bus (Redis Streams):</p> <pre><code># Publish event\nXADD cortx:events *\n  event_type \"workflow_completed\"\n  tenant_id \"agency-dod-001\"\n  workflow_id \"gtas-monthly\"\n  status \"success\"\n\n# Subscribe\nXREAD COUNT 10 STREAMS cortx:events 0\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#52-external-systems","title":"5.2 External Systems","text":"<p>Treasury Systems (FedSuite): - GTAS API: <code>https://gtas.treasury.gov/api/submit</code> - CARS API: <code>https://cars.treasury.gov/api/daily-position</code> - Authentication: Client certificate (mTLS)</p> <p>Healthcare Systems (MedSuite): - CMS FHIR API: <code>https://api.cms.gov/fhir/v1</code> - NPI Registry: <code>https://npiregistry.cms.hhs.gov/api</code> - Authentication: OAuth 2.0</p> <p>Real Estate Systems (CorpSuite): - Maryland SDAT: Licensed bulk files (SFTP) - MDLandRec: API integration (API key) - Compliance: AUP restrictions, human-in-loop required</p>"},{"location":"CORTX_PLATFORM_FDD/#53-ai-model-apis","title":"5.3 AI Model APIs","text":"<p>Current: - Google Vertex AI: Gemini 1.5 Pro/Flash - LangChain: Orchestration framework</p> <p>Planned: - Anthropic Claude API - OpenAI GPT-4 API - AWS Bedrock - Hugging Face Inference API (on-prem)</p>"},{"location":"CORTX_PLATFORM_FDD/#6-testing-strategy","title":"6. Testing Strategy","text":""},{"location":"CORTX_PLATFORM_FDD/#61-platform-service-tests","title":"6.1 Platform Service Tests","text":"<p>Unit Tests (pytest, &gt;85% coverage): - Service logic (validation, workflow, AI broker) - Data models (Pydantic schemas) - Utility functions</p> <p>Integration Tests: - Service-to-service communication - Database interactions (PostgreSQL, Redis) - External API mocking (Treasury, CMS)</p> <p>Contract Tests (Pact): - API contracts between services - Suite integration contracts</p>"},{"location":"CORTX_PLATFORM_FDD/#62-pack-execution-tests","title":"6.2 Pack Execution Tests","text":"<p>RulePack Tests: - Rule accuracy (known input \u2192 expected output) - Edge cases (null values, malformed data) - Performance (1M records in &lt;30 seconds)</p> <p>WorkflowPack Tests: - End-to-end workflow execution - Failure scenarios (compensation testing) - Human-in-loop approval gates</p>"},{"location":"CORTX_PLATFORM_FDD/#63-aiml-tests","title":"6.3 AI/ML Tests","text":"<p>Reproducibility (&gt;95% threshold): - Same prompt \u2192 same response (temperature=0) - Model version pinning - Regression test suite</p> <p>RAG Tests: - Knowledge retrieval accuracy - Context relevance scoring - Embedding drift detection</p>"},{"location":"CORTX_PLATFORM_FDD/#64-security-tests","title":"6.4 Security Tests","text":"<p>OWASP Top 10: - Injection attacks (SQL, NoSQL, command) - Broken authentication - Sensitive data exposure - XML external entities (XXE) - Broken access control</p> <p>Penetration Testing: - Annual 3rd party assessment - Vulnerability scanning (weekly) - Dependency scanning (CI/CD)</p>"},{"location":"CORTX_PLATFORM_FDD/#65-compliance-tests","title":"6.5 Compliance Tests","text":"<p>FedRAMP/NIST 800-53: - Control implementation validation - Evidence collection automation - Continuous monitoring tests</p> <p>HIPAA: - PHI access logging - Encryption verification - Breach notification procedures</p>"},{"location":"CORTX_PLATFORM_FDD/#7-deployment-operations","title":"7. Deployment &amp; Operations","text":""},{"location":"CORTX_PLATFORM_FDD/#70-environment-strategy","title":"7.0 Environment Strategy","text":"Env Purpose Data Isolation Compliance Level Notes dev Developer testing Shared Low Rapid iteration, resettable staging Pre-prod validation Per-tenant Moderate Near-prod config, test data prod Production Per-tenant High Full compliance, audit logs sandbox Customer demos/trials Per-tenant Moderate Isolated, short-lived"},{"location":"CORTX_PLATFORM_FDD/#71-cicd-pipeline","title":"7.1 CI/CD Pipeline","text":"<pre><code>stages:\n  - name: lint\n    tools: [ruff, mypy, eslint]\n\n  - name: test\n    parallel:\n      - unit_tests: pytest --cov=80\n      - integration_tests: pytest tests/integration\n      - security_scan: trivy, snyk\n\n  - name: build\n    artifacts:\n      - docker_images: gcr.io/cortx-platform/*\n      - helm_charts: charts/*\n\n  - name: deploy\n    environments: [dev, staging, prod]\n    approval_required: [staging, prod]\n</code></pre>"},{"location":"CORTX_PLATFORM_FDD/#72-observability","title":"7.2 Observability","text":"<p>Metrics (Prometheus): - Request rate, latency (p50, p95, p99) - Error rate (4xx, 5xx) - Pack execution duration - AI inference latency - Database connection pool</p> <p>Dashboards (Grafana): - Platform health overview - Per-tenant usage metrics - Compliance audit metrics - Cost attribution (GCP billing)</p> <p>Alerts (Cloud Monitoring): - Error rate &gt;1% (5min window) - Latency p99 &gt;1000ms - Database connections &gt;80% - Failed compliance checks</p>"},{"location":"CORTX_PLATFORM_FDD/#73-incident-response","title":"7.3 Incident Response","text":"<p>Runbook: 1. Detection: Automated alerts via PagerDuty 2. Triage: On-call engineer assesses severity 3. Mitigation: Rollback, scale, failover 4. Resolution: Root cause analysis 5. Post-Mortem: Document lessons learned</p> <p>SLA Targets: - P0 (Platform down): 15min response, 1hr resolution - P1 (Suite degraded): 1hr response, 4hr resolution - P2 (Feature issue): 4hr response, 24hr resolution</p>"},{"location":"CORTX_PLATFORM_FDD/#8-quality-success-metrics","title":"8. Quality &amp; Success Metrics","text":""},{"location":"CORTX_PLATFORM_FDD/#81-technical-metrics","title":"8.1 Technical Metrics","text":"Metric Target Current Status Test coverage \u226585% 78% \ud83d\udea7 In progress API latency (p99) &lt;500ms 342ms \u2705 Met Platform uptime 99.9% 99.87% \ud83d\udea7 Close AI accuracy \u226595% 96.3% \u2705 Met Pack execution &lt;30s/1M records 18s \u2705 Met"},{"location":"CORTX_PLATFORM_FDD/#82-compliance-metrics","title":"8.2 Compliance Metrics","text":"Framework Controls Mapped Evidence Collected Status FedRAMP 175/325 (54%) 120/175 (69%) \ud83d\udea7 Phase I HIPAA 48/48 (100%) 45/48 (94%) \u2705 Ready for audit NIST 800-53 175/325 (54%) 120/175 (69%) \ud83d\udea7 In progress SOC 2 64/64 (100%) 58/64 (91%) \ud83d\udea7 Audit Q2 2026"},{"location":"CORTX_PLATFORM_FDD/#83-business-metrics","title":"8.3 Business Metrics","text":"<ul> <li>Platform adoption: 12 tenants (target: 50 by EOY 2026)</li> <li>Pack marketplace: 23 certified packs (target: 100)</li> <li>Time savings: 75% reduction in manual reconciliation (FedSuite)</li> <li>Error reduction: 90% fewer compliance violations (MedSuite)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#9-roadmap","title":"9. Roadmap","text":""},{"location":"CORTX_PLATFORM_FDD/#phase-1-complete","title":"Phase 1 (Complete) \u2705","text":"<ul> <li>Core platform services (7 microservices)</li> <li>RulePack/WorkflowPack execution</li> <li>Multi-tenant SaaS deployment</li> <li>FedSuite production (GTAS reconciliation)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#phase-2-q1-q2-2026","title":"Phase 2 (Q1-Q2 2026) \ud83d\udea7","text":"<ul> <li>AI model expansion (Claude, GPT-4, Bedrock)</li> <li>BPM Designer RAG enhancements</li> <li>HIPAA 3rd party audit completion</li> <li>CorpSuite production (PropVerify)</li> <li>OCR Service GA (8137)</li> <li>Ledger Service GA (8136)</li> <li>RAG Service GA (8138)</li> <li>RAG Admin UI (knowledge management)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#phase-3-q3-q4-2026","title":"Phase 3 (Q3-Q4 2026) \ud83d\udccb","text":"<ul> <li>Pack Marketplace launch</li> <li>Multi-region deployment (DR)</li> <li>FedRAMP ATO achievement</li> <li>Cross-suite saga orchestration (Kafka migration)</li> <li>Multi-level RAG quality evaluations (retrieval accuracy, explainability, compliance trace)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#phase-4-2027","title":"Phase 4 (2027+) \ud83d\udd2e","text":"<ul> <li>International expansion (UK, Canada, Australia)</li> <li>On-prem appliance offering</li> <li>Advanced AI (fine-tuned compliance models)</li> <li>Blockchain-based audit trails (immutable ledger)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#10-appendices","title":"10. Appendices","text":""},{"location":"CORTX_PLATFORM_FDD/#a-glossary","title":"A. Glossary","text":"<ul> <li>CORTX: Compliance Operations &amp; Rule-based Transformation Execution</li> <li>RulePack: JSON-based validation rules and compliance policies</li> <li>WorkflowPack: YAML-based process orchestration definitions</li> <li>RAG: Retrieval-Augmented Generation (AI + knowledge base)</li> <li>Saga: Distributed transaction pattern with compensation</li> <li>Pack: Generic term for RulePack or WorkflowPack</li> <li>Suite: Domain-specific vertical application (FedSuite, MedSuite, etc.)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#b-references","title":"B. References","text":"<ul> <li>NIST 800-53 Rev 5</li> <li>FedRAMP Authorization Guide</li> <li>HIPAA Security Rule</li> <li>OMB Circular A-136</li> <li>GTAS Reporting Guide</li> <li>CORTX Hierarchical RAG Architecture (internal)</li> <li>CORTX Refactoring Analysis (internal)</li> </ul>"},{"location":"CORTX_PLATFORM_FDD/#c-contact-information","title":"C. Contact Information","text":"<ul> <li>Platform Owner: Sinergy Solutions LLC</li> <li>Technical Lead: [Contact via GitHub]</li> <li>Security Officer: [Contact for compliance inquiries]</li> <li>Support: support@sinergysolutions.ai</li> </ul> <p>Document Control</p> <ul> <li>Version: 1.0.0</li> <li>Last Updated: 2025-09-30</li> <li>Review Cycle: Quarterly</li> <li>Classification: Internal Use / Proprietary</li> <li>Approvers: Platform Architecture Team</li> </ul> <p>This document is a living specification and will evolve with the CORTX platform. All changes are tracked in version control.</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/","title":"CORTX Hierarchical RAG Architecture","text":"<p>Date: 2025-10-01 Status: Strategic Design Team: Tech Architect Analysis</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#executive-summary","title":"Executive Summary","text":"<p>This document defines a 4-level hierarchical RAG (Retrieval-Augmented Generation) architecture for the CORTX Platform, enabling contextual AI assistance that understands knowledge at Platform, Suite, Module, and Entity levels.</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#key-design-principles","title":"Key Design Principles","text":"<ol> <li>Contextual Awareness: AI can access knowledge from all relevant levels</li> <li>Hierarchical Retrieval: Search starts narrow (Module) and expands outward (Suite \u2192 Platform)</li> <li>Scoped Permissions: Entity-level knowledge is tenant-isolated</li> <li>Unified Management: Single RAG Management UI for ingesting and organizing knowledge</li> <li>Platform Integration: Centralized svc-rag (8138) with ingestion from svc-ocr (8137) and provenance via svc-ledger (8136)</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#1-hierarchical-knowledge-architecture","title":"1. Hierarchical Knowledge Architecture","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#12-platform-integration-svc-rag-svc-ocr-svc-ledger","title":"1.2 Platform Integration (svc-rag, svc-ocr, svc-ledger)","text":"<ul> <li>svc-rag (8138): Central RAG APIs for ingest \u2192 chunk \u2192 embed \u2192 retrieve across four scopes (Platform, Suite, Module, Entity). Exposes Admin UI hooks used by Designer.</li> <li>svc-ocr (8137): Document \u2192 text/fields extraction; normalized <code>DocumentExtraction</code> JSON is ingested by svc-rag with appropriate scope metadata.</li> <li>svc-ledger (8136): Append-only, SHA-256 hash-chained evidence for all compliance-relevant RAG actions (ingest, delete, query served to end users), enabling end-to-end provenance.</li> </ul>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#11-four-level-knowledge-hierarchy","title":"1.1 Four-Level Knowledge Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LEVEL 1: PLATFORM                            \u2502\n\u2502  Universal knowledge applicable to ALL suites &amp; modules         \u2502\n\u2502  \u251c\u2500\u2500 NIST 800-53, FedRAMP, HIPAA, SOC 2 controls               \u2502\n\u2502  \u251c\u2500\u2500 CORTX Platform documentation                               \u2502\n\u2502  \u251c\u2500\u2500 General AI/ML best practices                               \u2502\n\u2502  \u251c\u2500\u2500 Security &amp; compliance frameworks                           \u2502\n\u2502  \u2514\u2500\u2500 Cross-industry standards                                   \u2502\n\u2502  Scope: Global | Permissions: Public                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LEVEL 2: SUITE                               \u2502\n\u2502  Domain-specific knowledge for a vertical                       \u2502\n\u2502                                                                 \u2502\n\u2502  FedSuite:                                                      \u2502\n\u2502  \u251c\u2500\u2500 OMB Circulars (A-11, A-123, A-136)                        \u2502\n\u2502  \u251c\u2500\u2500 Treasury GTAS Reporting Guide                             \u2502\n\u2502  \u251c\u2500\u2500 Federal accounting standards (USSGL, FASAB)               \u2502\n\u2502  \u2514\u2500\u2500 Agency-wide policies (DOD FMR, VA directives)             \u2502\n\u2502                                                                 \u2502\n\u2502  CorpSuite:                                                     \u2502\n\u2502  \u251c\u2500\u2500 Real estate law (Maryland, Virginia)                      \u2502\n\u2502  \u251c\u2500\u2500 Procurement regulations (FAR, state rules)                \u2502\n\u2502  \u2514\u2500\u2500 Corporate compliance (SOX, GAAP)                          \u2502\n\u2502                                                                 \u2502\n\u2502  MedSuite:                                                      \u2502\n\u2502  \u251c\u2500\u2500 HIPAA Privacy &amp; Security Rules                            \u2502\n\u2502  \u251c\u2500\u2500 CMS guidelines                                             \u2502\n\u2502  \u2514\u2500\u2500 Healthcare billing standards (ICD-10, CPT)                \u2502\n\u2502                                                                 \u2502\n\u2502  Scope: Suite-wide | Permissions: Suite users                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LEVEL 3: MODULE                              \u2502\n\u2502  Module-specific technical knowledge                            \u2502\n\u2502                                                                 \u2502\n\u2502  FedTransform:                                                  \u2502\n\u2502  \u251c\u2500\u2500 Oracle EBS table schemas (GL, AP, AR, FA)                 \u2502\n\u2502  \u251c\u2500\u2500 PeopleSoft FSCM structure                                 \u2502\n\u2502  \u251c\u2500\u2500 SAP ECC/S4 HANA data models                               \u2502\n\u2502  \u251c\u2500\u2500 Workday Financial mappings                                \u2502\n\u2502  \u2514\u2500\u2500 FBDI template specifications                              \u2502\n\u2502                                                                 \u2502\n\u2502  PropVerify:                                                    \u2502\n\u2502  \u251c\u2500\u2500 Maryland SDAT API documentation                           \u2502\n\u2502  \u251c\u2500\u2500 MDLandRec data dictionary                                 \u2502\n\u2502  \u251c\u2500\u2500 Title examination checklists                              \u2502\n\u2502  \u2514\u2500\u2500 Lien/encumbrance lookup procedures                        \u2502\n\u2502                                                                 \u2502\n\u2502  FedReconcile:                                                  \u2502\n\u2502  \u251c\u2500\u2500 GTAS submission schemas (ATB, BETC)                       \u2502\n\u2502  \u251c\u2500\u2500 Trial Balance validation rules (204+ rules)               \u2502\n\u2502  \u2514\u2500\u2500 Reconciliation workflows                                  \u2502\n\u2502                                                                 \u2502\n\u2502  Scope: Module-wide | Permissions: Module users                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LEVEL 4: ENTITY (Tenant)                     \u2502\n\u2502  Organization/tenant-specific knowledge                         \u2502\n\u2502                                                                 \u2502\n\u2502  Examples:                                                      \u2502\n\u2502  \u251c\u2500\u2500 Agency-specific accounting policies                        \u2502\n\u2502  \u251c\u2500\u2500 Department-specific approval workflows                     \u2502\n\u2502  \u251c\u2500\u2500 Custom chart of accounts mappings                         \u2502\n\u2502  \u251c\u2500\u2500 Organization-specific compliance interpretations          \u2502\n\u2502  \u2514\u2500\u2500 Internal standard operating procedures (SOPs)             \u2502\n\u2502                                                                 \u2502\n\u2502  Scope: Tenant-specific | Permissions: Tenant users only       \u2502\n\u2502  Security: RLS enforced, encrypted at rest                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#2-contextual-retrieval-strategy","title":"2. Contextual Retrieval Strategy","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#21-cascading-context-pattern","title":"2.1 Cascading Context Pattern","text":"<p>Scenario: User working in FedTransform asks: \"How do I map Oracle GL balances to GTAS?\"</p> <p>Retrieval flow:</p> <pre><code>1. MODULE (FedTransform):\n   \u251c\u2500\u2500 Search: Oracle EBS GL tables, FBDI mappings\n   \u2514\u2500\u2500 Retrieve: Top 5 chunks (score &gt; 0.7)\n\n2. SUITE (FedSuite):\n   \u251c\u2500\u2500 Search: GTAS reporting requirements, USSGL mapping rules\n   \u2514\u2500\u2500 Retrieve: Top 5 chunks (score &gt; 0.7)\n\n3. ENTITY (Tenant: DOD Finance):\n   \u251c\u2500\u2500 Search: DOD-specific GL to GTAS mappings, agency policies\n   \u2514\u2500\u2500 Retrieve: Top 3 chunks (score &gt; 0.8)\n\n4. PLATFORM (if needed):\n   \u251c\u2500\u2500 Search: Data transformation best practices\n   \u2514\u2500\u2500 Retrieve: Top 2 chunks (score &gt; 0.75)\n\n5. COMBINE CONTEXT:\n   \u251c\u2500\u2500 Module: 5 chunks (most specific)\n   \u251c\u2500\u2500 Suite: 5 chunks (domain rules)\n   \u251c\u2500\u2500 Entity: 3 chunks (org-specific)\n   \u251c\u2500\u2500 Platform: 2 chunks (general guidance)\n   \u2514\u2500\u2500 Total: 15 chunks passed to LLM\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#22-context-priority-scoring","title":"2.2 Context Priority Scoring","text":"<pre><code>def calculate_context_score(chunk, level, base_similarity_score):\n    \"\"\"\n    Boost scores based on hierarchical relevance\n    \"\"\"\n    level_boost = {\n        \"entity\": 0.15,    # Most specific to user's org\n        \"module\": 0.10,    # Most specific to current task\n        \"suite\": 0.05,     # Domain-relevant\n        \"platform\": 0.0    # Baseline\n    }\n\n    return base_similarity_score + level_boost[level]\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#23-smart-context-expansion","title":"2.3 Smart Context Expansion","text":"<p>When to expand to higher levels: 1. Insufficient results at lower level (&lt; 3 chunks above threshold) 2. Explicit cross-domain query (e.g., \"What are the compliance requirements?\") 3. User requests broader context (e.g., \"Include federal regulations\")</p> <p>When to restrict context: 1. Highly technical query (e.g., \"What's the Oracle GL_BALANCES table structure?\") 2. Entity-specific query (e.g., \"What's our approval workflow?\") 3. Performance optimization (fewer tokens = faster, cheaper)</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#3-vector-store-architecture","title":"3. Vector Store Architecture","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#31-database-schema-design","title":"3.1 Database Schema Design","text":"<p>PostgreSQL with pgvector extension:</p> <pre><code>-- Unified RAG schema using pgvector with level-based scoping\nCREATE SCHEMA IF NOT EXISTS rag;\n\nCREATE TABLE rag.documents (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    tenant_id TEXT NOT NULL,                -- 'global' for Platform\n    level TEXT NOT NULL CHECK (level IN ('platform','suite','module','entity')),\n    suite_id TEXT,                          -- nullable when not applicable\n    module_id TEXT,                         -- nullable when not applicable\n    title TEXT,\n    source_type TEXT,                       -- upload|url|api\n    source_uri TEXT,\n    metadata JSONB DEFAULT '{}'::jsonb,\n    ingested_at TIMESTAMPTZ DEFAULT now(),\n    ingested_by TEXT,\n    version TEXT,\n    tags TEXT[]\n);\n\nCREATE TABLE rag.chunks (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    document_id UUID NOT NULL REFERENCES rag.documents(id) ON DELETE CASCADE,\n    ord INT NOT NULL,\n    content TEXT NOT NULL,\n    meta JSONB DEFAULT '{}'::jsonb,        -- page, section, headers\n    embedding VECTOR(384)                  -- using 384-dim embeddings\n);\n\n-- Row-Level Security for tenant isolation on documents (applies to chunks via FK)\nALTER TABLE rag.documents ENABLE ROW LEVEL SECURITY;\n\nCREATE POLICY rag_docs_tenant_isolation ON rag.documents\n  USING (tenant_id = current_setting('app.current_tenant_id', true));\n\n-- Similarity indexes\nCREATE INDEX IF NOT EXISTS idx_chunks_embedding ON rag.chunks\n  USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n\n-- Helpful metadata indexes\nCREATE INDEX IF NOT EXISTS idx_docs_level ON rag.documents(level);\nCREATE INDEX IF NOT EXISTS idx_docs_suite_module ON rag.documents(suite_id, module_id);\nCREATE INDEX IF NOT EXISTS idx_docs_tenant ON rag.documents(tenant_id);\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#32-vector-search-implementation","title":"3.2 Vector Search Implementation","text":"<pre><code># services/rag/app/hierarchical_retrieval.py\nfrom typing import List, Dict, Any, Optional\nimport asyncpg\n\nclass HierarchicalRAGRetriever:\n    \"\"\"\n    Retrieve context from unified rag.documents/rag.chunks across levels.\n    \"\"\"\n\n    def __init__(self, db_pool: asyncpg.Pool):\n        self.db = db_pool\n\n    async def retrieve_context(\n        self,\n        query_embedding: List[float],\n        tenant_id: str,\n        suite_id: str,\n        module_id: str,\n        levels: List[str] = [\"entity\", \"module\", \"suite\", \"platform\"],\n        k_per_level: Optional[Dict[str, int]] = None,\n        boosts: Optional[Dict[str, float]] = None\n    ) -&gt; List[Dict[str, Any]]:\n        if k_per_level is None:\n            k_per_level = {\"entity\": 3, \"module\": 5, \"suite\": 5, \"platform\": 2}\n        if boosts is None:\n            boosts = {\"entity\": 0.15, \"module\": 0.10, \"suite\": 0.05, \"platform\": 0.0}\n\n        results: List[Dict[str, Any]] = []\n        for level in levels:\n            rows = await self._search_level(\n                level, query_embedding, tenant_id, suite_id, module_id, k_per_level[level]\n            )\n            for r in rows:\n                r[\"adjusted_score\"] = float(r[\"similarity_score\"]) + boosts.get(level, 0.0)\n                r[\"level\"] = level\n            results.extend(rows)\n\n        # Sort by adjusted score and return\n        results.sort(key=lambda x: x[\"adjusted_score\"], reverse=True)\n        return results\n\n    async def _search_level(\n        self,\n        level: str,\n        embedding: List[float],\n        tenant_id: str,\n        suite_id: str,\n        module_id: str,\n        k: int\n    ) -&gt; List[Dict[str, Any]]:\n        filters = []\n        params = [embedding]\n\n        if level == \"entity\":\n            filters.append(\"d.tenant_id = $2\")\n            params.append(tenant_id)\n            if suite_id:\n                filters.append(\"d.suite_id = $3\")\n                params.append(suite_id)\n            if module_id:\n                filters.append(\"(d.module_id = $4 OR d.module_id IS NULL)\")\n                params.append(module_id)\n        elif level == \"module\":\n            filters.append(\"d.level = 'module'\")\n            filters.append(\"d.suite_id = $2\")\n            filters.append(\"d.module_id = $3\")\n            params.extend([suite_id, module_id])\n        elif level == \"suite\":\n            filters.append(\"d.level = 'suite'\")\n            filters.append(\"d.suite_id = $2\")\n            params.append(suite_id)\n        else:  # platform\n            filters.append(\"d.level = 'platform'\")\n            # no extra params\n\n        # Build dynamic WHERE with defaults\n        where_clause = \" AND \".join(filters) if filters else \"TRUE\"\n\n        query = f\"\"\"\n            SELECT\n                c.id as chunk_id,\n                d.id as document_id,\n                d.title,\n                d.level,\n                d.suite_id,\n                d.module_id,\n                d.tenant_id,\n                d.source_uri,\n                c.content,\n                c.meta,\n                1 - (c.embedding &lt;=&gt; $1::vector) AS similarity_score\n            FROM rag.chunks c\n            JOIN rag.documents d ON d.id = c.document_id\n            WHERE {where_clause}\n            ORDER BY c.embedding &lt;=&gt; $1::vector\n            LIMIT {k}\n        \"\"\"\n        rows = await self.db.fetch(query, *params)\n        return [dict(r) for r in rows]\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#4-rag-management-ui-from-fedtransform","title":"4. RAG Management UI (From FedTransform)","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#41-capabilities-to-extract","title":"4.1 Capabilities to Extract","text":"<p>From FedTransform backend: - \u2705 <code>oracle_docs_crawler.py</code> - URL crawling with depth control - \u2705 <code>embedding_service.py</code> - Document embedding generation - \u2705 <code>background_embedding_service.py</code> - Async batch processing - \u2705 <code>content_chunker.py</code> - Intelligent text chunking - \u2705 <code>progress_tracker.py</code> - Ingestion progress tracking</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#42-new-rag-management-service","title":"4.2 New RAG Management Service","text":"<p>Location: <code>cortx-platform/services/rag_manager/</code></p> <p>Purpose: Centralized UI and API for managing all 4 levels of knowledge</p> <p>Features:</p> <pre><code>RAG Management Dashboard:\n\u251c\u2500\u2500 Platform Knowledge\n\u2502   \u251c\u2500\u2500 Upload documents (PDF, DOCX, TXT, MD)\n\u2502   \u251c\u2500\u2500 Crawl URLs (with depth control)\n\u2502   \u251c\u2500\u2500 Import API documentation (OpenAPI specs)\n\u2502   \u2514\u2500\u2500 View/search/delete embeddings\n\u251c\u2500\u2500 Suite Knowledge (per suite)\n\u2502   \u251c\u2500\u2500 Same capabilities as Platform\n\u2502   \u2514\u2500\u2500 Suite admins can manage\n\u251c\u2500\u2500 Module Knowledge (per module)\n\u2502   \u251c\u2500\u2500 Same capabilities as Platform\n\u2502   \u2514\u2500\u2500 Module owners can manage\n\u2514\u2500\u2500 Entity Knowledge (per tenant)\n    \u251c\u2500\u2500 Same capabilities as Platform\n    \u251c\u2500\u2500 Tenant-isolated (RLS enforced)\n    \u2514\u2500\u2500 Tenant admins can manage\n</code></pre> <p>API Endpoints:</p> <pre><code># RAG Management API\nPOST   /v1/rag/ingest                 # Ingest document/URL\nGET    /v1/rag/knowledge               # List knowledge base\nDELETE /v1/rag/knowledge/{id}          # Delete knowledge\nPOST   /v1/rag/search                  # Search knowledge base\nGET    /v1/rag/progress/{job_id}       # Check ingestion progress\n\n# Level-specific endpoints\nPOST   /v1/rag/platform/ingest\nPOST   /v1/rag/suites/{suite_id}/ingest\nPOST   /v1/rag/modules/{module_id}/ingest\nPOST   /v1/rag/tenants/{tenant_id}/ingest\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#43-ui-mockup","title":"4.3 UI Mockup","text":"<pre><code>// RAG Management Dashboard (Next.js)\nexport default function RAGManagementPage() {\n  return (\n    &lt;DashboardLayout&gt;\n      &lt;Tabs&gt;\n        &lt;Tab label=\"Platform Knowledge\"&gt;\n          &lt;KnowledgeIngestionForm level=\"platform\" /&gt;\n          &lt;KnowledgeTable\n            data={platformKnowledge}\n            onDelete={handleDelete}\n          /&gt;\n        &lt;/Tab&gt;\n\n        &lt;Tab label=\"Suite Knowledge\"&gt;\n          &lt;SuiteSelector onChange={setSuite} /&gt;\n          &lt;KnowledgeIngestionForm\n            level=\"suite\"\n            suiteId={selectedSuite}\n          /&gt;\n          &lt;KnowledgeTable\n            data={suiteKnowledge}\n            onDelete={handleDelete}\n          /&gt;\n        &lt;/Tab&gt;\n\n        &lt;Tab label=\"Module Knowledge\"&gt;\n          &lt;ModuleSelector onChange={setModule} /&gt;\n          &lt;KnowledgeIngestionForm\n            level=\"module\"\n            moduleId={selectedModule}\n          /&gt;\n          &lt;KnowledgeTable\n            data={moduleKnowledge}\n            onDelete={handleDelete}\n          /&gt;\n        &lt;/Tab&gt;\n\n        &lt;Tab label=\"My Organization\"&gt;\n          &lt;KnowledgeIngestionForm\n            level=\"entity\"\n            tenantId={currentTenantId}\n          /&gt;\n          &lt;KnowledgeTable\n            data={entityKnowledge}\n            onDelete={handleDelete}\n          /&gt;\n        &lt;/Tab&gt;\n      &lt;/Tabs&gt;\n    &lt;/DashboardLayout&gt;\n  );\n}\n\n// Ingestion Form Component\nfunction KnowledgeIngestionForm({ level, suiteId, moduleId, tenantId }) {\n  return (\n    &lt;Card&gt;\n      &lt;Tabs&gt;\n        &lt;Tab label=\"Upload Document\"&gt;\n          &lt;FileUpload\n            accept=\".pdf,.docx,.txt,.md\"\n            onUpload={handleUpload}\n          /&gt;\n        &lt;/Tab&gt;\n\n        &lt;Tab label=\"Crawl URL\"&gt;\n          &lt;URLCrawlerForm\n            onSubmit={handleCrawl}\n            options={{\n              maxDepth: 3,\n              maxPages: 100,\n              excludePatterns: []\n            }}\n          /&gt;\n        &lt;/Tab&gt;\n\n        &lt;Tab label=\"Import API Docs\"&gt;\n          &lt;OpenAPIImporter onImport={handleAPIImport} /&gt;\n        &lt;/Tab&gt;\n      &lt;/Tabs&gt;\n\n      &lt;IngestionProgress jobId={currentJobId} /&gt;\n    &lt;/Card&gt;\n  );\n}\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#5-ocr-service-port-8137","title":"5. OCR Service (Port 8137)","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#51-service-purpose","title":"5.1 Service Purpose","text":"<p>Extract structured data from documents for all modules: - PropVerify: Title documents, deeds, liens - FedTransform: Legacy system reports, bank statements - ClaimsVerify (MedSuite): Healthcare claims, EOBs - Any module: PDF/image document processing</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#52-architecture","title":"5.2 Architecture","text":"<p>Technology Stack: - Tesseract OCR (open source) - Google Document AI (production, high-accuracy) - PyPDF2 for text-based PDFs - OpenCV for image preprocessing</p> <p>Capabilities:</p> <pre><code># services/ocr/app/main.py\nfrom fastapi import FastAPI, UploadFile, File\nfrom typing import Dict, Any, List\n\napp = FastAPI(title=\"CORTX OCR Service\", version=\"1.0.0\")\n\n@app.post(\"/v1/ocr/extract\")\nasync def extract_text(\n    file: UploadFile = File(...),\n    options: Dict[str, Any] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Extract text from document\n\n    Options:\n    - engine: 'tesseract' | 'google_doc_ai' | 'auto'\n    - language: 'eng', 'spa', etc.\n    - preprocessing: enhance, denoise, deskew\n    - output_format: 'text' | 'structured' | 'json'\n    \"\"\"\n    pass\n\n@app.post(\"/v1/ocr/extract-structured\")\nasync def extract_structured_data(\n    file: UploadFile = File(...),\n    schema: Dict[str, Any] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Extract structured data based on schema\n\n    Example schema:\n    {\n      \"fields\": [\n        {\"name\": \"property_address\", \"type\": \"address\"},\n        {\"name\": \"owner_name\", \"type\": \"person\"},\n        {\"name\": \"parcel_id\", \"type\": \"alphanumeric\"},\n        {\"name\": \"recording_date\", \"type\": \"date\"}\n      ]\n    }\n    \"\"\"\n    pass\n\n@app.post(\"/v1/ocr/batch\")\nasync def batch_extract(\n    files: List[UploadFile],\n    options: Dict[str, Any] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Batch process multiple documents\n    Returns job_id for async processing\n    \"\"\"\n    pass\n\n@app.get(\"/v1/ocr/jobs/{job_id}\")\nasync def get_job_status(job_id: str):\n    \"\"\"Check OCR job status\"\"\"\n    pass\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#53-data-linking-from-propverify","title":"5.3 Data Linking (From PropVerify)","text":"<p>PropVerify has advanced <code>data_linker.py</code> (35K lines) that: - Links extracted fields to master data - Resolves ambiguities - Cross-references multiple documents</p> <p>Decision: Keep in PropVerify for now, extract if other modules need it.</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#6-ledger-service-port-8136","title":"6. Ledger Service (Port 8136)","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#61-service-purpose","title":"6.1 Service Purpose","text":"<p>Provide immutable audit trails for compliance-critical operations: - PropVerify: Title chain verification history - FedReconcile: GTAS submission audit trail - ClaimsVerify: Healthcare claims processing trail - Any module: Tamper-proof audit logs</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#62-architecture","title":"6.2 Architecture","text":"<p>Technology: Permissioned blockchain (Hyperledger Fabric or PostgreSQL with cryptographic hashing)</p> <p>MVP Approach (PostgreSQL-based):</p> <pre><code># services/ledger/app/main.py\nfrom fastapi import FastAPI, Depends\nfrom typing import Dict, Any, List\nimport hashlib\nimport json\nfrom datetime import datetime\n\napp = FastAPI(title=\"CORTX Ledger Service\", version=\"1.0.0\")\n\n@app.post(\"/v1/ledger/append\")\nasync def append_entry(\n    entry: Dict[str, Any],\n    tenant_id: str,\n    module_id: str,\n    user_id: str\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Append immutable entry to ledger\n\n    Entry structure:\n    {\n      \"event_type\": \"title_verification_completed\",\n      \"entity_id\": \"property_123\",\n      \"entity_type\": \"property\",\n      \"data_hash\": \"sha256_of_data\",\n      \"metadata\": {...},\n      \"timestamp\": \"2025-10-01T12:00:00Z\"\n    }\n\n    Returns:\n    {\n      \"ledger_entry_id\": \"uuid\",\n      \"block_hash\": \"sha256_of_entry_+_prev_hash\",\n      \"previous_block_hash\": \"...\",\n      \"confirmation\": \"success\"\n    }\n    \"\"\"\n    # Calculate hash chain\n    prev_hash = await get_latest_block_hash(tenant_id)\n    entry_with_prev = {**entry, \"previous_hash\": prev_hash}\n    block_hash = hashlib.sha256(\n        json.dumps(entry_with_prev, sort_keys=True).encode()\n    ).hexdigest()\n\n    # Store in ledger table\n    await store_ledger_entry(\n        tenant_id=tenant_id,\n        module_id=module_id,\n        user_id=user_id,\n        entry=entry,\n        block_hash=block_hash,\n        previous_hash=prev_hash\n    )\n\n    return {\n        \"ledger_entry_id\": \"...\",\n        \"block_hash\": block_hash,\n        \"previous_block_hash\": prev_hash,\n        \"confirmation\": \"success\"\n    }\n\n@app.get(\"/v1/ledger/verify/{entry_id}\")\nasync def verify_entry(entry_id: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Verify integrity of ledger entry\n    Recalculates hash chain to ensure no tampering\n    \"\"\"\n    pass\n\n@app.get(\"/v1/ledger/history\")\nasync def get_history(\n    tenant_id: str,\n    entity_id: str = None,\n    module_id: str = None,\n    start_date: str = None,\n    end_date: str = None\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Get ledger history for entity/tenant\n    \"\"\"\n    pass\n\n@app.post(\"/v1/ledger/audit-report\")\nasync def generate_audit_report(\n    tenant_id: str,\n    start_date: str,\n    end_date: str,\n    module_ids: List[str] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Generate compliance audit report\n    \"\"\"\n    pass\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#63-database-schema","title":"6.3 Database Schema","text":"<pre><code>CREATE SCHEMA ledger;\n\nCREATE TABLE ledger.blocks (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    tenant_id VARCHAR(100) NOT NULL,\n    module_id VARCHAR(100) NOT NULL,\n    block_number BIGSERIAL,\n    block_hash VARCHAR(64) NOT NULL UNIQUE,  -- SHA-256\n    previous_hash VARCHAR(64),\n\n    -- Entry data\n    event_type VARCHAR(100) NOT NULL,\n    entity_id VARCHAR(255),\n    entity_type VARCHAR(100),\n    data_hash VARCHAR(64) NOT NULL,  -- Hash of actual data (stored separately)\n    metadata JSONB,\n\n    -- Audit\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    created_by VARCHAR(255) NOT NULL,\n\n    -- Constraints\n    CONSTRAINT fk_tenant FOREIGN KEY (tenant_id) REFERENCES platform.tenants(id),\n    CONSTRAINT valid_hash_chain CHECK (\n        (block_number = 1 AND previous_hash IS NULL) OR\n        (block_number &gt; 1 AND previous_hash IS NOT NULL)\n    )\n);\n\n-- Indexes\nCREATE INDEX idx_blocks_tenant ON ledger.blocks(tenant_id);\nCREATE INDEX idx_blocks_entity ON ledger.blocks(tenant_id, entity_id);\nCREATE INDEX idx_blocks_module ON ledger.blocks(module_id);\nCREATE INDEX idx_blocks_created_at ON ledger.blocks(created_at);\n\n-- Immutability: Prevent updates/deletes\nREVOKE UPDATE, DELETE ON ledger.blocks FROM PUBLIC;\n</code></pre>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#7-implementation-roadmap","title":"7. Implementation Roadmap","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#phase-1-foundation-weeks-1-2","title":"Phase 1: Foundation (Weeks 1-2)","text":"<ol> <li>\u2705 Design hierarchical RAG architecture (this document)</li> <li>\u23f3 Extract FedTransform RAG components</li> <li>\u23f3 Create RAG Management UI scaffold</li> <li>\u23f3 Set up pgvector database schema</li> <li>\u23f3 Implement basic retrieval (single-level)</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#phase-2-ocr-ledger-services-weeks-3-4","title":"Phase 2: OCR &amp; Ledger Services (Weeks 3-4)","text":"<ol> <li>\u23f3 Extract PropVerify OCR engine</li> <li>\u23f3 Create OCR Service (port 8137)</li> <li>\u23f3 Extract PropVerify Ledger service</li> <li>\u23f3 Create Ledger Service (port 8136)</li> <li>\u23f3 Integrate services with AI Broker</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#phase-3-hierarchical-retrieval-weeks-5-6","title":"Phase 3: Hierarchical Retrieval (Weeks 5-6)","text":"<ol> <li>\u23f3 Implement 4-level retrieval logic</li> <li>\u23f3 Build context scoring algorithm</li> <li>\u23f3 Add smart context expansion</li> <li>\u23f3 Performance optimization (caching, indexes)</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#phase-4-rag-management-ui-weeks-7-8","title":"Phase 4: RAG Management UI (Weeks 7-8)","text":"<ol> <li>\u23f3 Build document upload interface</li> <li>\u23f3 Build URL crawler interface</li> <li>\u23f3 Build knowledge browsing/search</li> <li>\u23f3 Implement progress tracking</li> <li>\u23f3 Add level-based permissions</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#phase-5-integration-testing-weeks-9-10","title":"Phase 5: Integration &amp; Testing (Weeks 9-10)","text":"<ol> <li>\u23f3 Integrate with all suites</li> <li>\u23f3 Load initial knowledge bases</li> <li>\u23f3 End-to-end testing</li> <li>\u23f3 Performance tuning</li> <li>\u23f3 Documentation</li> </ol>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#8-migration-strategy","title":"8. Migration Strategy","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#81-existing-rag-data","title":"8.1 Existing RAG Data","text":"<p>FedTransform RAG data: - Current location: FedTransform embeddings (FAISS/local) - Migration: Export \u2192 Re-embed \u2192 Import to Module-level (FedTransform)</p> <p>FedSuite RAG data: - Current location: <code>cortx-suites/fedsuite/embeddings/</code> - Migration: Export \u2192 Categorize (Suite vs Module) \u2192 Import</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#82-knowledge-seeding","title":"8.2 Knowledge Seeding","text":"<p>Platform Level (Week 1): - NIST 800-53 controls - CORTX Platform docs - General security best practices</p> <p>Suite Level (Week 2): - FedSuite: OMB circulars, GTAS guide, USSGL - CorpSuite: Real estate law basics - MedSuite: HIPAA regulations</p> <p>Module Level (Weeks 3-4): - FedTransform: Oracle/SAP schemas - PropVerify: SDAT API docs - FedReconcile: GTAS schemas</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#9-open-questions-decisions","title":"9. Open Questions &amp; Decisions","text":""},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#91-embedding-model","title":"9.1 Embedding Model","text":"<p>Question: Which embedding model? - Option A: OpenAI <code>text-embedding-3-small</code> (384-dim, $0.02/1M tokens) - Option B: Google <code>textembedding-gecko</code> (768-dim, Vertex AI pricing) - Option C: Open source (Sentence Transformers, free, self-hosted)</p> <p>Recommendation: Start with OpenAI (fast, cheap), migrate to open source for compliance/cost.</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#92-chunking-strategy","title":"9.2 Chunking Strategy","text":"<p>Question: How to chunk documents? - Fixed size: 512 tokens per chunk (simple) - Semantic chunking: Split on paragraphs/sections (better context) - Hybrid: Semantic + max size constraint</p> <p>Recommendation: Semantic chunking with 512-token max.</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#93-vector-store-performance","title":"9.3 Vector Store Performance","text":"<p>Question: Can pgvector handle this at scale? - Concern: 1M+ embeddings across 4 levels - Alternative: Pinecone, Weaviate, Qdrant (managed vector DBs)</p> <p>Recommendation: Start with pgvector (simpler), monitor performance, migrate if needed.</p> <p>END OF DOCUMENT</p>"},{"location":"HIERARCHICAL_RAG_ARCHITECTURE/#10-environment-deployment-considerations","title":"10. Environment &amp; Deployment Considerations","text":"<p>Environments: <code>dev</code> \u2192 <code>staging</code> \u2192 <code>prod</code> with identical topology and promotion gates.</p> Aspect Dev Staging Prod Identity In-repo OIDC + GitHub/Google Same + restricted external IdP Keycloak/Auth0 or hardened OIDC AI Providers Vertex + (optional) OpenAI (flagged) Vertex primary Vertex only (unless ATO extends) Database Cloud SQL (HA in stg/prod) + pgvector Cloud SQL (HA) + pgvector Cloud SQL (HA) + pgvector Redis MemoryStore basic MemoryStore standard MemoryStore standard Storage gcs-{svc}-dev gcs-{svc}-stg gcs-{svc}-prod Secrets Secret Manager (dev) Secret Manager (stg) Secret Manager (prod) Network Private VPC (dev subnet) Isolated subnet Isolated subnet + WAF hardening Deploy Auto on main merge Manual approve Manual approve + change record Data Synthetic Sanitized prod-like Live tenant data <p>Demo Checkpoints are aligned with this plan: (A) FedReconcile RAG demo (Week 3), (B) Ledger Evidence export (Week 6), (C) OCR\u2192RAG pipeline (Week 8\u20139).</p>"},{"location":"REFACTORING_ANALYSIS/","title":"CORTX Ecosystem Refactoring Analysis","text":"<p>Date: 2025-10-01 Status: Draft Team: Tech Architect, Backend Services Dev, Functional Lead</p>"},{"location":"REFACTORING_ANALYSIS/#executive-summary","title":"Executive Summary","text":"<p>This document provides a comprehensive analysis of the CORTX ecosystem refactoring effort, examining: 1. Platform Centralization: What services should be centralized in cortx-platform 2. Module Boundaries: Where each module should live in the new structure 3. Shared Code Extraction: What common code should be extracted into SDKs/packages</p>"},{"location":"REFACTORING_ANALYSIS/#key-findings-in-progress","title":"Key Findings (In Progress)","text":"<ul> <li>High Code Duplication: Auth, AI/RAG, validation, config, logging duplicated across 7+ repos</li> <li>Unclear Boundaries: Platform services vs module code mixed together</li> <li>Multiple FedTransform versions: Need to consolidate Asset Development and Development copies</li> <li>Greenlight duplicates: Two versions at different locations</li> </ul>"},{"location":"REFACTORING_ANALYSIS/#1-tech-architect-perspective-platform-centralization","title":"1. TECH ARCHITECT PERSPECTIVE: Platform Centralization","text":""},{"location":"REFACTORING_ANALYSIS/#analysis-methodology","title":"Analysis Methodology","text":"<p>Review each repository to identify: - Authentication &amp; authorization code \u2192 Identity Service (8082) - AI/RAG services \u2192 AI Broker Service (8085) - Validation engines \u2192 Validation Service (8083) - Workflow orchestration \u2192 Workflow Service (8130) - Compliance/audit logging \u2192 Compliance Service (8135) - Configuration management \u2192 Platform-level - Common middleware \u2192 Gateway Service (8080)</p>"},{"location":"REFACTORING_ANALYSIS/#11-authentication-authorization-code","title":"1.1 Authentication &amp; Authorization Code","text":""},{"location":"REFACTORING_ANALYSIS/#current-state","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/auth/\n\u251c\u2500\u2500 jwt_auth.py\n\u251c\u2500\u2500 federated_auth.py\n\u251c\u2500\u2500 federated_auth_fastapi.py\n\u2514\u2500\u2500 session_manager.py\n\ncortx-suites/fedsuite/middleware/\n\u2514\u2500\u2500 auth_fastapi.py\n\ncortx-propverify/backend/common/\n\u251c\u2500\u2500 auth.py\n\u2514\u2500\u2500 tokens.py\n\ndeprecated-cortx-development/app/auth/\n\u251c\u2500\u2500 federated_auth.py\n\u2514\u2500\u2500 session_manager.py\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation","title":"Recommendation","text":"<p>Target: cortx-platform Identity Service (port 8082)</p> <p>Files to centralize: - JWT validation &amp; token generation - Session management - Federated auth (OAuth/OIDC) - RBAC enforcement</p> <p>Keep in modules: - Module-specific permission checks - Custom auth decorators (if module-specific roles exist)</p> <p>Priority: HIGH - Foundational service</p>"},{"location":"REFACTORING_ANALYSIS/#12-airag-services","title":"1.2 AI/RAG Services","text":""},{"location":"REFACTORING_ANALYSIS/#current-state_1","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/ai/\n\u251c\u2500\u2500 ai_helper.py\n\u251c\u2500\u2500 ai_rag_engine.py\n\u251c\u2500\u2500 compliance_assistant.py\n\u251c\u2500\u2500 correction_generator.py\n\u251c\u2500\u2500 explanation_engine.py\n\u251c\u2500\u2500 intelligent_corrections.py\n\u251c\u2500\u2500 sync_rag_wrapper.py\n\ncortx-platform/modules/reconciliation/cortx_recon/ (?)\n\ncortx-propverify/backend/ai_svc/\n\u251c\u2500\u2500 app/\n\u251c\u2500\u2500 clients/\n\u2514\u2500\u2500 pii_detector.py\n\nFedTransform/backend/\n\u251c\u2500\u2500 ai_service.py\n\u251c\u2500\u2500 ai_service_ollama.py\n\u251c\u2500\u2500 ai_service_smart.py\n\u251c\u2500\u2500 embedding_service.py\n\u251c\u2500\u2500 ai_rag_engine.py (?)\n\ndeprecated-cortx-development/app/ai/\n\u2514\u2500\u2500 (similar files)\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_1","title":"Recommendation","text":"<p>Target:  - cortx-platform AI Broker Service (port 8085) for model routing, safety, and provider policy, and  - cortx-platform RAG Service (port 8138) for ingestion, chunking, embeddings, and hierarchical retrieval.</p> <p>Core services to centralize (split of concerns): - AI Broker (8085): Provider allowlist, model routing (Gemini/Claude/GPT-4), safety/PII redaction, prompt template library, response caching. - RAG (8138): Vector store admin (pgvector), document ingestion (upload + crawl), semantic chunking, embedding generation, 4-level hierarchical retrieval (Platform \u2192 Suite \u2192 Module \u2192 Entity) with specificity boosts.</p> <p>Module-specific AI code to keep: - Domain-specific prompt templates - Module-specific fine-tuning or model selection logic - Specialized correction generators (GTAS vs HIPAA vs PropVerify) - Module-scoped knowledge seeds (stored under Module/Suite scopes in RAG)</p> <p>Priority: HIGH - Heavy duplication</p> <p>Outcome of refactor: All modules call the AI Broker for generation and the RAG Service for retrieval; no module maintains its own embeddings or ad-hoc vector DB.</p>"},{"location":"REFACTORING_ANALYSIS/#13-validation-engines","title":"1.3 Validation Engines","text":""},{"location":"REFACTORING_ANALYSIS/#current-state_2","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/utils/\n\u251c\u2500\u2500 validation_engine.py\n\u251c\u2500\u2500 treasury_validation_engine.py\n\u251c\u2500\u2500 validation_logic.py\n\ncortx-suites/fedsuite/security/\n\u2514\u2500\u2500 safe_rule_engine.py\n\ncortx-propverify/backend/validation_svc/\n\u251c\u2500\u2500 app/\n\u2514\u2500\u2500 clients/\n\ncompliance-scanner/scanner/\n\u2514\u2500\u2500 engine.py\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_2","title":"Recommendation","text":"<p>Target: cortx-platform Validation Service (port 8083)</p> <p>Core engine to centralize: - RulePack execution engine (safe operators) - Rule parsing and validation - Batch validation - Result aggregation</p> <p>Module-specific validators to keep: - Domain-specific validation logic (GTAS rules, HIPAA rules, SDAT rules) - These become RulePacks stored in cortx-packs repository</p> <p>Priority: MEDIUM - Core platform capability</p>"},{"location":"REFACTORING_ANALYSIS/#14-workflow-orchestration","title":"1.4 Workflow Orchestration","text":""},{"location":"REFACTORING_ANALYSIS/#current-state_3","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-propverify/backend/workflow_svc/\n\u251c\u2500\u2500 app/\n\u2514\u2500\u2500 clients/\n\ncortx-suites/fedsuite/ (various workflow-related files)\n\u2514\u2500\u2500 cross_suite_integration.py\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_3","title":"Recommendation","text":"<p>Target: cortx-platform Workflow Service (port 8130)</p> <p>Core orchestration to centralize: - WorkflowPack execution engine - Step sequencing (parallel, sequential) - Saga pattern for distributed transactions - State machine management - Human-in-the-loop approval gates</p> <p>Module-specific workflows to keep: - Specific workflow definitions (stored as WorkflowPacks in cortx-packs) - Module-specific step implementations</p> <p>Priority: MEDIUM - Platform core</p>"},{"location":"REFACTORING_ANALYSIS/#15-compliance-audit-logging","title":"1.5 Compliance &amp; Audit Logging","text":""},{"location":"REFACTORING_ANALYSIS/#current-state_4","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/utils/\n\u2514\u2500\u2500 audit_compliance.py\n\ncortx-suites/fedsuite/middleware/\n\u2514\u2500\u2500 logging_fastapi.py\n\ncortx-platform (currently no dedicated compliance service)\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_4","title":"Recommendation","text":"<p>Target: cortx-platform Compliance Service (port 8135)</p> <p>Core compliance features to centralize: - Immutable audit trail - NIST 800-53 control evidence collection - Compliance report generation (FedRAMP, HIPAA, SOC 2) - Log aggregation and retention</p> <p>Companion Service: Promote Ledger Service (8136) for append-only, hash-chained compliance evidence shared across suites.</p> <p>Priority: HIGH - Regulatory requirement</p>"},{"location":"REFACTORING_ANALYSIS/#16-configuration-management","title":"1.6 Configuration Management","text":""},{"location":"REFACTORING_ANALYSIS/#current-state_5","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/config/\n\u251c\u2500\u2500 config.py\n\u251c\u2500\u2500 policies/\n\u2514\u2500\u2500 schemas/\n\ncortx-propverify/backend/common/\n\u2514\u2500\u2500 config.py\n\nFedTransform/backend/\n\u2514\u2500\u2500 database.py (config patterns)\n\ngreenlight/packages/config/\n\u251c\u2500\u2500 company.yml\n\u251c\u2500\u2500 keywords.yml\n\u2514\u2500\u2500 scoring.yml\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_5","title":"Recommendation","text":"<p>Target: cortx-platform Schema Service (port 8084) + Config package</p> <p>Core config to centralize: - Environment-based settings (Pydantic Settings pattern) - Secret management (GCP Secret Manager integration) - Multi-tenant configuration - Schema registry</p> <p>Module-specific config to keep: - Module-specific settings - Domain configuration files (e.g., greenlight scoring.yml)</p> <p>Priority: MEDIUM</p>"},{"location":"REFACTORING_ANALYSIS/#17-common-middleware","title":"1.7 Common Middleware","text":""},{"location":"REFACTORING_ANALYSIS/#18-ocr-service-new","title":"1.8 OCR Service (NEW)","text":""},{"location":"REFACTORING_ANALYSIS/#recommendation_6","title":"Recommendation","text":"<p>Target: cortx-platform OCR Service (port 8137)</p> <p>Rationale: OCR is a cross-cutting concern needed by PropVerify (land records), FedTransform (legacy reports), and future Claims modules. Centralizing it avoids duplicate engines and normalizes extraction outputs into a shared <code>DocumentExtraction</code> schema for downstream RAG ingestion.</p>"},{"location":"REFACTORING_ANALYSIS/#current-state_6","title":"Current State","text":"<p>Locations identified:</p> <pre><code>cortx-suites/fedsuite/middleware/\n\u251c\u2500\u2500 auth_fastapi.py\n\u2514\u2500\u2500 logging_fastapi.py\n\ncortx-suites/fedsuite/security/\n\u251c\u2500\u2500 cors_config.py\n\u251c\u2500\u2500 rate_limiter.py\n\u2514\u2500\u2500 secret_manager.py\n\ncortx-propverify/backend/common/\n\u251c\u2500\u2500 middleware.py\n\u251c\u2500\u2500 logging.py\n\u2514\u2500\u2500 metrics.py\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#recommendation_7","title":"Recommendation","text":"<p>Target: cortx-platform Gateway Service (port 8080) + common package</p> <p>Core middleware to centralize: - Request logging - CORS configuration - Rate limiting - Circuit breaker - Request/response transformation</p> <p>Priority: HIGH - Gateway is the entry point</p>"},{"location":"REFACTORING_ANALYSIS/#2-backend-services-developer-perspective-code-structure","title":"2. BACKEND SERVICES DEVELOPER PERSPECTIVE: Code Structure","text":""},{"location":"REFACTORING_ANALYSIS/#analysis-methodology_1","title":"Analysis Methodology","text":"<p>Examine actual code patterns, dependencies, and implementation details to determine: - Code quality and maintainability - Duplication vs variation - Migration complexity - Breaking changes</p>"},{"location":"REFACTORING_ANALYSIS/#21-common-utilities-analysis","title":"2.1 Common Utilities Analysis","text":""},{"location":"REFACTORING_ANALYSIS/#file-helpers-utilities","title":"File Helpers &amp; Utilities","text":"<p>Current locations:</p> <pre><code>cortx-suites/fedsuite/utils/\n\u251c\u2500\u2500 file_helpers.py\n\u251c\u2500\u2500 json_sanitizer.py\n\u251c\u2500\u2500 port_finder.py\n\u251c\u2500\u2500 suppress_warnings.py\n\u251c\u2500\u2500 amounts.py\n\ndeprecated-cortx-development/app/utils/\n\u251c\u2500\u2500 file_helpers.py\n\u251c\u2500\u2500 logging.py\n\u251c\u2500\u2500 suppress_warnings.py\n</code></pre> <p>Recommendation: Extract to <code>cortx-platform/packages/cortx_core/utils/</code></p>"},{"location":"REFACTORING_ANALYSIS/#22-data-models-schemas","title":"2.2 Data Models &amp; Schemas","text":"<p>Current state: Pydantic models and SQLAlchemy models scattered across repos</p> <p>Recommendation: - cortx-sdks/sdk-python/cortx_sdk/models/ - Shared Pydantic schemas - Each service maintains its own SQLAlchemy models (tenant-isolated)</p>"},{"location":"REFACTORING_ANALYSIS/#23-frontend-components","title":"2.3 Frontend Components","text":"<p>Current state:</p> <pre><code>cortx-platform/frontend/src/components/ (some components)\ncortx-designer/frontend/src/components/ (different components)\ncortx-propverify/ (has frontend but no shared component library)\n</code></pre> <p>Recommendation: Create <code>cortx-platform/packages/ui-components</code> (React component library)</p>"},{"location":"REFACTORING_ANALYSIS/#3-functional-lead-perspective-module-boundaries","title":"3. FUNCTIONAL LEAD PERSPECTIVE: Module Boundaries","text":""},{"location":"REFACTORING_ANALYSIS/#analysis-methodology_2","title":"Analysis Methodology","text":"<p>Define clear boundaries for each module based on: - Business domain - User personas - Data ownership - Compliance requirements</p>"},{"location":"REFACTORING_ANALYSIS/#31-fedsuite-modules","title":"3.1 FedSuite Modules","text":""},{"location":"REFACTORING_ANALYSIS/#fedreconcile","title":"FedReconcile","text":"<p>Current location: <code>/Users/michael/Development/cortx-suites/fedsuite/</code></p> <p>Business purpose: GTAS trial balance reconciliation with Treasury ATB</p> <p>Recommended location: <code>fedsuite/modules/fedreconcile/</code></p> <p>Structure:</p> <pre><code>fedsuite/\n\u251c\u2500\u2500 modules/\n\u2502   \u2514\u2500\u2500 fedreconcile/\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u2502   \u251c\u2500\u2500 reconciliation_engine.py\n\u2502       \u2502   \u251c\u2500\u2500 gtas_parser.py\n\u2502       \u2502   \u251c\u2500\u2500 tb_parser.py\n\u2502       \u2502   \u2514\u2500\u2500 diagnostic_engine.py\n\u2502       \u251c\u2500\u2500 rulepacks/ (GTAS-specific rules)\n\u2502       \u251c\u2500\u2500 workflows/ (GTAS-specific workflows)\n\u2502       \u251c\u2500\u2500 tests/\n\u2502       \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 services/ (suite-level infrastructure)\n    \u2514\u2500\u2500 api.py\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#fedtransform","title":"FedTransform","text":"<p>Current locations: - <code>/Volumes/Dev Volume/Asset Development/FedTransform</code> - <code>/Volumes/Dev Volume/Development/FedTransform</code></p> <p>Business purpose: Transform legacy data formats to FBDI-ready datasets for Oracle Cloud</p> <p>Recommended location: <code>fedsuite/modules/fedtransform/</code></p> <p>Action required: Consolidate the two versions (likely Asset Development is newer based on timestamps)</p>"},{"location":"REFACTORING_ANALYSIS/#32-corpsuite-modules","title":"3.2 CorpSuite Modules","text":""},{"location":"REFACTORING_ANALYSIS/#propverify","title":"PropVerify","text":"<p>Current location: <code>/Users/michael/Development/cortx-propverify</code></p> <p>Business purpose: Maryland land records title verification</p> <p>Recommended location: <code>corpsuite/modules/propverify/</code></p> <p>Notes: Currently has full microservices structure (5 services). Evaluate which services are truly module-specific vs should use platform services.</p>"},{"location":"REFACTORING_ANALYSIS/#greenlight","title":"Greenlight","text":"<p>Current locations: - <code>/Users/michael/Development/greenlight</code> - <code>/Volumes/Dev Volume/sinergy_dev/greenlight</code></p> <p>Business purpose: Vendor/go-to-market opportunity triage (SAM, eVA)</p> <p>Recommended location: <code>corpsuite/modules/greenlight/</code></p> <p>Action required: Consolidate two versions</p>"},{"location":"REFACTORING_ANALYSIS/#investmait-offermait","title":"InvestmAit (OffermAit)","text":"<p>Current location: <code>/Users/michael/Development/OffermAit</code></p> <p>Business purpose: Real estate investment analysis (P/L, sensitivity)</p> <p>Recommended location: <code>corpsuite/modules/investmait/</code></p> <p>Notes: Rename from OffermAit to InvestmAit for consistency</p>"},{"location":"REFACTORING_ANALYSIS/#33-cross-vertical-module","title":"3.3 Cross-Vertical Module","text":""},{"location":"REFACTORING_ANALYSIS/#compliance-scanner","title":"Compliance Scanner","text":"<p>Current location: <code>/Users/michael/Development/compliance-scanner</code></p> <p>Business purpose: Static code analysis for FedRAMP/HIPAA/NIST compliance</p> <p>Question: Is this a platform-level service or a module?</p> <p>Recommendation: Platform-level tool - Move to <code>cortx-platform/tools/compliance-scanner/</code></p> <p>Rationale: Used across all suites for code compliance checking</p>"},{"location":"REFACTORING_ANALYSIS/#4-key-architectural-decisions-resolved","title":"4. KEY ARCHITECTURAL DECISIONS (RESOLVED)","text":""},{"location":"REFACTORING_ANALYSIS/#decision-1-propverify-microservices","title":"Decision 1: PropVerify Microservices \u2705","text":"<p>Decision: Promote shared capabilities to platform and deprecate duplicates.</p> <p>Services to deprecate (use platform instead): - \u274c ai_svc \u2192 Use cortx-platform AI Broker (8085) - \u274c validation_svc \u2192 Use cortx-platform Validation Service (8083) - \u274c workflow_svc \u2192 Use cortx-platform Workflow Service (8130)</p> <p>Capabilities promoted to platform (immediately): - \u2705 OCR Service (8137) \u2013 Centralized OCR (Tesseract + optional DocAI), outputs normalized <code>DocumentExtraction</code> - \u2705 Ledger Service (8136) \u2013 Append-only, SHA-256 hash-chained evidence for compliance across suites - \u2705 RAG Service (8138) \u2013 Centralized ingestion, embeddings, and hierarchical retrieval (Platform/Suite/Module/Entity)</p> <p>Module keeps (PropVerify-specific): - Maryland SDAT/MDLandRec adapters (ingestion connectors) living under <code>corpsuite/modules/propverify/ingestion/</code> - Domain-specific RulePacks &amp; WorkflowPacks</p>"},{"location":"REFACTORING_ANALYSIS/#decision-2-fedtransform-consolidation","title":"Decision 2: FedTransform Consolidation \u2705","text":"<p>Decision: Use <code>/Volumes/Dev Volume/Development/FedTransform</code> as canonical</p> <p>Rationale: This version was being updated to align with UI Modernization Guide</p> <p>Action items: 1. Copy Development version to target location 2. Update UI components to match UI_MODERNIZATION_GUIDE.md (Sinergy branding) 3. Archive Asset Development version 4. Verify UI components use:    - Sinergy Teal (#00C2CB) and Federal Navy (#2D5972)    - Space Grotesk (headings), DM Sans (buttons), IBM Plex Sans (body)    - SS_Logo_Transparent.png branding 5. Extract existing FedTransform RAG scaffolding into platform RAG Service (8138); keep module ontologies as Module-scope seeds.</p>"},{"location":"REFACTORING_ANALYSIS/#decision-3-suite-level-architecture","title":"Decision 3: Suite-Level Architecture \u2705","text":""},{"location":"REFACTORING_ANALYSIS/#decision-4-hierarchical-rag-service","title":"Decision 4: Hierarchical RAG Service \u2705","text":"<p>Decision: Extract RAG from FedTransform and centralize as svc-rag (8138) with 4-level scoping (Platform, Suite, Module, Entity) and specificity-boosted retrieval. Consequences: Designer and all suites reference a single retrieval API; modules contribute scoped knowledge; AI Broker provides embeddings behind policy.</p>"},{"location":"REFACTORING_ANALYSIS/#decision-5-environment-strategy","title":"Decision 5: Environment Strategy \u2705","text":"<p>Decision: Adopt three-tier promotion (dev \u2192 staging \u2192 prod) with Vertex AI as primary provider; OpenAI permitted only in dev via broker flags; Cloud Run runtime; Cloud SQL + pgvector; Memorystore Redis Streams. Consequences: Consistent compliance posture; simple demo checkpoints; portable AI providers behind the broker abstraction.</p> <p>Decision: Domain-based architecture with centralized platform</p> <p>Domain Structure:</p> <pre><code>fedsuite.ai        \u2192 FedSuite (FedReconcile, FedTransform)\nmedsuite.ai        \u2192 MedSuite (ClaimsVerify, HipaaAudit)\ngovsuite.ai        \u2192 GovSuite (TBD modules)\ncorpsuite.ai       \u2192 CorpSuite (PropVerify, Greenlight, InvestmAit)\n\nplatform.sinergysolutions.ai  \u2192 CORTX Platform (7 services)\ndesigner.sinergysolutions.ai  \u2192 BPM Designer\n</code></pre> <p>Recommendation: See Section 6 for detailed suite architecture</p>"},{"location":"REFACTORING_ANALYSIS/#5-suite-architecture-recommendation","title":"5. SUITE ARCHITECTURE RECOMMENDATION","text":""},{"location":"REFACTORING_ANALYSIS/#51-multi-domain-strategy","title":"5.1 Multi-Domain Strategy","text":"<p>Architecture Pattern: Domain-per-suite with shared platform services</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     DOMAIN ARCHITECTURE                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  fedsuite.ai (Federal)                                          \u2502\n\u2502  \u251c\u2500\u2500 Next.js App \u2192 FedReconcile, FedTransform modules           \u2502\n\u2502  \u251c\u2500\u2500 API calls \u2192 platform.sinergysolutions.ai/v1/*              \u2502\n\u2502  \u2514\u2500\u2500 Database: fedsuite schema in shared PostgreSQL             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  corpsuite.ai (Corporate)                                       \u2502\n\u2502  \u251c\u2500\u2500 Next.js App \u2192 PropVerify, Greenlight, InvestmAit          \u2502\n\u2502  \u251c\u2500\u2500 API calls \u2192 platform.sinergysolutions.ai/v1/*              \u2502\n\u2502  \u2514\u2500\u2500 Database: corpsuite schema in shared PostgreSQL            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  medsuite.ai (Healthcare)                                       \u2502\n\u2502  \u251c\u2500\u2500 Next.js App \u2192 ClaimsVerify, HipaaAudit                     \u2502\n\u2502  \u251c\u2500\u2500 API calls \u2192 platform.sinergysolutions.ai/v1/*              \u2502\n\u2502  \u2514\u2500\u2500 Database: medsuite schema in shared PostgreSQL             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  govsuite.ai (State/Local Gov)                                  \u2502\n\u2502  \u251c\u2500\u2500 Next.js App \u2192 TBD modules                                  \u2502\n\u2502  \u251c\u2500\u2500 API calls \u2192 platform.sinergysolutions.ai/v1/*              \u2502\n\u2502  \u2514\u2500\u2500 Database: govsuite schema in shared PostgreSQL             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  platform.sinergysolutions.ai (CORTX Platform)                  \u2502\n\u2502  \u251c\u2500\u2500 Gateway (8080), Identity (8082), AI Broker (8085)          \u2502\n\u2502  \u251c\u2500\u2500 Validation (8083), Workflow (8130), Compliance (8135)      \u2502\n\u2502  \u251c\u2500\u2500 Schemas (8084), Ledger (8136), OCR (8137), RAG (8138)     \u2502\n\u2502  \u2514\u2500\u2500 Database: platform schema + tenant management              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  designer.sinergysolutions.ai (BPM Designer)                    \u2502\n\u2502  \u251c\u2500\u2500 React Flow canvas, AI assistant, Pack marketplace          \u2502\n\u2502  \u2514\u2500\u2500 Calls platform services for pack validation/testing        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#52-suite-frontend-architecture","title":"5.2 Suite Frontend Architecture","text":"<p>Technology Stack: - Framework: Next.js 14 (App Router) - UI Library: React + Tailwind CSS - Component Library: <code>@sinergysolutions/ui-components</code> (shared) - API Client: <code>@sinergysolutionsllc/cortx-sdk</code> (TypeScript SDK) - State Management: React Query for server state, Zustand for client state - Auth: JWT tokens from platform Identity Service</p> <p>Directory Structure (per suite):</p> <pre><code>fedsuite/\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 app/                      # Next.js 14 App Router\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 layout.tsx            # Root layout (Sinergy branding)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 page.tsx              # Suite landing page\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 fedreconcile/         # FedReconcile module pages\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 fedtransform/         # FedTransform module pages\n\u2502   \u2502   \u251c\u2500\u2500 components/               # Suite-specific components\n\u2502   \u2502   \u251c\u2500\u2500 lib/                      # SDK client, utilities\n\u2502   \u2502   \u2514\u2500\u2500 styles/\n\u2502   \u2502       \u251c\u2500\u2500 globals.css           # Sinergy brand styles\n\u2502   \u2502       \u2514\u2500\u2500 tailwind.config.js    # Sinergy colors/fonts\n\u2502   \u251c\u2500\u2500 public/\n\u2502   \u2502   \u251c\u2500\u2500 SS_Logo_Transparent.png\n\u2502   \u2502   \u2514\u2500\u2500 SS-Icon-Transparent.png\n\u2502   \u2514\u2500\u2500 package.json\n\u251c\u2500\u2500 modules/                           # Backend modules\n\u2502   \u251c\u2500\u2500 fedreconcile/\n\u2502   \u2514\u2500\u2500 fedtransform/\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#53-suite-backend-architecture","title":"5.3 Suite Backend Architecture","text":"<p>Deployment Pattern: Each suite is a single FastAPI application with module routers</p> <pre><code># fedsuite/backend/main.py\nfrom fastapi import FastAPI\nfrom modules.fedreconcile import router as fedreconcile_router\nfrom modules.fedtransform import router as fedtransform_router\n\napp = FastAPI(title=\"FedSuite API\", version=\"1.0.0\")\n\n# Register module routers\napp.include_router(fedreconcile_router, prefix=\"/v1/fedreconcile\", tags=[\"fedreconcile\"])\napp.include_router(fedtransform_router, prefix=\"/v1/fedtransform\", tags=[\"fedtransform\"])\n</code></pre> <p>Module Structure:</p> <pre><code>fedsuite/modules/fedreconcile/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 router.py              # FastAPI router\n\u2502   \u251c\u2500\u2500 service.py             # Business logic\n\u2502   \u251c\u2500\u2500 models.py              # Data models\n\u2502   \u2514\u2500\u2500 clients/               # External API clients (GTAS, Treasury)\n\u251c\u2500\u2500 rulepacks/                 # GTAS-specific validation rules\n\u251c\u2500\u2500 workflows/                 # GTAS-specific workflows\n\u251c\u2500\u2500 tests/\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"REFACTORING_ANALYSIS/#54-database-strategy","title":"5.4 Database Strategy","text":"<p>Multi-Tenant Schema-Per-Suite Pattern:</p> <pre><code>-- PostgreSQL schemas\nCREATE SCHEMA platform;        -- Platform services, tenant registry\nCREATE SCHEMA fedsuite;        -- FedReconcile, FedTransform data\nCREATE SCHEMA corpsuite;       -- PropVerify, Greenlight, InvestmAit data\nCREATE SCHEMA medsuite;        -- ClaimsVerify, HipaaAudit data\nCREATE SCHEMA govsuite;        -- GovSuite data\n</code></pre> <p>Data Isolation: - Each suite operates in its own schema - Platform services use <code>platform</code> schema for cross-cutting concerns - RLS (Row-Level Security) within each schema for tenant isolation - Tenant ID propagated via JWT claims</p>"},{"location":"REFACTORING_ANALYSIS/#55-api-gateway-strategy","title":"5.5 API Gateway Strategy","text":"<p>Recommendation: Single Gateway with domain-based routing</p> <p>Option A: Single Gateway at platform.sinergysolutions.ai (RECOMMENDED)</p> <pre><code>platform.sinergysolutions.ai/v1/suites/fedsuite/*   \u2192 fedsuite backend\nplatform.sinergysolutions.ai/v1/suites/corpsuite/* \u2192 corpsuite backend\nplatform.sinergysolutions.ai/v1/suites/medsuite/*  \u2192 medsuite backend\nplatform.sinergysolutions.ai/v1/suites/govsuite/*  \u2192 govsuite backend\n</code></pre> <p>Pros: - Single ingress point for monitoring, rate limiting, auth - Centralized CORS, logging, metrics - Easier certificate management - Unified API documentation</p> <p>Cons: - Single point of failure (mitigated with GCP Cloud Run autoscaling) - More complex routing logic</p> <p>Option B: Suite-Level Gateways (ALTERNATIVE)</p> <pre><code>api.fedsuite.ai/*\napi.corpsuite.ai/*\napi.medsuite.ai/*\napi.govsuite.ai/*\n</code></pre> <p>Pros: - Suite autonomy - Blast radius containment - Independent scaling</p> <p>Cons: - More infrastructure overhead - Duplicated middleware logic - More complex monitoring</p> <p>RECOMMENDATION: Option A (Single Gateway) for Phase 1, migrate to Option B if suite independence becomes critical.</p>"},{"location":"REFACTORING_ANALYSIS/#56-shared-ui-component-library","title":"5.6 Shared UI Component Library","text":"<p>Location: <code>cortx-platform/packages/ui-components/</code></p> <p>Purpose: Provide Sinergy-branded React components for all suites</p> <p>Components to include:</p> <pre><code>// Brand\n&lt;SinergyLogo variant=\"full\" | \"icon\" /&gt;\n&lt;SuiteHeader suite=\"fed\" | \"corp\" | \"med\" | \"gov\" /&gt;\n\n// Layout\n&lt;DashboardLayout /&gt;\n&lt;ModuleLayout /&gt;\n&lt;WizardLayout /&gt;\n\n// Forms\n&lt;SinergyButton variant=\"primary\" | \"secondary\" /&gt;\n&lt;SinergyInput /&gt;\n&lt;SinergySelect /&gt;\n\n// Data Display\n&lt;SinergyTable /&gt;\n&lt;SinergyCard /&gt;\n&lt;StoplightIndicator value={0-100} /&gt;\n\n// Charts (with Sinergy colors)\n&lt;SinergyLineChart /&gt;\n&lt;SinergyBarChart /&gt;\n&lt;SinergyHeatmap /&gt;\n\n// AI\n&lt;AIAssistantPanel /&gt;\n&lt;RAGCitationView /&gt;\n</code></pre> <p>Styling: All components use Sinergy brand colors and typography from UI_MODERNIZATION_GUIDE.md</p>"},{"location":"REFACTORING_ANALYSIS/#57-deployment-architecture","title":"5.7 Deployment Architecture","text":"<p>GCP Cloud Run (Serverless):</p> <pre><code>platform.sinergysolutions.ai \u2192 GCP Cloud Run (cortx-platform-gateway)\ndesigner.sinergysolutions.ai \u2192 GCP Cloud Run (cortx-designer)\nfedsuite.ai                  \u2192 GCP Cloud Run (fedsuite-app)\ncorpsuite.ai                 \u2192 GCP Cloud Run (corpsuite-app)\nmedsuite.ai                  \u2192 GCP Cloud Run (medsuite-app)\ngovsuite.ai                  \u2192 GCP Cloud Run (govsuite-app)\n</code></pre> <p>Services:</p> <pre><code>cortx-platform-gateway       (Gateway Service)\ncortx-platform-identity      (Identity Service)\ncortx-platform-ai-broker     (AI Broker Service)\ncortx-platform-validation    (Validation Service)\ncortx-platform-workflow      (Workflow Service)\ncortx-platform-compliance    (Compliance Service)\ncortx-platform-schemas       (Schema Service)\ncortx-platform-ledger*       (Ledger Service - TBD)\n\nfedsuite-app                 (Next.js + FastAPI modules)\ncorpsuite-app                (Next.js + FastAPI modules)\nmedsuite-app                 (Next.js + FastAPI modules)\ngovsuite-app                 (Next.js + FastAPI modules)\n</code></pre> <p>Shared Infrastructure: - PostgreSQL (Cloud SQL) - shared with schema-per-suite - Redis (Memorystore) - shared, key prefixing - GCS (Cloud Storage) - bucket-per-suite - Secret Manager - centralized</p>"},{"location":"REFACTORING_ANALYSIS/#58-cross-suite-integration","title":"5.8 Cross-Suite Integration","text":"<p>Event Bus Pattern (Redis Streams):</p> <pre><code># Publish event from FedReconcile\nawait redis.xadd(\n    \"cortx:events:fedsuite\",\n    {\n        \"event_type\": \"reconciliation_completed\",\n        \"workflow_id\": \"gtas_monthly_001\",\n        \"tenant_id\": \"agency-dod-001\",\n        \"status\": \"success\"\n    }\n)\n\n# Subscribe from Compliance Service\nevents = await redis.xread({\"cortx:events:fedsuite\": \"0\"}, count=10)\n</code></pre> <p>Cross-Suite Workflows: - FedReconcile \u2192 Compliance Service (audit trail) - PropVerify \u2192 Ledger Service (immutable records) - All suites \u2192 AI Broker (explanations, recommendations)</p>"},{"location":"REFACTORING_ANALYSIS/#6-outstanding-questions","title":"6. OUTSTANDING QUESTIONS","text":""},{"location":"REFACTORING_ANALYSIS/#61-ledger-service-decision-resolved","title":"6.1 Ledger Service Decision \u2705 (Resolved)","text":"<p>Outcome: Promote to platform as Ledger Service (8136). Required by multiple suites for tamper-evident compliance evidence; integrates with Compliance Service (8135). </p>"},{"location":"REFACTORING_ANALYSIS/#62-ocr-engine-decision-resolved","title":"6.2 OCR Engine Decision \u2705 (Resolved)","text":"<p>Outcome: Promote to platform as OCR Service (8137) with Tesseract default and optional Google Document AI via AI Broker policy.</p>"},{"location":"REFACTORING_ANALYSIS/#63-rag-centralization-resolved","title":"6.3 RAG Centralization \u2705 (Resolved)","text":"<p>Outcome: Create dedicated RAG Service (8138). Modules no longer own vector DBs; all retrieval uses hierarchical scoping via the platform service.</p>"},{"location":"REFACTORING_ANALYSIS/#7-migration-plan-phased-demo-checkpoints","title":"7. MIGRATION PLAN (PHASED + DEMO CHECKPOINTS)","text":"<p>Phase 0 (Week 0\u20131): Foundations - Stand up svc-rag (8138) schema/tables (pgvector), minimal APIs (upload/crawl, ingest, query) - Promote svc-ocr (8137) and svc-ledger (8136) with MVP endpoints - Gateway routes and Identity scopes for new services</p> <p>Checkpoint A (End of Week 3): FedReconcile RAG Demo - Seed Platform: OMB A-136; Suite: GTAS; Module: FedTransform/FedReconcile docs; Entity: sample agency - Next.js demo page: query with hierarchical citations; export ledger CSV of actions</p> <p>Phase 1 (Week 2\u20134): Integrations - PropVerify: switch OCR to Platform; remove internal ledger writes - FedTransform: move RAG content to svc-rag (module scope); update SDK calls</p> <p>Phase 2 (Week 5\u20136): Hardening - RLS policies, PII redaction in AI Broker before embedding - RAG Admin UI (scope tabs; upload/crawl/browse/delete)</p> <p>Checkpoint B (End of Week 6): Ledger Evidence Demo - Show hash-chain verification; downloadable CSV; integrate with Compliance UI</p> <p>Phase 3 (Week 7\u20138): Suite Conversions - Greenlight, InvestmAit: audit AI usage; migrate to AI Broker + svc-rag as needed - E2E tests across gateway \u2192 services \u2192 DB</p> <p>Checkpoint C (End of Week 8\u20139): OCR\u2192RAG Pipeline Demo - Upload scanned PDF \u2192 OCR \u2192 svc-rag index \u2192 answer with citations</p>"},{"location":"REFACTORING_ANALYSIS/#8-next-steps","title":"8. NEXT STEPS","text":"<ol> <li>\u2705 Complete this analysis</li> <li>\u2705 Get stakeholder decisions on key questions</li> <li>\u23f3 Create ADRs for key decisions:</li> <li>ADR-001: Platform centralization strategy (Gateway, Identity, Validation, Workflow, Compliance)</li> <li>ADR-002: Suite-level architecture (Single gateway vs per-suite)</li> <li>ADR-003: Database strategy (schema-per-suite + RLS)</li> <li>ADR-004: Shared UI component library</li> <li>ADR-005: PropVerify service migration to platform (OCR, Ledger, RAG)</li> <li>ADR-006: RAG hierarchy &amp; retrieval policy (Platform/Suite/Module/Entity)</li> <li>ADR-007: AI Broker provider policy (Vertex primary; OpenAI dev-only)</li> <li>\u23f3 Create detailed migration plan (phased rollout)</li> <li>\u23f3 Identify breaking changes and migration paths</li> <li>\u23f3 Create prototype refactoring for one module (FedReconcile RAG demo) referencing Platform/Suite/Module scopes + Ledger export</li> </ol>"},{"location":"REFACTORING_ANALYSIS/#appendices","title":"Appendices","text":""},{"location":"REFACTORING_ANALYSIS/#appendix-a-repository-inventory","title":"Appendix A: Repository Inventory","text":""},{"location":"REFACTORING_ANALYSIS/#source-repositories","title":"Source Repositories","text":"<ol> <li><code>/Users/michael/Development/cortx-suites</code> - FedSuite code</li> <li><code>/Users/michael/Development/cortx-platform</code> - Platform services (partial)</li> <li><code>/Users/michael/Development/cortx-designer</code> - BPM Designer</li> <li><code>/Users/michael/Development/cortx-propverify</code> - PropVerify module</li> <li><code>/Users/michael/Development/greenlight</code> - Greenlight module</li> <li><code>/Users/michael/Development/OffermAit</code> - InvestmAit module</li> <li><code>/Users/michael/Development/compliance-scanner</code> - Compliance scanner tool</li> <li><code>/Volumes/Dev Volume/Asset Development/FedTransform</code> - FedTransform (v1)</li> <li><code>/Volumes/Dev Volume/Development/FedTransform</code> - FedTransform (v2?)</li> <li><code>/Volumes/Dev Volume/sinergy_dev/greenlight</code> - Greenlight (alt)</li> <li><code>/Users/michael/Development/deprecated-cortx-development</code> - Legacy code</li> </ol>"},{"location":"REFACTORING_ANALYSIS/#target-repositories","title":"Target Repositories","text":"<ol> <li><code>~/Development/sinergysolutionsllc/cortx-platform</code> - Platform services</li> <li><code>~/Development/sinergysolutionsllc/cortx-designer</code> - BPM Designer</li> <li><code>~/Development/sinergysolutionsllc/cortx-sdks</code> - SDKs</li> <li><code>~/Development/sinergysolutionsllc/cortx-packs</code> - RulePacks &amp; WorkflowPacks</li> <li><code>~/Development/sinergysolutionsllc/cortx-e2e</code> - E2E tests</li> <li><code>~/Development/sinergysolutionsllc/fedsuite</code> - Federal suite</li> <li><code>~/Development/sinergysolutionsllc/corpsuite</code> - Corporate suite</li> <li><code>~/Development/sinergysolutionsllc/medsuite</code> - Healthcare suite</li> <li><code>~/Development/sinergysolutionsllc/govsuite</code> - Government suite</li> </ol> <p>END OF ANALYSIS (IN PROGRESS)</p>"},{"location":"TUTORIAL/","title":"Hello CORTX Tutorial","text":"<p>This tutorial will guide you through an end-to-end demonstration of the CORTX platform.</p>"},{"location":"TUTORIAL/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and docker-compose are installed.</li> <li>You have cloned the <code>cortx-platform</code> repository.</li> </ul>"},{"location":"TUTORIAL/#1-spin-up-the-dev-stack","title":"1. Spin up the dev stack","text":"<p>From the root of the <code>cortx-platform</code> repository, run:</p> <pre><code>docker-compose up -d\n</code></pre> <p>This will start all the CORTX platform services.</p>"},{"location":"TUTORIAL/#2-upload-a-document","title":"2. Upload a document","text":"<p>We will use the OCR service to extract text from a scanned document.</p> <pre><code>curl -X POST -F 'file=@/path/to/your/document.pdf' http://localhost:8137/api/ocr/extract\n</code></pre> <p>This will return a job ID. You can use this job ID to check the status of the OCR job and retrieve the extracted text.</p>"},{"location":"TUTORIAL/#3-ingest-to-rag","title":"3. Ingest to RAG","text":"<p>Once the text has been extracted, you can ingest it into the RAG service.</p> <pre><code>curl -X POST -H \"Content-Type: application/json\" -d '{\n  \"doc_id\": \"my-document\",\n  \"content\": \"&lt;the extracted text&gt;\",\n  \"scope\": \"entity\",\n  \"entity_id\": \"my-entity\"\n}' http://localhost:8138/api/rag/index\n</code></pre>"},{"location":"TUTORIAL/#4-query-hierarchical-context","title":"4. Query hierarchical context","text":"<p>Now you can query the RAG service to retrieve contextual information.</p> <pre><code>curl -X POST -H \"Content-Type: application/json\" -d '{\n  \"query\": \"What is the main topic of my document?\",\n  \"scope\": \"entity\",\n  \"entity_id\": \"my-entity\"\n}' http://localhost:8138/api/rag/query\n</code></pre>"},{"location":"TUTORIAL/#5-execute-a-workflowpack","title":"5. Execute a WorkflowPack","text":"<p>Now we will execute a WorkflowPack that uses the information from the document.</p> <pre><code>curl -X POST -H \"Content-Tye: application/json\" -d '{\n  \"workflow_id\": \"example-workflow\",\n  \"input_data\": {\n    \"doc_id\": \"my-document\"\n  }\n}' http://localhost:8130/api/workflows/execute\n</code></pre>"},{"location":"TUTORIAL/#6-export-ledger-evidence","title":"6. Export ledger evidence","text":"<p>Finally, you can export the ledger evidence for the workflow execution.</p> <pre><code>curl http://localhost:8136/api/ledger/events?since=YYYY-MM-DD\n</code></pre> <p>This will return a list of all the events that have been recorded in the ledger since the specified date.</p>"},{"location":"adrs/","title":"Architecture Decision Records","text":"<p>See the canonical index: ADR-000-index.</p>"},{"location":"adrs/ADR-000-index/","title":"Architecture Decision Records","text":"<p>This is a log of all architecture decision records in CORTX.</p> ADR Number Title Status Date"},{"location":"ai_governance/AI_RULES/","title":"AI Development Rules &amp; Guidelines","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: Platform Architecture Team Classification: Internal</p>"},{"location":"ai_governance/AI_RULES/#purpose","title":"Purpose","text":"<p>This document establishes rules, guidelines, and best practices for AI-assisted development within the CORTX Platform ecosystem. These rules ensure consistent, high-quality, secure, and compliant code generation across all Sinergy Solutions repositories.</p>"},{"location":"ai_governance/AI_RULES/#core-principles","title":"Core Principles","text":""},{"location":"ai_governance/AI_RULES/#1-compliance-first-development","title":"1. Compliance-First Development","text":"<ul> <li>All AI-generated code MUST align with regulatory requirements (FedRAMP, HIPAA, NIST 800-53, SOC 2)</li> <li>Security controls and audit logging are non-negotiable</li> <li>Privacy by design: PII redaction before any LLM processing</li> <li>Immutable audit trails for all critical operations</li> </ul>"},{"location":"ai_governance/AI_RULES/#2-code-quality-standards","title":"2. Code Quality Standards","text":"<ul> <li>Test coverage: Maintain &gt;80% unit test coverage for all new code</li> <li>Type safety: Use strict typing (Python type hints, TypeScript strict mode)</li> <li>Documentation: All public APIs must have OpenAPI/JSDoc comments</li> <li>Error handling: Comprehensive error handling with contextual messages</li> </ul>"},{"location":"ai_governance/AI_RULES/#3-security-first-approach","title":"3. Security-First Approach","text":"<ul> <li>Never include secrets, API keys, or credentials in code</li> <li>All sensitive data must use environment variables or GCP Secret Manager</li> <li>Input validation on all user-provided data</li> <li>Safe operators only (no eval, exec, or code injection vectors)</li> <li>SQL injection prevention: Use parameterized queries exclusively</li> </ul>"},{"location":"ai_governance/AI_RULES/#4-platform-coherence","title":"4. Platform Coherence","text":"<ul> <li>Follow established patterns from existing services</li> <li>Maintain consistency across microservices architecture</li> <li>Respect service boundaries and API contracts</li> <li>Use shared libraries and common utilities</li> </ul>"},{"location":"ai_governance/AI_RULES/#ai-agent-roles-responsibilities","title":"AI Agent Roles &amp; Responsibilities","text":""},{"location":"ai_governance/AI_RULES/#tech-lead-architect","title":"Tech Lead Architect","text":"<p>Context: Cross-repository architecture, platform-wide decisions, API contracts</p> <p>Responsibilities: - Design service interfaces and inter-service communication patterns - Define data models and database schemas - Establish API versioning and backward compatibility strategies - Review and approve architectural decision records (ADRs)</p> <p>Rules: - Always consider multi-tenant implications - Document API contracts in OpenAPI 3.0 format - Ensure services are independently deployable - Plan for horizontal scalability from day one</p>"},{"location":"ai_governance/AI_RULES/#backend-services-developer","title":"Backend Services Developer","text":"<p>Context: FastAPI services, business logic, data access, integrations</p> <p>Responsibilities: - Implement RESTful APIs following OpenAPI specifications - Write database queries with proper indexing - Implement business logic with comprehensive error handling - Create unit and integration tests for all endpoints</p> <p>Rules: - Use FastAPI dependency injection for all shared resources - Implement request/response validation with Pydantic models - Add correlation IDs to all log entries - Include health check and readiness probe endpoints - Never bypass RBAC checks</p>"},{"location":"ai_governance/AI_RULES/#uifrontend-developer","title":"UI/Frontend Developer","text":"<p>Context: Next.js applications, React components, Tailwind CSS, user experience</p> <p>Responsibilities: - Build responsive, accessible user interfaces - Implement client-side state management - Integrate with backend APIs using typed clients - Create reusable component libraries</p> <p>Rules: - Use TypeScript strict mode exclusively - Implement proper error boundaries - Follow WCAG 2.1 AA accessibility standards - Use React Query for server state management - Implement proper loading and error states</p>"},{"location":"ai_governance/AI_RULES/#gcp-deploymentops-engineer","title":"GCP Deployment/Ops Engineer","text":"<p>Context: Cloud infrastructure, Terraform, CI/CD, monitoring, security</p> <p>Responsibilities: - Maintain Terraform infrastructure as code - Configure Cloud Run services with proper resource limits - Set up monitoring, logging, and alerting - Manage secrets and service accounts</p> <p>Rules: - All infrastructure changes must be in Terraform - Use least privilege principle for IAM roles - Enable Cloud Armor for DDoS protection - Configure automatic scaling and health checks - Implement proper backup and disaster recovery</p>"},{"location":"ai_governance/AI_RULES/#quality-assurance-lead","title":"Quality Assurance Lead","text":"<p>Context: Testing strategy, quality metrics, CI/CD pipeline, test automation</p> <p>Responsibilities: - Define and maintain test coverage standards - Create test plans for new features - Review test quality and effectiveness - Track and report quality metrics</p> <p>Rules: - Require tests for all pull requests - Block merges if coverage drops below 80% - Maintain separate test fixtures and utilities - Use pytest for Python, Jest for TypeScript - Implement contract testing for service boundaries</p>"},{"location":"ai_governance/AI_RULES/#code-generation-guidelines","title":"Code Generation Guidelines","text":""},{"location":"ai_governance/AI_RULES/#python-fastapi-services","title":"Python (FastAPI Services)","text":""},{"location":"ai_governance/AI_RULES/#service-structure","title":"Service Structure","text":"<pre><code># REQUIRED: Type hints for all functions\nfrom typing import Optional, List\nfrom pydantic import BaseModel, Field\nfrom fastapi import FastAPI, HTTPException, Depends\n\n# REQUIRED: Structured logging with correlation IDs\nimport structlog\nlogger = structlog.get_logger()\n\n# REQUIRED: Request/Response models with validation\nclass RequestModel(BaseModel):\n    field: str = Field(..., description=\"Field description\")\n    tenant_id: str = Field(..., pattern=\"^[a-z0-9-]+$\")\n\n# REQUIRED: Dependency injection for auth\nasync def verify_token(token: str = Depends(oauth2_scheme)):\n    # Validate JWT, extract claims\n    pass\n\n# REQUIRED: Comprehensive error handling\n@app.post(\"/api/v1/resource\")\nasync def create_resource(\n    request: RequestModel,\n    user=Depends(verify_token)\n):\n    try:\n        logger.info(\n            \"resource.create.start\",\n            tenant_id=request.tenant_id,\n            user_id=user.id\n        )\n        # Implementation\n        return {\"status\": \"success\"}\n    except Exception as e:\n        logger.error(\n            \"resource.create.failed\",\n            error=str(e),\n            tenant_id=request.tenant_id\n        )\n        raise HTTPException(status_code=500, detail=\"Resource creation failed\")\n</code></pre>"},{"location":"ai_governance/AI_RULES/#database-access","title":"Database Access","text":"<pre><code># REQUIRED: Use SQLAlchemy or raw SQL with parameters (never string interpolation)\nfrom sqlalchemy import text\n\nasync def get_user(tenant_id: str, user_id: str):\n    # CORRECT: Parameterized query\n    query = text(\"\"\"\n        SELECT * FROM :tenant_schema.users\n        WHERE user_id = :user_id\n    \"\"\")\n    result = await db.execute(\n        query,\n        {\"tenant_schema\": tenant_id, \"user_id\": user_id}\n    )\n\n    # WRONG: String interpolation (SQL injection risk)\n    # query = f\"SELECT * FROM {tenant_id}.users WHERE user_id = '{user_id}'\"\n</code></pre>"},{"location":"ai_governance/AI_RULES/#testing","title":"Testing","text":"<pre><code># REQUIRED: Test structure with fixtures\nimport pytest\nfrom fastapi.testclient import TestClient\n\n@pytest.fixture\ndef client():\n    return TestClient(app)\n\n@pytest.fixture\ndef mock_auth():\n    # Return mock user context\n    pass\n\ndef test_create_resource_success(client, mock_auth):\n    \"\"\"Test successful resource creation with valid input.\"\"\"\n    response = client.post(\n        \"/api/v1/resource\",\n        json={\"field\": \"value\", \"tenant_id\": \"test-tenant\"},\n        headers={\"Authorization\": f\"Bearer {mock_auth.token}\"}\n    )\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"success\"\n\ndef test_create_resource_unauthorized(client):\n    \"\"\"Test resource creation fails without authentication.\"\"\"\n    response = client.post(\"/api/v1/resource\", json={})\n    assert response.status_code == 401\n</code></pre>"},{"location":"ai_governance/AI_RULES/#typescript-nextjs-sdks","title":"TypeScript (Next.js, SDKs)","text":""},{"location":"ai_governance/AI_RULES/#component-structure","title":"Component Structure","text":"<pre><code>// REQUIRED: Strict TypeScript\ninterface ResourceProps {\n  resourceId: string;\n  tenantId: string;\n  onUpdate?: (resource: Resource) =&gt; void;\n}\n\n// REQUIRED: Error boundaries and loading states\nexport const ResourceComponent: React.FC&lt;ResourceProps&gt; = ({\n  resourceId,\n  tenantId,\n  onUpdate\n}) =&gt; {\n  const { data, isLoading, error } = useQuery({\n    queryKey: ['resource', resourceId],\n    queryFn: () =&gt; api.getResource(resourceId, tenantId)\n  });\n\n  if (isLoading) return &lt;LoadingSpinner /&gt;;\n  if (error) return &lt;ErrorDisplay error={error} /&gt;;\n  if (!data) return &lt;EmptyState /&gt;;\n\n  return (\n    &lt;div className=\"resource-container\"&gt;\n      {/* Implementation */}\n    &lt;/div&gt;\n  );\n};\n</code></pre>"},{"location":"ai_governance/AI_RULES/#api-client","title":"API Client","text":"<pre><code>// REQUIRED: Type-safe API clients\ninterface CortxApiClient {\n  getResource(id: string, tenantId: string): Promise&lt;Resource&gt;;\n  createResource(data: CreateResourceRequest): Promise&lt;Resource&gt;;\n}\n\n// REQUIRED: Error handling with specific error types\nclass ApiError extends Error {\n  constructor(\n    message: string,\n    public statusCode: number,\n    public code: string\n  ) {\n    super(message);\n  }\n}\n\nexport const cortxClient: CortxApiClient = {\n  async getResource(id: string, tenantId: string) {\n    try {\n      const response = await fetch(`/api/v1/resources/${id}`, {\n        headers: {\n          'X-Tenant-ID': tenantId,\n          'Authorization': `Bearer ${getToken()}`\n        }\n      });\n\n      if (!response.ok) {\n        throw new ApiError(\n          'Failed to fetch resource',\n          response.status,\n          'RESOURCE_FETCH_FAILED'\n        );\n      }\n\n      return await response.json();\n    } catch (error) {\n      logger.error('API call failed', { id, tenantId, error });\n      throw error;\n    }\n  }\n};\n</code></pre>"},{"location":"ai_governance/AI_RULES/#rulepackworkflowpack-definitions","title":"RulePack/WorkflowPack Definitions","text":""},{"location":"ai_governance/AI_RULES/#rulepack-json","title":"RulePack (JSON)","text":"<pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"example-validation-v1\",\n    \"version\": \"1.0.0\",\n    \"compliance\": [\"NIST-800-53-AC-3\"],\n    \"created_by\": \"sinergy-platform\",\n    \"created_at\": \"2025-10-01T00:00:00Z\",\n    \"description\": \"Example validation rules for demonstration\"\n  },\n  \"rules\": [\n    {\n      \"rule_id\": \"EXAMPLE-001\",\n      \"type\": \"FATAL\",\n      \"field\": \"user_id\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[a-z0-9_-]{3,64}$\",\n      \"error_message\": \"User ID must be 3-64 characters (lowercase alphanumeric, hyphens, underscores)\"\n    },\n    {\n      \"rule_id\": \"EXAMPLE-002\",\n      \"type\": \"WARNING\",\n      \"field\": \"email\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\",\n      \"error_message\": \"Email format appears invalid\"\n    }\n  ]\n}\n</code></pre>"},{"location":"ai_governance/AI_RULES/#workflowpack-yaml","title":"WorkflowPack (YAML)","text":"<pre><code>workflow_id: example-workflow-v1\nversion: 1.0.0\ndescription: Example workflow demonstrating step types\n\nmetadata:\n  compliance: [SOC2-CC6.1]\n  created_by: sinergy-platform\n  created_at: \"2025-10-01T00:00:00Z\"\n\nsteps:\n  - id: validate_input\n    type: validation\n    config:\n      rulepack: example-validation-v1\n      on_failure: halt\n\n  - id: check_eligibility\n    type: decision\n    config:\n      condition: \"input.status == 'active'\"\n      on_true: process_record\n      on_false: skip_processing\n\n  - id: process_record\n    type: calculation\n    config:\n      formula: \"input.amount * 1.05\"\n      output_field: \"adjusted_amount\"\n\n  - id: ai_review\n    type: ai-inference\n    config:\n      model: gemini-1.5-flash\n      prompt: \"Review this record for anomalies: {{input}}\"\n      max_tokens: 500\n\n  - id: human_approval\n    type: approval\n    config:\n      role: COMPLIANCE_OFFICER\n      timeout_hours: 24\n\n  - id: submit_result\n    type: data-sink\n    config:\n      endpoint: \"https://api.example.com/submit\"\n      method: POST\n      headers:\n        Content-Type: application/json\n</code></pre>"},{"location":"ai_governance/AI_RULES/#ai-model-usage-guidelines","title":"AI Model Usage Guidelines","text":""},{"location":"ai_governance/AI_RULES/#model-selection","title":"Model Selection","text":"<p>Gemini 1.5 Flash (Current Default): - Use for: Quick responses, simple explanations, routine queries - Cost: Low - Latency: 200-500ms - Context window: 1M tokens</p> <p>Gemini 1.5 Pro (High Complexity): - Use for: Complex reasoning, multi-step workflows, code generation - Cost: Medium - Latency: 500-1500ms - Context window: 1M tokens</p> <p>Claude 3.5 Sonnet (Planned): - Use for: Highest quality code generation, complex reasoning - Cost: High - Latency: 1000-2000ms - Context window: 200K tokens</p>"},{"location":"ai_governance/AI_RULES/#rag-retrieval-augmented-generation","title":"RAG (Retrieval-Augmented Generation)","text":"<p>Vector Store Management: - Embed compliance documents (Treasury rules, HIPAA guidelines, NIST controls) - Update embeddings when source documents change - Use 384-dimensional embeddings (sentence-transformers) - Threshold: 0.5 cosine similarity minimum</p> <p>Knowledge Base Documents: - OMB Circular A-136 (Treasury Financial Reporting) - GTAS Validation Rules (204 rules) - HIPAA Security Rule (Technical Safeguards) - NIST 800-53 Rev 5 Control Catalog - FedRAMP Authorization Boundary Guidance - CORTX Platform API Documentation - RulePack/WorkflowPack Schema Definitions</p> <p>Retrieval Strategy:</p> <pre><code># Example RAG retrieval\nasync def get_compliance_context(query: str) -&gt; List[Document]:\n    # Generate query embedding\n    query_embedding = await embedding_model.embed(query)\n\n    # Search vector store\n    results = await vector_store.similarity_search(\n        query_embedding,\n        k=5,  # Top 5 most relevant\n        threshold=0.5  # Minimum similarity\n    )\n\n    # Boost results with keyword matches\n    for result in results:\n        if any(keyword in result.content.lower() for keyword in query.lower().split()):\n            result.score *= 1.2\n\n    return sorted(results, key=lambda r: r.score, reverse=True)\n</code></pre>"},{"location":"ai_governance/AI_RULES/#pii-protection","title":"PII Protection","text":"<p>Always redact before LLM calls: - Social Security Numbers (SSN): XXX-XX-1234 - Credit Card Numbers: *   1234 - Email addresses: ur@domain.com - Phone numbers: () -1234 - IP addresses: ..***.123</p> <p>Redaction Implementation:</p> <pre><code>import re\n\nPII_PATTERNS = {\n    'ssn': r'\\b\\d{3}-\\d{2}-\\d{4}\\b',\n    'credit_card': r'\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b',\n    'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n    'phone': r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n}\n\ndef redact_pii(text: str) -&gt; str:\n    \"\"\"Redact PII before sending to LLM.\"\"\"\n    for pii_type, pattern in PII_PATTERNS.items():\n        text = re.sub(pattern, f'[REDACTED_{pii_type.upper()}]', text)\n    return text\n</code></pre>"},{"location":"ai_governance/AI_RULES/#security-requirements","title":"Security Requirements","text":""},{"location":"ai_governance/AI_RULES/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<p>JWT Token Validation:</p> <pre><code>from jose import jwt, JWTError\n\nasync def verify_jwt(token: str) -&gt; dict:\n    try:\n        payload = jwt.decode(\n            token,\n            SECRET_KEY,\n            algorithms=[\"RS256\"],\n            audience=\"cortx-platform\",\n            issuer=\"identity-service\"\n        )\n\n        # Verify required claims\n        required_claims = ['sub', 'tenant_id', 'roles', 'exp']\n        if not all(claim in payload for claim in required_claims):\n            raise JWTError(\"Missing required claims\")\n\n        return payload\n    except JWTError as e:\n        logger.error(\"JWT validation failed\", error=str(e))\n        raise HTTPException(status_code=401, detail=\"Invalid token\")\n</code></pre> <p>RBAC Enforcement:</p> <pre><code>from enum import Enum\n\nclass Permission(Enum):\n    EXECUTE_WORKFLOW = \"execute:workflows\"\n    CREATE_PACK = \"create:packs\"\n    VIEW_AUDIT_LOGS = \"view:audit_logs\"\n\ndef require_permission(permission: Permission):\n    async def dependency(user=Depends(verify_token)):\n        if permission.value not in user.get('permissions', []):\n            raise HTTPException(\n                status_code=403,\n                detail=f\"Missing required permission: {permission.value}\"\n            )\n        return user\n    return dependency\n\n# Usage\n@app.post(\"/api/v1/workflows/execute\")\nasync def execute_workflow(\n    user=Depends(require_permission(Permission.EXECUTE_WORKFLOW))\n):\n    pass\n</code></pre>"},{"location":"ai_governance/AI_RULES/#input-validation","title":"Input Validation","text":"<p>Always validate user input:</p> <pre><code>from pydantic import BaseModel, Field, validator\n\nclass UserInput(BaseModel):\n    username: str = Field(..., min_length=3, max_length=64, pattern=\"^[a-z0-9_-]+$\")\n    email: str = Field(..., regex=r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n    tenant_id: str\n\n    @validator('tenant_id')\n    def validate_tenant_id(cls, v):\n        if not re.match(r'^[a-z0-9-]+$', v):\n            raise ValueError('Invalid tenant_id format')\n        return v\n\n    class Config:\n        # Reject unknown fields\n        extra = 'forbid'\n</code></pre>"},{"location":"ai_governance/AI_RULES/#secrets-management","title":"Secrets Management","text":"<p>Never hardcode secrets:</p> <pre><code># WRONG\nAPI_KEY = \"sk_live_abc123xyz\"\n\n# CORRECT: Use environment variables\nimport os\nAPI_KEY = os.getenv(\"GEMINI_API_KEY\")\nif not API_KEY:\n    raise ValueError(\"GEMINI_API_KEY environment variable not set\")\n\n# BETTER: Use GCP Secret Manager\nfrom google.cloud import secretmanager\n\ndef get_secret(secret_id: str) -&gt; str:\n    client = secretmanager.SecretManagerServiceClient()\n    name = f\"projects/{PROJECT_ID}/secrets/{secret_id}/versions/latest\"\n    response = client.access_secret_version(request={\"name\": name})\n    return response.payload.data.decode(\"UTF-8\")\n\nAPI_KEY = get_secret(\"gemini-api-key\")\n</code></pre>"},{"location":"ai_governance/AI_RULES/#audit-logging-requirements","title":"Audit Logging Requirements","text":""},{"location":"ai_governance/AI_RULES/#log-all-critical-events","title":"Log All Critical Events","text":"<p>Required fields in every audit log: - <code>timestamp</code>: ISO 8601 format - <code>event_type</code>: Descriptive event name (e.g., \"workflow_executed\") - <code>tenant_id</code>: Multi-tenant isolation - <code>user_id</code>: Actor performing action - <code>session_id</code>: Session correlation - <code>correlation_id</code>: Request tracing - <code>status</code>: success/failure - <code>details</code>: Event-specific metadata - <code>compliance_tags</code>: Applicable frameworks</p> <p>Example implementation:</p> <pre><code>import structlog\nfrom datetime import datetime\n\nlogger = structlog.get_logger()\n\nasync def log_audit_event(\n    event_type: str,\n    tenant_id: str,\n    user_id: str,\n    session_id: str,\n    correlation_id: str,\n    status: str,\n    details: dict,\n    compliance_tags: List[str]\n):\n    logger.info(\n        event_type,\n        timestamp=datetime.utcnow().isoformat(),\n        tenant_id=tenant_id,\n        user_id=user_id,\n        session_id=session_id,\n        correlation_id=correlation_id,\n        status=status,\n        details=details,\n        compliance_tags=compliance_tags\n    )\n\n    # Also write to compliance service for immutable storage\n    await compliance_service.store_audit_log({\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"event_type\": event_type,\n        \"tenant_id\": tenant_id,\n        \"user_id\": user_id,\n        \"session_id\": session_id,\n        \"correlation_id\": correlation_id,\n        \"status\": status,\n        \"details\": details,\n        \"compliance_tags\": compliance_tags\n    })\n</code></pre>"},{"location":"ai_governance/AI_RULES/#testing-requirements","title":"Testing Requirements","text":""},{"location":"ai_governance/AI_RULES/#coverage-targets","title":"Coverage Targets","text":"<ul> <li>Unit tests: &gt;80% line coverage</li> <li>Integration tests: All service-to-service interactions</li> <li>E2E tests: Critical user journeys</li> <li>Contract tests: All API endpoints</li> </ul>"},{"location":"ai_governance/AI_RULES/#test-structure","title":"Test Structure","text":"<p>Python (pytest):</p> <pre><code># tests/unit/test_validation_service.py\nimport pytest\nfrom app.services.validation import validate_rulepack\n\nclass TestValidationService:\n    \"\"\"Unit tests for RulePack validation service.\"\"\"\n\n    @pytest.fixture\n    def sample_rulepack(self):\n        return {\n            \"metadata\": {\"pack_id\": \"test-v1\", \"version\": \"1.0.0\"},\n            \"rules\": [\n                {\n                    \"rule_id\": \"TEST-001\",\n                    \"type\": \"FATAL\",\n                    \"field\": \"amount\",\n                    \"operator\": \"&gt;\",\n                    \"value\": 0,\n                    \"error_message\": \"Amount must be positive\"\n                }\n            ]\n        }\n\n    @pytest.fixture\n    def sample_data(self):\n        return {\"amount\": 100, \"currency\": \"USD\"}\n\n    def test_validate_rulepack_success(self, sample_rulepack, sample_data):\n        \"\"\"Test successful validation with valid data.\"\"\"\n        result = validate_rulepack(sample_rulepack, sample_data)\n        assert result.is_valid\n        assert len(result.violations) == 0\n\n    def test_validate_rulepack_fatal_error(self, sample_rulepack):\n        \"\"\"Test validation fails with FATAL error on negative amount.\"\"\"\n        invalid_data = {\"amount\": -50, \"currency\": \"USD\"}\n        result = validate_rulepack(sample_rulepack, invalid_data)\n        assert not result.is_valid\n        assert len(result.violations) == 1\n        assert result.violations[0].severity == \"FATAL\"\n</code></pre> <p>TypeScript (Jest):</p> <pre><code>// tests/unit/api-client.test.ts\nimport { cortxClient } from '@/lib/api-client';\nimport { rest } from 'msw';\nimport { setupServer } from 'msw/node';\n\nconst server = setupServer(\n  rest.get('/api/v1/resources/:id', (req, res, ctx) =&gt; {\n    return res(ctx.json({ id: req.params.id, status: 'active' }));\n  })\n);\n\nbeforeAll(() =&gt; server.listen());\nafterEach(() =&gt; server.resetHandlers());\nafterAll(() =&gt; server.close());\n\ndescribe('CortxApiClient', () =&gt; {\n  it('should fetch resource successfully', async () =&gt; {\n    const resource = await cortxClient.getResource('test-123', 'tenant-1');\n    expect(resource.id).toBe('test-123');\n    expect(resource.status).toBe('active');\n  });\n\n  it('should throw ApiError on 404', async () =&gt; {\n    server.use(\n      rest.get('/api/v1/resources/:id', (req, res, ctx) =&gt; {\n        return res(ctx.status(404));\n      })\n    );\n\n    await expect(\n      cortxClient.getResource('missing', 'tenant-1')\n    ).rejects.toThrow('Failed to fetch resource');\n  });\n});\n</code></pre>"},{"location":"ai_governance/AI_RULES/#documentation-requirements","title":"Documentation Requirements","text":""},{"location":"ai_governance/AI_RULES/#code-documentation","title":"Code Documentation","text":"<p>Python docstrings (Google style):</p> <pre><code>def execute_workflow(\n    workflow_id: str,\n    tenant_id: str,\n    input_data: dict,\n    user_context: dict\n) -&gt; WorkflowResult:\n    \"\"\"Execute a WorkflowPack with the provided input data.\n\n    Args:\n        workflow_id: Unique identifier for the workflow (e.g., \"gtas-monthly-v1\")\n        tenant_id: Tenant identifier for multi-tenant isolation\n        input_data: Input data to process through the workflow\n        user_context: User authentication and authorization context\n\n    Returns:\n        WorkflowResult containing execution status, outputs, and audit trail\n\n    Raises:\n        WorkflowNotFoundError: If workflow_id does not exist\n        ValidationError: If input_data fails schema validation\n        PermissionError: If user lacks execute:workflows permission\n\n    Example:\n        &gt;&gt;&gt; result = execute_workflow(\n        ...     workflow_id=\"gtas-monthly-v1\",\n        ...     tenant_id=\"agency-dod-001\",\n        ...     input_data={\"records\": [...]},\n        ...     user_context={\"user_id\": \"jane.doe\", \"roles\": [\"SUITE_OPERATOR\"]}\n        ... )\n        &gt;&gt;&gt; print(result.status)\n        'completed'\n    \"\"\"\n    pass\n</code></pre> <p>TypeScript JSDoc:</p> <pre><code>/**\n * Execute a WorkflowPack with the provided input data.\n *\n * @param workflowId - Unique identifier for the workflow\n * @param tenantId - Tenant identifier for multi-tenant isolation\n * @param inputData - Input data to process through the workflow\n * @returns Promise resolving to WorkflowResult\n * @throws {WorkflowNotFoundError} If workflow_id does not exist\n * @throws {ValidationError} If input_data fails schema validation\n *\n * @example\n * ```typescript\n * const result = await executeWorkflow(\n *   'gtas-monthly-v1',\n *   'agency-dod-001',\n *   { records: [...] }\n * );\n * console.log(result.status); // 'completed'\n * ```\n */\nexport async function executeWorkflow(\n  workflowId: string,\n  tenantId: string,\n  inputData: unknown\n): Promise&lt;WorkflowResult&gt; {\n  // Implementation\n}\n</code></pre>"},{"location":"ai_governance/AI_RULES/#api-documentation","title":"API Documentation","text":"<p>All endpoints must have OpenAPI specs:</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI(\n    title=\"CORTX Validation Service\",\n    description=\"RulePack execution and data validation\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    openapi_url=\"/openapi.json\"\n)\n\nclass ExecuteRequest(BaseModel):\n    \"\"\"Request model for RulePack execution.\"\"\"\n    rulepack_id: str = Field(..., description=\"RulePack identifier\")\n    data: dict = Field(..., description=\"Data to validate\")\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"rulepack_id\": \"federal-gtas-v1\",\n                \"data\": {\"TAS\": \"012-3456\", \"amount\": 1000.00}\n            }\n        }\n\n@app.post(\n    \"/api/v1/validate\",\n    response_model=ValidationResult,\n    summary=\"Execute RulePack validation\",\n    description=\"Validate data against a RulePack and return violations\",\n    tags=[\"Validation\"]\n)\nasync def execute_rulepack(request: ExecuteRequest):\n    \"\"\"Execute RulePack validation endpoint.\"\"\"\n    pass\n</code></pre>"},{"location":"ai_governance/AI_RULES/#performance-guidelines","title":"Performance Guidelines","text":""},{"location":"ai_governance/AI_RULES/#database-queries","title":"Database Queries","text":"<ul> <li>Use connection pooling (min=5, max=20 connections)</li> <li>Index all foreign keys and frequently queried columns</li> <li>Avoid N+1 queries (use eager loading)</li> <li>Batch operations for bulk inserts/updates</li> <li>Limit result sets (default max=1000 records)</li> </ul>"},{"location":"ai_governance/AI_RULES/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Cache frequently accessed configuration (TTL: 5 minutes)</li> <li>Cache RulePack/WorkflowPack definitions (TTL: 1 hour, invalidate on update)</li> <li>Use Redis for distributed caching</li> <li>Implement cache warming for critical paths</li> </ul>"},{"location":"ai_governance/AI_RULES/#api-rate-limiting","title":"API Rate Limiting","text":"<ul> <li>Default: 100 requests/second per tenant</li> <li>Burst: 200 requests/second (10 second window)</li> <li>Use Redis for distributed rate limiting</li> <li>Return <code>Retry-After</code> header on 429 responses</li> </ul>"},{"location":"ai_governance/AI_RULES/#deployment-checklist","title":"Deployment Checklist","text":"<p>Before deploying AI-generated code:</p> <ul> <li>[ ] All tests pass (<code>make test</code>)</li> <li>[ ] Coverage meets threshold (&gt;80%)</li> <li>[ ] Linting passes with no errors</li> <li>[ ] Security scan passes (no critical vulnerabilities)</li> <li>[ ] OpenAPI documentation generated</li> <li>[ ] Environment variables documented in <code>.env.example</code></li> <li>[ ] Secrets stored in GCP Secret Manager</li> <li>[ ] Audit logging implemented for critical operations</li> <li>[ ] RBAC checks in place for protected endpoints</li> <li>[ ] Database migrations tested (up and down)</li> <li>[ ] Performance tested (load testing for high-volume endpoints)</li> <li>[ ] Monitoring dashboards updated</li> <li>[ ] Runbook updated for ops team</li> </ul>"},{"location":"ai_governance/AI_RULES/#common-patterns-anti-patterns","title":"Common Patterns &amp; Anti-Patterns","text":""},{"location":"ai_governance/AI_RULES/#patterns","title":"Patterns \u2705","text":"<p>Multi-Tenant Isolation:</p> <pre><code># Always scope queries to tenant\nasync def get_resources(tenant_id: str):\n    return await db.execute(\n        text(f\"SELECT * FROM {tenant_id}.resources\")\n    )\n</code></pre> <p>Correlation IDs:</p> <pre><code>import uuid\n\ncorrelation_id = str(uuid.uuid4())\nlogger.info(\"request.start\", correlation_id=correlation_id)\n# Pass correlation_id through all service calls\n</code></pre> <p>Circuit Breaker Pattern:</p> <pre><code>from circuitbreaker import circuit\n\n@circuit(failure_threshold=5, recovery_timeout=60)\nasync def call_external_api():\n    # External API call\n    pass\n</code></pre>"},{"location":"ai_governance/AI_RULES/#anti-patterns","title":"Anti-Patterns \u274c","text":"<p>Global State:</p> <pre><code># WRONG: Mutable global state\ncurrent_user = None\n\n# CORRECT: Dependency injection\ndef get_current_user(token: str = Depends(oauth2_scheme)):\n    pass\n</code></pre> <p>Blocking I/O:</p> <pre><code># WRONG: Blocking file read\nwith open('file.txt') as f:\n    data = f.read()\n\n# CORRECT: Async I/O\nimport aiofiles\nasync with aiofiles.open('file.txt') as f:\n    data = await f.read()\n</code></pre> <p>Hardcoded Configuration:</p> <pre><code># WRONG\nDATABASE_URL = \"postgresql://localhost/cortx\"\n\n# CORRECT\nDATABASE_URL = os.getenv(\"DATABASE_URL\")\n</code></pre>"},{"location":"ai_governance/AI_RULES/#continuous-improvement","title":"Continuous Improvement","text":""},{"location":"ai_governance/AI_RULES/#feedback-loop","title":"Feedback Loop","text":"<ul> <li>Monitor AI-generated code quality metrics</li> <li>Track bugs originating from AI-generated code</li> <li>Regularly update prompts based on common issues</li> <li>Maintain library of high-quality examples</li> </ul>"},{"location":"ai_governance/AI_RULES/#knowledge-base-updates","title":"Knowledge Base Updates","text":"<ul> <li>Update RAG vector store when:</li> <li>New compliance rules published</li> <li>Platform APIs change</li> <li>New patterns established</li> <li>Security vulnerabilities discovered</li> </ul>"},{"location":"ai_governance/AI_RULES/#version-control","title":"Version Control","text":"<ul> <li>Tag all AI-generated code with agent role</li> <li>Include reasoning in commit messages</li> <li>Link to relevant ADRs and documentation</li> <li>Review AI suggestions before committing</li> </ul>"},{"location":"ai_governance/AI_RULES/#enforcement","title":"Enforcement","text":"<p>All pull requests must: 1. Pass automated CI/CD checks 2. Meet code coverage requirements 3. Include tests for new functionality 4. Pass security scanning 5. Be reviewed by human developer 6. Follow these AI development rules</p> <p>Violations will result in: - PR rejection - Required remediation - Agent prompt refinement - Documentation updates</p>"},{"location":"ai_governance/AI_RULES/#contact-support","title":"Contact &amp; Support","text":"<p>Questions about these rules? - Platform Architecture Team: architecture@sinergysolutions.ai - Security Officer: security@sinergysolutions.ai - Slack: #ai-development-guidelines</p> <p>Propose changes: - Create GitHub issue in <code>sinergysolutionsllc</code> org - Tag with <code>ai-governance</code> - Request review from architecture team</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Review Cycle: Quarterly - Next Review: 2026-01-01 - Approvers: Platform Architecture Team</p>"},{"location":"ai_governance/FOCUS/","title":"Platform Development Focus &amp; Priorities","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: Executive Leadership &amp; Product Team Classification: Internal</p>"},{"location":"ai_governance/FOCUS/#purpose","title":"Purpose","text":"<p>This document defines the current strategic priorities, constraints, and focus areas for the CORTX Platform development. It serves as a guidepost for AI-assisted development, ensuring that all code generation and architectural decisions align with business objectives and resource constraints.</p>"},{"location":"ai_governance/FOCUS/#current-phase-phase-2-q4-2025-q2-2026","title":"Current Phase: Phase 2 (Q4 2025 - Q2 2026)","text":""},{"location":"ai_governance/FOCUS/#phase-overview","title":"Phase Overview","text":"<p>Status: Active Development Timeline: October 2025 - June 2026 Primary Goal: Achieve production readiness for multi-tenant SaaS platform with FedRAMP/HIPAA compliance</p> <p>Key Milestones: - Q4 2025: AI model expansion, BPM Designer RAG enhancements - Q1 2026: HIPAA 3rd party audit completion, CorpSuite PropVerify production - Q2 2026: Pack Marketplace MVP, SOC 2 Type II audit</p>"},{"location":"ai_governance/FOCUS/#strategic-priorities-ranked","title":"Strategic Priorities (Ranked)","text":""},{"location":"ai_governance/FOCUS/#1-compliance-security-critical","title":"1. Compliance &amp; Security (CRITICAL)","text":"<p>Priority Level: P0 Rationale: Required for enterprise sales and government contracts</p> <p>Focus Areas: - Complete HIPAA 3rd party audit (Q1 2026 deadline) - Achieve 175/325 NIST 800-53 controls (Phase I FedRAMP) - SOC 2 Type II readiness (audit scheduled Q2 2026) - Continuous compliance monitoring automation</p> <p>Active Work: - Implementing remaining HIPAA safeguards (SI-3, SI-4, SI-7) - Penetration testing preparation (scheduled Q1 2026) - Evidence collection automation for compliance reports - Audit trail immutability verification</p> <p>Constraints: - No shortcuts on security controls - All compliance work must be documented - Evidence collection is mandatory for every control - Security changes require architecture review</p> <p>AI Development Guidance: - Always implement audit logging for critical operations - Include compliance tags in all generated code - Follow NIST 800-53 control requirements - Generate evidence artifacts automatically</p>"},{"location":"ai_governance/FOCUS/#2-platform-stability-performance-high","title":"2. Platform Stability &amp; Performance (HIGH)","text":"<p>Priority Level: P1 Rationale: Production reliability is essential for customer trust</p> <p>Focus Areas: - Achieve 99.9% uptime SLA - Reduce API latency (p99 &lt;500ms target) - Improve test coverage from 78% to &gt;85% - Eliminate critical bugs in production</p> <p>Active Work: - Load testing for high-volume workflows (1M+ records) - Database query optimization (indexing, connection pooling) - Circuit breaker implementation for external services - Comprehensive error handling and recovery</p> <p>Constraints: - No breaking API changes without migration path - All changes require backwards compatibility - Performance regression tests required - Monitoring dashboards must be updated</p> <p>AI Development Guidance: - Generate performance tests for high-volume operations - Include proper error handling and retries - Use async/await for I/O-bound operations - Implement connection pooling and caching</p>"},{"location":"ai_governance/FOCUS/#3-ai-model-expansion-high","title":"3. AI Model Expansion (HIGH)","text":"<p>Priority Level: P1 Rationale: Multi-model support reduces vendor lock-in and improves quality</p> <p>Focus Areas: - Integrate Claude 3.5 Sonnet for code generation - Add GPT-4 Turbo for complex reasoning - Implement AWS Bedrock for enterprise customers - Enhance RAG with compliance knowledge base</p> <p>Active Work: - Model router implementation (cost/latency/compliance optimization) - PII redaction before all LLM calls - RAG vector store updates with Treasury/HIPAA documents - Prompt template management system</p> <p>Constraints: - PII must be redacted before LLM processing - Model costs must be tracked per tenant - Fallback models required for high availability - Compliance approval needed for new models</p> <p>AI Development Guidance: - Abstract model selection behind router interface - Implement graceful degradation if primary model fails - Log all LLM calls with prompt hashes - Cache common responses to reduce costs</p>"},{"location":"ai_governance/FOCUS/#4-pack-marketplace-development-medium","title":"4. Pack Marketplace Development (MEDIUM)","text":"<p>Priority Level: P2 Rationale: Ecosystem growth drives network effects and revenue</p> <p>Focus Areas: - Launch Pack Marketplace MVP (Q2 2026) - Implement certification process (3 tiers: Official, Certified, Community) - Define revenue model (70/30 split for certified packs) - Build discovery and recommendation engine</p> <p>Active Work: - Pack versioning and dependency management - Certification workflow (review \u2192 compliance \u2192 testing \u2192 approval) - Marketplace UI/UX design - Revenue tracking and payout automation</p> <p>Constraints: - Official packs must be free (government funded) - Certification requires thorough testing - No breaking changes to pack schemas - License compatibility verification required</p> <p>AI Development Guidance: - Generate pack templates for common use cases - Create validation tools for pack authoring - Build recommendation system based on tenant context - Automate certification test generation</p>"},{"location":"ai_governance/FOCUS/#5-corpsuite-production-readiness-medium","title":"5. CorpSuite Production Readiness (MEDIUM)","text":"<p>Priority Level: P2 Rationale: Diversify revenue beyond federal customers</p> <p>Focus Areas: - PropVerify title verification production launch - Maryland SDAT integration (AUP compliance) - Greenlight opportunity analysis module - InvestMait investment tracking</p> <p>Active Work: - SDAT data licensing and access controls - Human-in-the-loop approval for sensitive data - PropVerify UI/UX refinement - Performance optimization for bulk property searches</p> <p>Constraints: - SDAT AUP restrictions (no automated scraping) - Human verification required for critical decisions - Rate limiting to respect SDAT terms - Privacy controls for property owner data</p> <p>AI Development Guidance: - Implement SDAT API integration with rate limiting - Generate approval workflows for sensitive operations - Create property validation RulePacks - Build AI-assisted property analysis tools</p>"},{"location":"ai_governance/FOCUS/#6-cross-suite-orchestration-medium","title":"6. Cross-Suite Orchestration (MEDIUM)","text":"<p>Priority Level: P2 Rationale: Enable complex workflows spanning multiple suites</p> <p>Focus Areas: - Implement saga pattern for distributed transactions - Event-driven architecture (Redis \u2192 Kafka migration) - Cross-suite data sharing with tenant isolation - Workflow orchestration improvements</p> <p>Active Work: - Saga coordinator service design - Event schema registry - Compensation logic for failed transactions - Cross-suite integration testing</p> <p>Constraints: - Maintain tenant isolation across suites - Ensure ACID properties for critical workflows - No tight coupling between suites - Event versioning for backwards compatibility</p> <p>AI Development Guidance: - Generate saga workflows with compensation logic - Implement event handlers with idempotency - Create cross-suite integration tests - Build workflow visualization tools</p>"},{"location":"ai_governance/FOCUS/#current-constraints","title":"Current Constraints","text":""},{"location":"ai_governance/FOCUS/#technical-constraints","title":"Technical Constraints","text":"<p>Infrastructure: - GCP Cloud Run is primary deployment target - PostgreSQL for persistence (Supabase managed) - Redis for event bus (planned Kafka migration in Phase 3) - Cloud Storage for artifacts - Terraform for all infrastructure changes</p> <p>Technology Stack: - Python 3.11+ for backend services (FastAPI) - TypeScript/Next.js 14 for frontend - Node 20+ for TypeScript projects - pnpm for package management</p> <p>Compliance Requirements: - FedRAMP Phase I (175 controls) by Q4 2026 - HIPAA audit Q1 2026 - SOC 2 Type II audit Q2 2026 - NIST 800-53 Rev 5 continuous compliance</p>"},{"location":"ai_governance/FOCUS/#resource-constraints","title":"Resource Constraints","text":"<p>Team Size: - 3 full-time engineers - 1 compliance officer (part-time) - 1 product manager (part-time) - AI-assisted development for velocity</p> <p>Budget: - Cloud spend limit: $5k/month - AI model costs: $1k/month - Third-party audits: $50k budgeted - Infrastructure as priority investment</p> <p>Time Constraints: - HIPAA audit deadline: Q1 2026 (non-negotiable) - SOC 2 audit: Q2 2026 (scheduled) - FedRAMP ATO target: Q4 2026 (aggressive)</p>"},{"location":"ai_governance/FOCUS/#business-constraints","title":"Business Constraints","text":"<p>Customer Commitments: - FedSuite production uptime: 99.9% - GTAS reconciliation accuracy: 100% - Support SLA: 4-hour response for P1 issues</p> <p>Regulatory Requirements: - No PII in LLM training data - 7-year audit log retention - Right to deletion (GDPR compliance) - Data residency (US-only for government)</p>"},{"location":"ai_governance/FOCUS/#areas-to-avoid-de-prioritized","title":"Areas to Avoid (De-Prioritized)","text":""},{"location":"ai_governance/FOCUS/#1-international-expansion","title":"1. International Expansion","text":"<p>Status: Phase 4 (2027+) Reason: Focus on US market, regulatory complexity</p> <p>Do Not: - Build multi-language support - Implement GDPR-specific features beyond basics - Create region-specific compliance packs - Plan for international data residency</p>"},{"location":"ai_governance/FOCUS/#2-mobile-applications","title":"2. Mobile Applications","text":"<p>Status: Not on roadmap Reason: Web-first approach, limited resources</p> <p>Do Not: - Create native iOS/Android apps - Build mobile-specific APIs - Optimize for mobile UI/UX - Invest in mobile testing infrastructure</p>"},{"location":"ai_governance/FOCUS/#3-on-premises-deployment","title":"3. On-Premises Deployment","text":"<p>Status: Phase 4 (2027+), enterprise-only Reason: SaaS-first model, complexity</p> <p>Do Not: - Build on-prem installation tools - Create air-gapped deployment options - Support legacy infrastructure - Invest in on-prem documentation (yet)</p>"},{"location":"ai_governance/FOCUS/#4-advanced-ai-features","title":"4. Advanced AI Features","text":"<p>Status: Phase 3+ Reason: Core capabilities first</p> <p>Do Not: - Fine-tune custom LLMs - Build AI model training pipelines - Implement reinforcement learning - Create AI explainability dashboards (advanced)</p>"},{"location":"ai_governance/FOCUS/#5-blockchaindistributed-ledger","title":"5. Blockchain/Distributed Ledger","text":"<p>Status: Research phase only Reason: Regulatory uncertainty, complexity</p> <p>Do Not: - Implement blockchain audit trails - Create cryptocurrency payment options - Build distributed consensus mechanisms - Invest in blockchain infrastructure</p>"},{"location":"ai_governance/FOCUS/#decision-making-framework","title":"Decision-Making Framework","text":"<p>When prioritizing new features or technical debt:</p>"},{"location":"ai_governance/FOCUS/#high-priority-do-now","title":"High Priority (Do Now)","text":"<ul> <li>Critical security vulnerabilities</li> <li>Compliance blockers (HIPAA, FedRAMP, SOC 2)</li> <li>Production outages or data loss risks</li> <li>Customer-impacting bugs (P0/P1)</li> </ul>"},{"location":"ai_governance/FOCUS/#medium-priority-schedule","title":"Medium Priority (Schedule)","text":"<ul> <li>Performance improvements with measurable impact</li> <li>Technical debt reducing development velocity</li> <li>Features with committed customer contracts</li> <li>Scalability improvements for known limits</li> </ul>"},{"location":"ai_governance/FOCUS/#low-priority-backlog","title":"Low Priority (Backlog)","text":"<ul> <li>Nice-to-have features without customer demand</li> <li>Speculative optimizations</li> <li>Aesthetic improvements without UX impact</li> <li>Experimental technologies without clear ROI</li> </ul>"},{"location":"ai_governance/FOCUS/#defer-not-now","title":"Defer (Not Now)","text":"<ul> <li>International expansion features</li> <li>Mobile applications</li> <li>On-premises deployment (non-enterprise)</li> <li>Unproven AI techniques</li> </ul>"},{"location":"ai_governance/FOCUS/#quality-gates","title":"Quality Gates","text":"<p>All code (AI-generated or human-written) must meet:</p>"},{"location":"ai_governance/FOCUS/#pre-commit","title":"Pre-Commit","text":"<ul> <li>[ ] Linting passes (ruff for Python, eslint for TypeScript)</li> <li>[ ] Type checking passes (mypy, TypeScript strict)</li> <li>[ ] Unit tests written for new code</li> <li>[ ] Test coverage &gt;80% for modified files</li> </ul>"},{"location":"ai_governance/FOCUS/#pre-merge","title":"Pre-Merge","text":"<ul> <li>[ ] All tests pass in CI/CD</li> <li>[ ] Code review approved by human developer</li> <li>[ ] Security scan passes (Snyk, Trivy)</li> <li>[ ] OpenAPI documentation updated (if API changes)</li> <li>[ ] No new critical or high-severity vulnerabilities</li> </ul>"},{"location":"ai_governance/FOCUS/#pre-deploy","title":"Pre-Deploy","text":"<ul> <li>[ ] Integration tests pass</li> <li>[ ] Load testing completed (for high-volume features)</li> <li>[ ] Monitoring dashboards updated</li> <li>[ ] Runbook updated for ops team</li> <li>[ ] Feature flags configured (if applicable)</li> <li>[ ] Rollback plan documented</li> </ul>"},{"location":"ai_governance/FOCUS/#communication-channels","title":"Communication Channels","text":""},{"location":"ai_governance/FOCUS/#daily-standup-async","title":"Daily Standup (Async)","text":"<ul> <li>When: 9 AM ET daily</li> <li>Where: Slack #platform-daily</li> <li>Format: What I did, what I'm doing, blockers</li> </ul>"},{"location":"ai_governance/FOCUS/#weekly-planning","title":"Weekly Planning","text":"<ul> <li>When: Monday 10 AM ET</li> <li>Where: Google Meet</li> <li>Format: Review priorities, assign work, address blockers</li> </ul>"},{"location":"ai_governance/FOCUS/#sprint-retrospective","title":"Sprint Retrospective","text":"<ul> <li>When: Every 2 weeks (Friday)</li> <li>Where: Google Meet</li> <li>Format: What went well, what to improve, action items</li> </ul>"},{"location":"ai_governance/FOCUS/#architecture-review","title":"Architecture Review","text":"<ul> <li>When: As needed (scheduled ad-hoc)</li> <li>Where: Google Meet + ADR documentation</li> <li>Format: Present proposal, discuss tradeoffs, document decision</li> </ul>"},{"location":"ai_governance/FOCUS/#success-metrics-q4-2025-q2-2026","title":"Success Metrics (Q4 2025 - Q2 2026)","text":""},{"location":"ai_governance/FOCUS/#compliance","title":"Compliance","text":"<ul> <li>[ ] HIPAA audit completed with no major findings (Q1 2026)</li> <li>[ ] 175/325 NIST 800-53 controls implemented and evidenced</li> <li>[ ] SOC 2 Type II audit initiated (Q2 2026)</li> <li>[ ] Zero compliance-related security incidents</li> </ul>"},{"location":"ai_governance/FOCUS/#performance","title":"Performance","text":"<ul> <li>[ ] 99.9% uptime (monthly)</li> <li>[ ] API p99 latency &lt;500ms</li> <li>[ ] Pack execution: 1M records in &lt;30 seconds</li> <li>[ ] Test coverage &gt;85%</li> </ul>"},{"location":"ai_governance/FOCUS/#product","title":"Product","text":"<ul> <li>[ ] Pack Marketplace MVP launched (Q2 2026)</li> <li>[ ] 3+ AI models integrated (Gemini, Claude, GPT-4)</li> <li>[ ] CorpSuite PropVerify in production</li> <li>[ ] 50+ certified RulePacks/WorkflowPacks</li> </ul>"},{"location":"ai_governance/FOCUS/#business","title":"Business","text":"<ul> <li>[ ] 50 total tenants (up from 12)</li> <li>[ ] 75% customer retention rate</li> <li>[ ] 4-hour P1 support SLA maintained</li> <li>[ ] $500k ARR (annual recurring revenue)</li> </ul>"},{"location":"ai_governance/FOCUS/#quarterly-review-process","title":"Quarterly Review Process","text":"<p>Schedule: Last week of each quarter Participants: Executive team, product manager, tech lead Agenda: 1. Review progress against success metrics 2. Assess strategic priorities (re-rank if needed) 3. Identify new constraints or blockers 4. Update focus areas for next quarter 5. Document decisions in this file</p> <p>Next Review: December 30, 2025</p>"},{"location":"ai_governance/FOCUS/#how-ai-agents-should-use-this-document","title":"How AI Agents Should Use This Document","text":""},{"location":"ai_governance/FOCUS/#before-generating-code","title":"Before Generating Code","text":"<ol> <li>Check if the feature aligns with current priorities (1-6)</li> <li>Verify it doesn't conflict with constraints</li> <li>Ensure it's not in the \"avoid\" list</li> <li>Confirm compliance requirements are understood</li> </ol>"},{"location":"ai_governance/FOCUS/#during-development","title":"During Development","text":"<ol> <li>Reference success metrics for quality targets</li> <li>Apply appropriate quality gates</li> <li>Consider resource constraints (cost, time, team)</li> <li>Follow decision-making framework for tradeoffs</li> </ol>"},{"location":"ai_governance/FOCUS/#when-uncertain","title":"When Uncertain","text":"<ol> <li>Propose solution with rationale</li> <li>Highlight potential conflicts with priorities</li> <li>Suggest alternatives if constraints violated</li> <li>Request human review for strategic decisions</li> </ol>"},{"location":"ai_governance/FOCUS/#document-maintenance","title":"Document Maintenance","text":"<p>Update Frequency: Monthly or when priorities shift Owner: Product Manager + Tech Lead Review: All engineers + stakeholders</p> <p>Change Log: - 2025-10-01: Initial version for Phase 2 - (Future updates will be logged here)</p>"},{"location":"ai_governance/FOCUS/#contact","title":"Contact","text":"<p>Questions about priorities: - Product Manager: product@sinergysolutions.ai - Tech Lead: tech-lead@sinergysolutions.ai</p> <p>Propose priority changes: - Create GitHub issue with <code>priority-change</code> label - Include business justification and impact analysis - Tag product manager for review</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Next Review: 2025-11-01 - Approvers: Executive Leadership Team</p>"},{"location":"ai_governance/MODEL_SELECTION/","title":"AI Model Selection &amp; Routing Strategy","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: AI Platform Team Classification: Internal</p>"},{"location":"ai_governance/MODEL_SELECTION/#purpose","title":"Purpose","text":"<p>This document defines the strategy for selecting, routing, and managing AI models across the CORTX Platform. It establishes criteria for model selection based on use case, cost, latency, quality, and compliance requirements.</p>"},{"location":"ai_governance/MODEL_SELECTION/#model-inventory","title":"Model Inventory","text":""},{"location":"ai_governance/MODEL_SELECTION/#currently-supported","title":"Currently Supported","text":""},{"location":"ai_governance/MODEL_SELECTION/#google-gemini-15-flash","title":"Google Gemini 1.5 Flash","text":"<p>Provider: Google Cloud Vertex AI Status: \u2705 Production (Default)</p> <p>Specifications: - Context Window: 1M tokens - Output Limit: 8,192 tokens - Latency: p50: 250ms, p95: 500ms, p99: 800ms - Cost: $0.00001875/1K input tokens, $0.000075/1K output tokens - Strengths: Fast, cost-effective, good for routine tasks - Limitations: Lower reasoning quality for complex tasks</p> <p>Use Cases: - RulePack validation explanations - Simple Q&amp;A (platform documentation) - Quick compliance lookups - Pack template generation - Basic code suggestions</p> <p>Configuration:</p> <pre><code>GEMINI_FLASH_CONFIG = {\n    \"model\": \"gemini-1.5-flash\",\n    \"temperature\": 0.0,  # Deterministic for reproducibility\n    \"top_p\": 0.95,\n    \"top_k\": 40,\n    \"max_output_tokens\": 2048,\n    \"safety_settings\": {\n        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    }\n}\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#google-gemini-15-pro","title":"Google Gemini 1.5 Pro","text":"<p>Provider: Google Cloud Vertex AI Status: \u2705 Production (Premium)</p> <p>Specifications: - Context Window: 1M tokens - Output Limit: 8,192 tokens - Latency: p50: 600ms, p95: 1200ms, p99: 1800ms - Cost: $0.000125/1K input tokens, $0.000375/1K output tokens - Strengths: Higher quality reasoning, complex tasks - Limitations: Higher cost, slower</p> <p>Use Cases: - Complex WorkflowPack generation - Multi-step reasoning tasks - Advanced code generation - Compliance policy analysis - AI-assisted workflow design</p> <p>Configuration:</p> <pre><code>GEMINI_PRO_CONFIG = {\n    \"model\": \"gemini-1.5-pro\",\n    \"temperature\": 0.2,  # Slight creativity for complex tasks\n    \"top_p\": 0.95,\n    \"top_k\": 40,\n    \"max_output_tokens\": 4096,\n    \"safety_settings\": {\n        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    }\n}\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#planned-q1-q2-2026","title":"Planned (Q1-Q2 2026)","text":""},{"location":"ai_governance/MODEL_SELECTION/#anthropic-claude-35-sonnet","title":"Anthropic Claude 3.5 Sonnet","text":"<p>Provider: Anthropic API Status: \ud83d\udccb Planned Q1 2026</p> <p>Specifications: - Context Window: 200K tokens - Output Limit: 4,096 tokens - Latency (estimated): p50: 800ms, p95: 1500ms, p99: 2200ms - Cost: $0.003/1K input tokens, $0.015/1K output tokens - Strengths: Highest quality code generation, superior reasoning - Limitations: Highest cost, smaller context window</p> <p>Planned Use Cases: - Production-quality code generation - Complex compliance reasoning - Critical decision support - High-stakes workflow design - Architecture recommendations</p>"},{"location":"ai_governance/MODEL_SELECTION/#openai-gpt-4-turbo","title":"OpenAI GPT-4 Turbo","text":"<p>Provider: OpenAI API Status: \ud83d\udccb Planned Q2 2026</p> <p>Specifications: - Context Window: 128K tokens - Output Limit: 4,096 tokens - Latency (estimated): p50: 700ms, p95: 1400ms, p99: 2000ms - Cost: $0.01/1K input tokens, $0.03/1K output tokens - Strengths: Strong general reasoning, good tool use - Limitations: Higher cost</p> <p>Planned Use Cases: - Advanced reasoning tasks - Multi-modal analysis (if needed) - Complex data analysis - Enterprise customer preference</p>"},{"location":"ai_governance/MODEL_SELECTION/#aws-bedrock-claude-titan","title":"AWS Bedrock (Claude, Titan)","text":"<p>Provider: AWS Bedrock Status: \ud83d\udd2e Roadmap (Phase 3)</p> <p>Rationale: Enterprise customers requiring AWS infrastructure Models: Claude 3 family, Amazon Titan Benefits: AWS ecosystem integration, enterprise SLAs</p>"},{"location":"ai_governance/MODEL_SELECTION/#future-considerations","title":"Future Considerations","text":""},{"location":"ai_governance/MODEL_SELECTION/#hugging-face-hosted-models","title":"Hugging Face Hosted Models","text":"<p>Status: \ud83d\udd2e Research</p> <p>Candidates: - <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> - <code>meta-llama/Llama-3-70B-Instruct</code> - <code>google/flan-t5-xxl</code></p> <p>Benefits: Open source, lower cost, customizable Challenges: Quality variability, hosting complexity</p>"},{"location":"ai_governance/MODEL_SELECTION/#on-premises-models","title":"On-Premises Models","text":"<p>Status: \ud83d\udd2e Phase 4 (2027+)</p> <p>Use Case: Air-gapped government deployments Requirements: GPU infrastructure, model serving platform Candidates: Llama 3, Mixtral, custom fine-tuned models</p>"},{"location":"ai_governance/MODEL_SELECTION/#model-routing-strategy","title":"Model Routing Strategy","text":""},{"location":"ai_governance/MODEL_SELECTION/#decision-tree","title":"Decision Tree","text":"<pre><code>async def select_model(\n    task_type: str,\n    complexity: str,\n    latency_requirement: str,\n    cost_sensitivity: str,\n    tenant_preferences: dict\n) -&gt; str:\n    \"\"\"Select optimal model based on task characteristics.\n\n    Args:\n        task_type: Type of task (e.g., \"code_generation\", \"explanation\", \"qa\")\n        complexity: Task complexity (\"simple\", \"moderate\", \"complex\")\n        latency_requirement: Latency tolerance (\"low\", \"medium\", \"high\")\n        cost_sensitivity: Cost consideration (\"low\", \"medium\", \"high\")\n        tenant_preferences: Tenant-specific model preferences\n\n    Returns:\n        Model identifier (e.g., \"gemini-1.5-flash\")\n    \"\"\"\n    # 1. Check tenant preferences (enterprise customers may specify)\n    if tenant_preferences.get(\"preferred_model\"):\n        return tenant_preferences[\"preferred_model\"]\n\n    # 2. Apply routing rules\n    if task_type == \"code_generation\" and complexity == \"complex\":\n        return \"claude-3.5-sonnet\"  # Highest quality code\n    elif task_type == \"explanation\" and complexity == \"simple\":\n        return \"gemini-1.5-flash\"  # Fast, cost-effective\n    elif task_type == \"workflow_design\" and complexity in [\"moderate\", \"complex\"]:\n        return \"gemini-1.5-pro\"  # Good balance\n    elif latency_requirement == \"low\" and cost_sensitivity == \"high\":\n        return \"gemini-1.5-flash\"  # Fastest, cheapest\n    elif complexity == \"complex\" and cost_sensitivity == \"low\":\n        return \"claude-3.5-sonnet\"  # Best quality\n    else:\n        return \"gemini-1.5-pro\"  # Default production model\n\n    # Default fallback\n    return \"gemini-1.5-flash\"\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#routing-rules","title":"Routing Rules","text":""},{"location":"ai_governance/MODEL_SELECTION/#by-task-type","title":"By Task Type","text":"Task Type Simple Moderate Complex Code Generation Gemini Flash Gemini Pro Claude Sonnet Explanation Gemini Flash Gemini Flash Gemini Pro Q&amp;A Gemini Flash Gemini Flash Gemini Pro Workflow Design Gemini Flash Gemini Pro Claude Sonnet Compliance Analysis Gemini Flash Gemini Pro Claude Sonnet Data Analysis Gemini Flash Gemini Pro GPT-4 Turbo"},{"location":"ai_governance/MODEL_SELECTION/#by-latency-requirement","title":"By Latency Requirement","text":"Requirement Model Choice Max Latency (p99) Low (&lt;500ms) Gemini Flash 800ms Medium (&lt;1500ms) Gemini Pro 1800ms High (&gt;1500ms) Claude Sonnet 2200ms"},{"location":"ai_governance/MODEL_SELECTION/#by-cost-sensitivity","title":"By Cost Sensitivity","text":"Sensitivity Model Choice Cost/1M Tokens (Input) High (minimize cost) Gemini Flash $18.75 Medium (balance) Gemini Pro $125 Low (maximize quality) Claude Sonnet $3,000"},{"location":"ai_governance/MODEL_SELECTION/#prompt-templates","title":"Prompt Templates","text":""},{"location":"ai_governance/MODEL_SELECTION/#template-structure","title":"Template Structure","text":"<pre><code>from typing import Dict, List\n\nclass PromptTemplate:\n    \"\"\"Structured prompt template with variables.\"\"\"\n\n    def __init__(\n        self,\n        template_id: str,\n        system_prompt: str,\n        user_prompt_template: str,\n        variables: List[str],\n        recommended_model: str,\n        temperature: float = 0.0\n    ):\n        self.template_id = template_id\n        self.system_prompt = system_prompt\n        self.user_prompt_template = user_prompt_template\n        self.variables = variables\n        self.recommended_model = recommended_model\n        self.temperature = temperature\n\n    def render(self, **kwargs) -&gt; Dict[str, str]:\n        \"\"\"Render template with provided variables.\"\"\"\n        missing = set(self.variables) - set(kwargs.keys())\n        if missing:\n            raise ValueError(f\"Missing required variables: {missing}\")\n\n        user_prompt = self.user_prompt_template.format(**kwargs)\n\n        return {\n            \"system_prompt\": self.system_prompt,\n            \"user_prompt\": user_prompt,\n            \"model\": self.recommended_model,\n            \"temperature\": self.temperature\n        }\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#template-library","title":"Template Library","text":""},{"location":"ai_governance/MODEL_SELECTION/#rulepack-validation-explanation","title":"RulePack Validation Explanation","text":"<pre><code>RULEPACK_EXPLANATION_TEMPLATE = PromptTemplate(\n    template_id=\"rulepack_explanation_v1\",\n    system_prompt=\"\"\"You are a compliance expert assistant for the CORTX Platform.\nYour role is to explain RulePack validation failures in plain language, referencing\nthe relevant regulatory requirements and suggesting corrections.\n\nUse the provided RAG context about compliance frameworks.\nBe specific, actionable, and cite regulatory codes when applicable.\"\"\",\n\n    user_prompt_template=\"\"\"Explain this validation failure:\n\n**Rule ID:** {rule_id}\n**Field:** {field}\n**Failed Value:** {failed_value}\n**Error Message:** {error_message}\n\n**Compliance Context:**\n{rag_context}\n\nProvide:\n1. What went wrong (plain language)\n2. Why this rule exists (regulatory requirement)\n3. How to fix it (specific steps)\"\"\",\n\n    variables=[\"rule_id\", \"field\", \"failed_value\", \"error_message\", \"rag_context\"],\n    recommended_model=\"gemini-1.5-flash\",\n    temperature=0.0\n)\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#workflowpack-generation","title":"WorkflowPack Generation","text":"<pre><code>WORKFLOW_GENERATION_TEMPLATE = PromptTemplate(\n    template_id=\"workflow_generation_v1\",\n    system_prompt=\"\"\"You are a workflow design expert for the CORTX Platform.\nYou create WorkflowPacks (YAML) from natural language descriptions.\n\nFollow the WorkflowPack schema strictly. Use appropriate node types:\n- data-source: Ingest data\n- validation: Execute RulePack\n- calculation: Perform computations\n- decision: Conditional branching\n- approval: Human-in-the-loop\n- ai-inference: AI model calls\n- data-sink: Output results\n\nEnsure compliance with regulatory frameworks when applicable.\"\"\",\n\n    user_prompt_template=\"\"\"Create a WorkflowPack for this requirement:\n\n**Description:** {description}\n\n**Compliance Requirements:** {compliance_requirements}\n\n**Available RulePacks:** {available_rulepacks}\n\n**RAG Context:**\n{rag_context}\n\nGenerate a complete WorkflowPack YAML following the schema.\nInclude metadata, steps with appropriate types, and configurations.\"\"\",\n\n    variables=[\"description\", \"compliance_requirements\", \"available_rulepacks\", \"rag_context\"],\n    recommended_model=\"gemini-1.5-pro\",\n    temperature=0.2\n)\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#code-generation","title":"Code Generation","text":"<pre><code>CODE_GENERATION_TEMPLATE = PromptTemplate(\n    template_id=\"code_generation_v1\",\n    system_prompt=\"\"\"You are an expert Python/TypeScript developer for the CORTX Platform.\n\nFollow these strict rules:\n- Use type hints (Python) or TypeScript strict mode\n- Include comprehensive error handling\n- Add unit tests for all functions\n- Follow PEP 8 (Python) or Airbnb style (TypeScript)\n- Include docstrings with examples\n- Implement proper logging with correlation IDs\n- Never include secrets or hardcoded credentials\n- Use parameterized queries (no SQL injection)\n\nAll code must be production-ready with &gt;80% test coverage.\"\"\",\n\n    user_prompt_template=\"\"\"Generate {language} code for this requirement:\n\n**Requirement:** {requirement}\n\n**Context:**\n{context}\n\n**Constraints:**\n{constraints}\n\n**Expected Inputs/Outputs:**\n{inputs_outputs}\n\nProvide:\n1. Implementation code with type hints\n2. Unit tests with fixtures\n3. Usage example\n4. Brief explanation of design decisions\"\"\",\n\n    variables=[\"language\", \"requirement\", \"context\", \"constraints\", \"inputs_outputs\"],\n    recommended_model=\"claude-3.5-sonnet\",  # Best for code\n    temperature=0.0\n)\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#compliance-qa","title":"Compliance Q&amp;A","text":"<pre><code>COMPLIANCE_QA_TEMPLATE = PromptTemplate(\n    template_id=\"compliance_qa_v1\",\n    system_prompt=\"\"\"You are a regulatory compliance expert for federal, healthcare,\nand cybersecurity frameworks (FedRAMP, HIPAA, NIST 800-53, SOC 2).\n\nAnswer questions accurately using the provided RAG context.\nCite specific control numbers or regulatory sections.\nIf uncertain, say so rather than guessing.\"\"\",\n\n    user_prompt_template=\"\"\"Question: {question}\n\n**RAG Context:**\n{rag_context}\n\n**Relevant Frameworks:** {frameworks}\n\nProvide a detailed answer with:\n1. Direct answer\n2. Supporting regulatory citations\n3. Implementation guidance (if applicable)\n4. Related considerations\"\"\",\n\n    variables=[\"question\", \"rag_context\", \"frameworks\"],\n    recommended_model=\"gemini-1.5-flash\",\n    temperature=0.0\n)\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#quality-controls","title":"Quality Controls","text":""},{"location":"ai_governance/MODEL_SELECTION/#reproducibility","title":"Reproducibility","text":"<p>Requirement: Same input \u2192 same output (&gt;95% consistency)</p> <p>Implementation:</p> <pre><code># Use temperature=0 for deterministic tasks\nasync def get_deterministic_response(\n    prompt: str,\n    model: str = \"gemini-1.5-flash\"\n):\n    response = await llm.generate(\n        model=model,\n        prompt=prompt,\n        temperature=0.0,  # No randomness\n        top_p=1.0,        # Full probability mass\n        seed=42           # Fixed seed (if supported)\n    )\n    return response\n</code></pre> <p>Testing:</p> <pre><code>async def test_reproducibility():\n    prompt = \"Explain HIPAA Security Rule \u00a7164.312(a)(1)\"\n\n    responses = []\n    for _ in range(10):\n        response = await get_deterministic_response(prompt)\n        responses.append(response)\n\n    # All responses should be identical\n    assert len(set(responses)) == 1, \"Responses are not reproducible\"\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#output-validation","title":"Output Validation","text":"<p>Requirement: Validate all AI-generated content before use</p> <p>Schema Validation:</p> <pre><code>from pydantic import BaseModel, validator\n\nclass WorkflowPackOutput(BaseModel):\n    \"\"\"Validate AI-generated WorkflowPack.\"\"\"\n    workflow_id: str\n    version: str\n    steps: List[dict]\n\n    @validator('version')\n    def validate_version(cls, v):\n        # Ensure semantic versioning\n        if not re.match(r'^\\d+\\.\\d+\\.\\d+$', v):\n            raise ValueError(\"Invalid version format\")\n        return v\n\n    @validator('steps')\n    def validate_steps(cls, v):\n        # Ensure at least one step\n        if len(v) &lt; 1:\n            raise ValueError(\"WorkflowPack must have at least one step\")\n        return v\n\nasync def validate_generated_workflow(ai_output: str) -&gt; WorkflowPackOutput:\n    \"\"\"Validate AI-generated WorkflowPack.\"\"\"\n    try:\n        workflow_data = yaml.safe_load(ai_output)\n        validated = WorkflowPackOutput(**workflow_data)\n        return validated\n    except Exception as e:\n        logger.error(\"workflow.validation.failed\", error=str(e))\n        raise\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#hallucination-detection","title":"Hallucination Detection","text":"<p>Requirement: Detect and flag potentially hallucinated information</p> <p>Strategies: 1. RAG Citation Check: Ensure claims are grounded in retrieved context 2. Fact Verification: Cross-reference with knowledge base 3. Confidence Scoring: Track model confidence (if available) 4. Human Review: Flag low-confidence responses for review</p> <pre><code>def detect_hallucination(\n    response: str,\n    rag_context: List[str],\n    confidence_threshold: float = 0.7\n) -&gt; bool:\n    \"\"\"Detect potential hallucinations in AI response.\n\n    Returns:\n        True if potential hallucination detected, False otherwise\n    \"\"\"\n    # 1. Check if key claims are in RAG context\n    response_claims = extract_claims(response)\n\n    grounded_claims = 0\n    for claim in response_claims:\n        if any(is_claim_in_context(claim, ctx) for ctx in rag_context):\n            grounded_claims += 1\n\n    grounding_ratio = grounded_claims / len(response_claims)\n\n    # 2. Flag if &lt;70% of claims are grounded\n    if grounding_ratio &lt; confidence_threshold:\n        logger.warning(\n            \"hallucination.detected\",\n            grounding_ratio=grounding_ratio,\n            response_preview=response[:200]\n        )\n        return True\n\n    return False\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#cost-management","title":"Cost Management","text":""},{"location":"ai_governance/MODEL_SELECTION/#budget-tracking","title":"Budget Tracking","text":"<p>Per-Tenant Budget: Track AI costs by tenant Monthly Limit: Alert at 80% of budget, block at 100%</p> <pre><code>from datetime import datetime, timedelta\n\nasync def track_ai_cost(\n    tenant_id: str,\n    model: str,\n    input_tokens: int,\n    output_tokens: int\n):\n    \"\"\"Track AI costs per tenant.\"\"\"\n    # Get model pricing\n    pricing = MODEL_PRICING[model]\n\n    cost = (\n        (input_tokens / 1000) * pricing[\"input\"] +\n        (output_tokens / 1000) * pricing[\"output\"]\n    )\n\n    # Update tenant usage\n    await db.execute(\n        \"\"\"\n        INSERT INTO ai_usage (tenant_id, model, cost, tokens_in, tokens_out, timestamp)\n        VALUES (:tenant_id, :model, :cost, :tokens_in, :tokens_out, :timestamp)\n        \"\"\",\n        {\n            \"tenant_id\": tenant_id,\n            \"model\": model,\n            \"cost\": cost,\n            \"tokens_in\": input_tokens,\n            \"tokens_out\": output_tokens,\n            \"timestamp\": datetime.utcnow()\n        }\n    )\n\n    # Check budget\n    month_start = datetime.utcnow().replace(day=1, hour=0, minute=0, second=0)\n    monthly_cost = await db.fetch_val(\n        \"\"\"\n        SELECT SUM(cost) FROM ai_usage\n        WHERE tenant_id = :tenant_id AND timestamp &gt;= :month_start\n        \"\"\",\n        {\"tenant_id\": tenant_id, \"month_start\": month_start}\n    )\n\n    budget_limit = await get_tenant_ai_budget(tenant_id)\n\n    if monthly_cost &gt;= budget_limit * 0.8:\n        await alert_budget_threshold(tenant_id, monthly_cost, budget_limit)\n\n    if monthly_cost &gt;= budget_limit:\n        raise BudgetExceededError(f\"Monthly AI budget exceeded for {tenant_id}\")\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#model-pricing","title":"Model Pricing","text":"<pre><code>MODEL_PRICING = {\n    \"gemini-1.5-flash\": {\n        \"input\": 0.00001875,   # per 1K tokens\n        \"output\": 0.000075\n    },\n    \"gemini-1.5-pro\": {\n        \"input\": 0.000125,\n        \"output\": 0.000375\n    },\n    \"claude-3.5-sonnet\": {\n        \"input\": 0.003,\n        \"output\": 0.015\n    },\n    \"gpt-4-turbo\": {\n        \"input\": 0.01,\n        \"output\": 0.03\n    }\n}\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#cost-optimization","title":"Cost Optimization","text":"<p>Strategies: 1. Caching: Cache common responses (1-hour TTL) 2. Prompt Compression: Remove unnecessary tokens 3. Model Downgrading: Use cheaper models when appropriate 4. Batch Processing: Combine multiple requests</p> <pre><code>async def optimize_cost(\n    task_type: str,\n    complexity: str,\n    cached_result_available: bool\n):\n    \"\"\"Optimize cost by selecting cheapest adequate model.\"\"\"\n    if cached_result_available:\n        return \"cache\"  # No cost\n\n    if task_type in [\"explanation\", \"qa\"] and complexity == \"simple\":\n        return \"gemini-1.5-flash\"  # Cheapest\n\n    if complexity == \"moderate\":\n        return \"gemini-1.5-pro\"  # Mid-tier\n\n    return \"gemini-1.5-pro\"  # Default (don't auto-select most expensive)\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":""},{"location":"ai_governance/MODEL_SELECTION/#key-metrics","title":"Key Metrics","text":"<p>Usage Metrics: - Requests per model (per tenant, per task type) - Token consumption (input, output) - Cost per tenant (daily, monthly) - Model latency (p50, p95, p99)</p> <p>Quality Metrics: - Error rate by model - Validation failures (schema, hallucination) - User feedback (thumbs up/down) - Reproducibility score</p> <p>System Metrics: - Model availability - Rate limit violations - Cache hit rate - Retry rate</p>"},{"location":"ai_governance/MODEL_SELECTION/#dashboards","title":"Dashboards","text":"<pre><code># Grafana dashboard configuration\nDASHBOARDS = {\n    \"ai_usage\": {\n        \"requests_by_model\": \"sum(ai.request.count) by (model)\",\n        \"cost_by_tenant\": \"sum(ai.cost) by (tenant_id)\",\n        \"latency_by_model\": \"histogram(ai.request.latency) by (model)\",\n        \"error_rate\": \"sum(ai.request.errors) / sum(ai.request.count)\"\n    },\n    \"quality\": {\n        \"validation_failures\": \"sum(ai.output.validation_failed)\",\n        \"hallucination_detections\": \"sum(ai.hallucination.detected)\",\n        \"user_feedback_positive\": \"sum(ai.feedback.positive) / sum(ai.feedback.total)\"\n    }\n}\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#alerts","title":"Alerts","text":"<p>Critical: - Model unavailable for &gt;5 minutes - Error rate &gt;5% (any model) - Budget exceeded for any tenant</p> <p>Warning: - Model latency p99 &gt;2x baseline - Hallucination detection rate &gt;10% - Cache hit rate &lt;50%</p> <pre><code>ALERTS = {\n    \"model_unavailable\": {\n        \"condition\": \"ai.model.available == 0\",\n        \"duration\": \"5m\",\n        \"severity\": \"critical\",\n        \"action\": \"page_oncall\"\n    },\n    \"high_error_rate\": {\n        \"condition\": \"ai.request.errors / ai.request.count &gt; 0.05\",\n        \"duration\": \"10m\",\n        \"severity\": \"critical\",\n        \"action\": \"slack_alert\"\n    },\n    \"budget_warning\": {\n        \"condition\": \"ai.cost.monthly &gt; budget * 0.8\",\n        \"duration\": \"1m\",\n        \"severity\": \"warning\",\n        \"action\": \"email_admin\"\n    }\n}\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#fallback-resilience","title":"Fallback &amp; Resilience","text":""},{"location":"ai_governance/MODEL_SELECTION/#model-fallback-chain","title":"Model Fallback Chain","text":"<pre><code>MODEL_FALLBACK_CHAIN = {\n    \"claude-3.5-sonnet\": [\"gemini-1.5-pro\", \"gemini-1.5-flash\"],\n    \"gpt-4-turbo\": [\"gemini-1.5-pro\", \"gemini-1.5-flash\"],\n    \"gemini-1.5-pro\": [\"gemini-1.5-flash\"],\n    \"gemini-1.5-flash\": []  # No fallback\n}\n\nasync def call_with_fallback(\n    prompt: str,\n    primary_model: str,\n    max_retries: int = 3\n):\n    \"\"\"Call AI model with automatic fallback.\"\"\"\n    models_to_try = [primary_model] + MODEL_FALLBACK_CHAIN.get(primary_model, [])\n\n    for model in models_to_try:\n        try:\n            response = await llm.generate(\n                model=model,\n                prompt=prompt,\n                timeout=10  # 10 second timeout\n            )\n            return response\n        except Exception as e:\n            logger.warning(\n                \"model.call.failed\",\n                model=model,\n                error=str(e)\n            )\n            continue\n\n    raise ModelUnavailableError(\"All models failed\")\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#circuit-breaker","title":"Circuit Breaker","text":"<pre><code>from circuitbreaker import circuit\n\n@circuit(failure_threshold=5, recovery_timeout=60)\nasync def call_llm(model: str, prompt: str):\n    \"\"\"Call LLM with circuit breaker pattern.\"\"\"\n    response = await llm_client.generate(model, prompt)\n    return response\n</code></pre>"},{"location":"ai_governance/MODEL_SELECTION/#compliance-governance","title":"Compliance &amp; Governance","text":""},{"location":"ai_governance/MODEL_SELECTION/#model-approval-process","title":"Model Approval Process","text":"<p>New Model Integration: 1. Security Review: Assess data handling, privacy, encryption 2. Compliance Review: Verify alignment with FedRAMP, HIPAA, SOC 2 3. Cost Analysis: Estimate monthly costs, ROI 4. Quality Testing: Benchmark on standard test sets 5. Pilot Testing: Limited rollout to select tenants 6. Production Approval: Final approval from architecture team</p>"},{"location":"ai_governance/MODEL_SELECTION/#data-handling","title":"Data Handling","text":"<p>PII Protection: - All input must be PII-redacted before LLM calls - No PII in model training data (use commercial APIs only) - Audit all prompts containing sensitive data</p> <p>Data Retention: - Prompts: 90 days (for debugging) - Responses: 30 days (for caching) - Usage logs: 1 year (for billing) - Audit logs: 7 years (compliance requirement)</p>"},{"location":"ai_governance/MODEL_SELECTION/#changelog","title":"Changelog","text":"<p>2025-10-01: - Initial model selection strategy - Defined routing rules and templates - Configured Gemini 1.5 Flash/Pro as primary models - Planned Claude and GPT-4 integration (Q1-Q2 2026)</p>"},{"location":"ai_governance/MODEL_SELECTION/#contact","title":"Contact","text":"<p>AI Model Strategy: - AI Platform Team: ai-platform@sinergysolutions.ai - Slack: #ai-model-selection</p> <p>Request New Model: - Create GitHub issue with <code>ai-model-request</code> label - Include use case, expected cost, and compliance considerations</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Review Cycle: Quarterly - Next Review: 2026-01-01 - Approvers: AI Platform Team + Architecture Team</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/","title":"RAG Knowledge Base Management","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: AI Platform Team Classification: Internal</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#purpose","title":"Purpose","text":"<p>This document defines the management, maintenance, and governance of the CORTX Platform's Retrieval-Augmented Generation (RAG) knowledge base. The RAG system enhances AI capabilities by grounding responses in verified compliance documents, regulatory frameworks, and platform documentation.</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#overview","title":"Overview","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#what-is-rag","title":"What is RAG?","text":"<p>Retrieval-Augmented Generation (RAG) is a technique that enhances Large Language Model (LLM) responses by: 1. Retrieving relevant context from a curated knowledge base 2. Injecting that context into the LLM prompt 3. Generating responses grounded in factual, domain-specific information</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#why-rag-for-cortx","title":"Why RAG for CORTX?","text":"<p>Benefits: - Accuracy: Reduce hallucinations by grounding responses in verified documents - Compliance: Ensure AI recommendations align with regulatory frameworks - Context: Provide domain expertise (Treasury rules, HIPAA controls, etc.) - Freshness: Update knowledge without retraining models - Explainability: Cite sources for AI-generated recommendations</p> <p>Use Cases: - Explain RulePack validation failures with regulatory context - Generate WorkflowPacks based on compliance requirements - Answer questions about platform capabilities and APIs - Provide compliance guidance for Pack authors - Suggest corrections for failed validations</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#architecture","title":"Architecture","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#vector-store","title":"Vector Store","text":"<p>Technology: Sentence Transformers + PostgreSQL pgvector Embedding Model: <code>all-MiniLM-L6-v2</code> (384 dimensions) Similarity Metric: Cosine similarity Indexing: HNSW (Hierarchical Navigable Small World)</p> <p>Configuration:</p> <pre><code>from sentence_transformers import SentenceTransformer\n\n# Embedding model\nembedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\n# Vector store settings\nVECTOR_DIMENSIONS = 384\nSIMILARITY_THRESHOLD = 0.5\nTOP_K_RESULTS = 5\nMAX_CHUNK_SIZE = 512  # tokens\nCHUNK_OVERLAP = 50    # tokens\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#document-processing-pipeline","title":"Document Processing Pipeline","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Source Documents \u2502\n\u2502  (PDF, MD, TXT)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Text Extraction  \u2502\n\u2502  (pypdf, pandoc) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Chunking      \u2502\n\u2502 (512 tokens max) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Embedding      \u2502\n\u2502   Generation     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   PostgreSQL     \u2502\n\u2502  Vector Storage  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#retrieval-flow","title":"Retrieval Flow","text":"<pre><code>async def retrieve_context(query: str, top_k: int = 5) -&gt; List[Document]:\n    \"\"\"Retrieve relevant context from knowledge base.\n\n    Args:\n        query: User query or prompt\n        top_k: Number of results to return\n\n    Returns:\n        List of documents with content and metadata\n    \"\"\"\n    # 1. Generate query embedding\n    query_embedding = embedder.encode(query)\n\n    # 2. Search vector store\n    results = await vector_store.similarity_search(\n        query_embedding,\n        k=top_k,\n        threshold=SIMILARITY_THRESHOLD\n    )\n\n    # 3. Apply keyword boosting\n    for result in results:\n        if any(keyword in result.content.lower()\n               for keyword in query.lower().split()):\n            result.score *= 1.2\n\n    # 4. Re-rank by score\n    results = sorted(results, key=lambda r: r.score, reverse=True)\n\n    # 5. Return top results\n    return results[:top_k]\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#knowledge-base-contents","title":"Knowledge Base Contents","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#1-compliance-regulatory-documents","title":"1. Compliance &amp; Regulatory Documents","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#federal-financial-compliance","title":"Federal Financial Compliance","text":"<p>Source: US Department of Treasury, OMB</p> Document Version Last Updated Chunks Status OMB Circular A-136 2023 2023-06-15 342 \u2705 Active GTAS Validation Rules 2024 2024-01-01 204 \u2705 Active Treasury Financial Manual Vol 1, Part 2 2023-09-30 156 \u2705 Active USSGL Account Attributes FY 2024 2023-10-01 89 \u2705 Active <p>Coverage: 791 chunks, ~405,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#hipaa-compliance","title":"HIPAA Compliance","text":"<p>Source: HHS Office for Civil Rights</p> Document Version Last Updated Chunks Status HIPAA Security Rule Final Rule 2003-02-20 128 \u2705 Active HIPAA Privacy Rule Final Rule 2002-08-14 156 \u2705 Active Breach Notification Rule Final Rule 2009-08-24 67 \u2705 Active Technical Safeguards Guide 2020 2020-05-15 94 \u2705 Active <p>Coverage: 445 chunks, ~228,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#nist-cybersecurity","title":"NIST Cybersecurity","text":"<p>Source: NIST Computer Security Resource Center</p> Document Version Last Updated Chunks Status NIST 800-53 Rev 5 Revision 5 2020-09-23 1,247 \u2705 Active FedRAMP Authorization Guide v3.1 2021-06-08 234 \u2705 Active NIST Cybersecurity Framework v1.1 2018-04-16 187 \u2705 Active <p>Coverage: 1,668 chunks, ~854,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#2-platform-documentation","title":"2. Platform Documentation","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#cortx-platform-apis","title":"CORTX Platform APIs","text":"<p>Source: Internal OpenAPI specifications</p> Service Endpoints Last Updated Chunks Status Gateway API 12 2025-09-30 48 \u2705 Active Identity API 8 2025-09-30 32 \u2705 Active AI Broker API 15 2025-09-30 60 \u2705 Active Validation API 10 2025-09-30 40 \u2705 Active Workflow API 18 2025-09-30 72 \u2705 Active Compliance API 14 2025-09-30 56 \u2705 Active <p>Coverage: 308 chunks, ~158,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#pack-schemas-examples","title":"Pack Schemas &amp; Examples","text":"<p>Source: cortx-packs repository</p> Category Packs Last Updated Chunks Status RulePack Schema 1 2025-09-30 24 \u2705 Active WorkflowPack Schema 1 2025-09-30 32 \u2705 Active Example RulePacks 8 2025-09-30 96 \u2705 Active Example WorkflowPacks 5 2025-09-30 80 \u2705 Active <p>Coverage: 232 chunks, ~119,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#3-domain-knowledge","title":"3. Domain Knowledge","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#federal-financial-management","title":"Federal Financial Management","text":"<p>Source: FedSuite documentation, Treasury guidance</p> Topic Documents Chunks Status Trial Balance Reconciliation 3 67 \u2705 Active GTAS Submission Process 4 89 \u2705 Active Treasury Account Symbols 2 45 \u2705 Active FBDI Integration 2 38 \u2705 Active <p>Coverage: 239 chunks, ~122,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#healthcare-compliance","title":"Healthcare Compliance","text":"<p>Source: MedSuite documentation, CMS guidance</p> Topic Documents Chunks Status Claims Verification 2 56 \u2705 Active HIPAA Audit Procedures 3 78 \u2705 Active EHR Integration 1 34 \u2705 Active <p>Coverage: 168 chunks, ~86,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#real-estate-property","title":"Real Estate &amp; Property","text":"<p>Source: CorpSuite documentation, Maryland SDAT</p> Topic Documents Chunks Status Title Verification 2 45 \u2705 Active Property Search Procedures 1 28 \u2705 Active SDAT AUP Restrictions 1 19 \u2705 Active <p>Coverage: 92 chunks, ~47,000 tokens</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#total-knowledge-base-statistics","title":"Total Knowledge Base Statistics","text":"<ul> <li>Total Documents: 73</li> <li>Total Chunks: 3,943</li> <li>Total Tokens: ~2,019,000</li> <li>Vector Dimensions: 384</li> <li>Storage Size: ~1.5 GB (embeddings + metadata)</li> <li>Last Full Update: 2025-09-30</li> </ul>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#document-management","title":"Document Management","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#adding-new-documents","title":"Adding New Documents","text":"<p>Process: 1. Source Verification: Ensure document is authoritative and current 2. License Check: Verify we have rights to use (public domain, licensed, internal) 3. Format Conversion: Convert to plain text (Markdown preferred) 4. Chunking: Split into 512-token chunks with 50-token overlap 5. Embedding Generation: Generate vector embeddings 6. Metadata Tagging: Add source, date, version, category 7. Quality Review: Verify retrieval accuracy with test queries 8. Indexing: Insert into vector store with HNSW indexing</p> <p>Example Code:</p> <pre><code>from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom datetime import datetime\n\nasync def add_document(\n    content: str,\n    source: str,\n    category: str,\n    version: str,\n    metadata: dict\n):\n    \"\"\"Add new document to knowledge base.\"\"\"\n    # 1. Split into chunks\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=512,\n        chunk_overlap=50,\n        length_function=len\n    )\n    chunks = splitter.split_text(content)\n\n    # 2. Generate embeddings\n    embeddings = embedder.encode(chunks)\n\n    # 3. Prepare metadata\n    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n        chunk_metadata = {\n            **metadata,\n            \"source\": source,\n            \"category\": category,\n            \"version\": version,\n            \"chunk_id\": i,\n            \"total_chunks\": len(chunks),\n            \"added_at\": datetime.utcnow().isoformat()\n        }\n\n        # 4. Insert into vector store\n        await vector_store.insert(\n            embedding=embedding,\n            content=chunk,\n            metadata=chunk_metadata\n        )\n\n    logger.info(\n        \"document.added\",\n        source=source,\n        chunks=len(chunks),\n        category=category\n    )\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#updating-existing-documents","title":"Updating Existing Documents","text":"<p>When to Update: - New version of regulatory document published - Platform API changes - Schema modifications - Corrections to existing content</p> <p>Process: 1. Mark Old Version: Tag as deprecated (don't delete yet) 2. Add New Version: Follow \"Adding New Documents\" process 3. Verify Retrieval: Test queries to ensure new version retrieved 4. Archive Old Version: After 30 days, remove deprecated version 5. Update Changelog: Document changes in knowledge base log</p> <p>Example:</p> <pre><code>async def update_document(\n    document_id: str,\n    new_content: str,\n    new_version: str\n):\n    \"\"\"Update existing document with new version.\"\"\"\n    # 1. Deprecate old version\n    await vector_store.update_metadata(\n        document_id=document_id,\n        metadata={\"status\": \"deprecated\", \"deprecated_at\": datetime.utcnow()}\n    )\n\n    # 2. Add new version\n    await add_document(\n        content=new_content,\n        source=f\"{document_id}\",\n        category=original_category,\n        version=new_version,\n        metadata={\"replaces\": document_id}\n    )\n\n    # 3. Schedule cleanup\n    await schedule_cleanup(document_id, days=30)\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#removing-documents","title":"Removing Documents","text":"<p>When to Remove: - Document superseded by newer version (after 30-day grace period) - License expired or revoked - Content no longer relevant - Source deemed unreliable</p> <p>Process: 1. Verify No Dependencies: Check if any packs reference this document 2. Archive First: Export to cold storage before deletion 3. Soft Delete: Mark as deleted, don't remove immediately 4. Monitor Impact: Track retrieval metrics for 7 days 5. Hard Delete: Permanently remove after verification period</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#retrieval-strategies","title":"Retrieval Strategies","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#standard-retrieval","title":"Standard Retrieval","text":"<p>Use Case: General queries, broad topics Method: Cosine similarity, top-k results Parameters: k=5, threshold=0.5</p> <pre><code>results = await retrieve_context(\n    query=\"What are HIPAA technical safeguards?\",\n    top_k=5\n)\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#keyword-boosted-retrieval","title":"Keyword-Boosted Retrieval","text":"<p>Use Case: Specific terms, acronyms, regulatory references Method: Cosine similarity + keyword matching bonus Parameters: k=5, threshold=0.5, boost=1.2x</p> <pre><code>async def retrieve_with_keyword_boost(query: str, keywords: List[str]):\n    results = await retrieve_context(query, top_k=10)\n\n    for result in results:\n        if any(kw.lower() in result.content.lower() for kw in keywords):\n            result.score *= 1.2\n\n    return sorted(results, key=lambda r: r.score, reverse=True)[:5]\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#category-filtered-retrieval","title":"Category-Filtered Retrieval","text":"<p>Use Case: Domain-specific queries Method: Pre-filter by category before similarity search Parameters: category filter, k=5</p> <pre><code>results = await vector_store.similarity_search(\n    query_embedding,\n    k=5,\n    filter={\"category\": \"hipaa_compliance\"}\n)\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#multi-query-retrieval","title":"Multi-Query Retrieval","text":"<p>Use Case: Complex, multi-faceted questions Method: Generate multiple query variations, merge results Parameters: 3 query variations, k=3 per query, deduplicate</p> <pre><code>async def multi_query_retrieval(original_query: str):\n    # Generate query variations\n    variations = await llm.generate([\n        f\"Rephrase this query: {original_query}\",\n        f\"Break this into sub-questions: {original_query}\"\n    ])\n\n    all_results = []\n    for query in [original_query] + variations:\n        results = await retrieve_context(query, top_k=3)\n        all_results.extend(results)\n\n    # Deduplicate and re-rank\n    unique_results = deduplicate_by_content(all_results)\n    return sorted(unique_results, key=lambda r: r.score, reverse=True)[:5]\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#quality-assurance","title":"Quality Assurance","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#retrieval-accuracy-testing","title":"Retrieval Accuracy Testing","text":"<p>Test Set: 100 curated query-answer pairs Success Criteria: Correct answer in top-3 results for &gt;90% of queries</p> <p>Example Test Cases:</p> <pre><code>TEST_CASES = [\n    {\n        \"query\": \"What is the GTAS submission deadline?\",\n        \"expected_source\": \"GTAS Validation Rules 2024\",\n        \"expected_keywords\": [\"submission\", \"deadline\", \"calendar day\"]\n    },\n    {\n        \"query\": \"How do I implement HIPAA access controls?\",\n        \"expected_source\": \"HIPAA Security Rule\",\n        \"expected_keywords\": [\"access control\", \"\u00a7164.312(a)(1)\"]\n    },\n    {\n        \"query\": \"What are the RulePack severity levels?\",\n        \"expected_source\": \"RulePack Schema\",\n        \"expected_keywords\": [\"FATAL\", \"WARNING\", \"INFO\"]\n    }\n]\n\nasync def test_retrieval_accuracy():\n    correct = 0\n    for test in TEST_CASES:\n        results = await retrieve_context(test[\"query\"], top_k=3)\n\n        # Check if expected source in top 3\n        if any(test[\"expected_source\"] in r.metadata[\"source\"] for r in results):\n            correct += 1\n\n    accuracy = correct / len(TEST_CASES)\n    assert accuracy &gt; 0.90, f\"Retrieval accuracy {accuracy:.2%} below threshold\"\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#embedding-drift-detection","title":"Embedding Drift Detection","text":"<p>Monitor: Cosine similarity distribution over time Alert: If mean similarity drops &gt;10% from baseline</p> <pre><code>async def monitor_embedding_drift():\n    # Sample random queries\n    sample_queries = await get_random_queries(n=100)\n\n    current_similarities = []\n    for query in sample_queries:\n        results = await retrieve_context(query, top_k=1)\n        current_similarities.append(results[0].score)\n\n    current_mean = np.mean(current_similarities)\n    baseline_mean = await get_baseline_similarity()\n\n    drift = (baseline_mean - current_mean) / baseline_mean\n\n    if drift &gt; 0.10:\n        logger.warning(\n            \"embedding.drift.detected\",\n            current_mean=current_mean,\n            baseline_mean=baseline_mean,\n            drift_pct=drift * 100\n        )\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#coverage-analysis","title":"Coverage Analysis","text":"<p>Metric: Percentage of queries with &gt;0.5 similarity score Target: &gt;95% of queries return at least 1 result</p> <pre><code>async def analyze_coverage(queries: List[str]):\n    covered = 0\n    for query in queries:\n        results = await retrieve_context(query, top_k=1)\n        if results and results[0].score &gt; 0.5:\n            covered += 1\n\n    coverage = covered / len(queries)\n    logger.info(\"rag.coverage\", coverage_pct=coverage * 100)\n\n    return coverage\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#performance-optimization","title":"Performance Optimization","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#caching-strategy","title":"Caching Strategy","text":"<p>Cache Layer: Redis TTL: 1 hour for query results Cache Key: SHA-256 hash of query + parameters</p> <pre><code>import hashlib\nimport json\n\nasync def retrieve_with_cache(query: str, top_k: int = 5):\n    # Generate cache key\n    cache_key = hashlib.sha256(\n        json.dumps({\"query\": query, \"top_k\": top_k}).encode()\n    ).hexdigest()\n\n    # Check cache\n    cached = await redis.get(f\"rag:{cache_key}\")\n    if cached:\n        logger.info(\"rag.cache.hit\", query=query)\n        return json.loads(cached)\n\n    # Retrieve from vector store\n    results = await retrieve_context(query, top_k)\n\n    # Cache results\n    await redis.setex(\n        f\"rag:{cache_key}\",\n        3600,  # 1 hour TTL\n        json.dumps([r.to_dict() for r in results])\n    )\n\n    logger.info(\"rag.cache.miss\", query=query)\n    return results\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#index-optimization","title":"Index Optimization","text":"<p>Index Type: HNSW (Hierarchical Navigable Small World) Parameters: - <code>m</code>: 16 (connections per layer) - <code>ef_construction</code>: 200 (build-time accuracy) - <code>ef_search</code>: 100 (query-time accuracy)</p> <pre><code>-- Create HNSW index\nCREATE INDEX idx_embeddings_hnsw\nON knowledge_base\nUSING hnsw (embedding vector_cosine_ops)\nWITH (m = 16, ef_construction = 200);\n\n-- Query with ef_search\nSET hnsw.ef_search = 100;\nSELECT * FROM knowledge_base\nORDER BY embedding &lt;=&gt; query_embedding\nLIMIT 5;\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#batch-retrieval","title":"Batch Retrieval","text":"<p>Use Case: Retrieve context for multiple queries at once Benefit: Reduce database round-trips</p> <pre><code>async def batch_retrieve(queries: List[str], top_k: int = 5):\n    # Generate all embeddings at once\n    query_embeddings = embedder.encode(queries)\n\n    # Batch query vector store\n    all_results = await vector_store.batch_similarity_search(\n        embeddings=query_embeddings,\n        k=top_k\n    )\n\n    return all_results\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#monitoring-metrics","title":"Monitoring &amp; Metrics","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#key-metrics","title":"Key Metrics","text":"<p>Retrieval Metrics: - Query latency (p50, p95, p99) - Cache hit rate - Results per query (avg, median) - Similarity scores (avg, distribution)</p> <p>Quality Metrics: - Retrieval accuracy (test set) - Coverage rate (queries with results) - User feedback (thumbs up/down on AI responses)</p> <p>System Metrics: - Vector store size (GB) - Embedding generation time - Index build time - Storage growth rate</p> <p>Dashboards:</p> <pre><code># Grafana dashboard queries\n{\n    \"rag_query_latency_ms\": \"histogram(rag.query.duration)\",\n    \"rag_cache_hit_rate\": \"sum(rag.cache.hit) / sum(rag.cache.total)\",\n    \"rag_avg_similarity\": \"avg(rag.result.similarity)\",\n    \"rag_results_per_query\": \"avg(rag.result.count)\"\n}\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#alerts","title":"Alerts","text":"<p>Critical: - Retrieval accuracy &lt;90% (test set) - Query latency p99 &gt;1000ms - Vector store unavailable</p> <p>Warning: - Cache hit rate &lt;50% - Embedding drift &gt;10% - Coverage rate &lt;95%</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#security-privacy","title":"Security &amp; Privacy","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#pii-redaction","title":"PII Redaction","text":"<p>Before Embedding: All documents must be scanned for PII and redacted before embedding generation.</p> <pre><code>def redact_pii_before_embedding(content: str) -&gt; str:\n    \"\"\"Redact PII before generating embeddings.\"\"\"\n    # SSN\n    content = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[REDACTED_SSN]', content)\n\n    # Email\n    content = re.sub(\n        r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n        '[REDACTED_EMAIL]',\n        content\n    )\n\n    # Phone\n    content = re.sub(r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b', '[REDACTED_PHONE]', content)\n\n    return content\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#access-control","title":"Access Control","text":"<p>Knowledge Base Access: - Public documents: No restrictions - Internal documents: Require authentication - Tenant-specific documents: Tenant isolation</p> <pre><code>async def retrieve_with_access_control(\n    query: str,\n    user_context: dict,\n    top_k: int = 5\n):\n    results = await retrieve_context(query, top_k)\n\n    # Filter based on user permissions\n    filtered_results = [\n        r for r in results\n        if can_access_document(r.metadata, user_context)\n    ]\n\n    return filtered_results\n\ndef can_access_document(metadata: dict, user_context: dict) -&gt; bool:\n    \"\"\"Check if user can access document.\"\"\"\n    doc_classification = metadata.get(\"classification\", \"public\")\n\n    if doc_classification == \"public\":\n        return True\n\n    if doc_classification == \"internal\":\n        return user_context.get(\"authenticated\", False)\n\n    if doc_classification == \"tenant_private\":\n        return metadata.get(\"tenant_id\") == user_context.get(\"tenant_id\")\n\n    return False\n</code></pre>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#maintenance-schedule","title":"Maintenance Schedule","text":""},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#daily","title":"Daily","text":"<ul> <li>Monitor retrieval metrics</li> <li>Check cache hit rates</li> <li>Review error logs</li> </ul>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#weekly","title":"Weekly","text":"<ul> <li>Run retrieval accuracy tests</li> <li>Analyze coverage metrics</li> <li>Review new document additions</li> </ul>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#monthly","title":"Monthly","text":"<ul> <li>Embedding drift analysis</li> <li>Index optimization review</li> <li>Update deprecated documents</li> <li>Archive old versions</li> </ul>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#quarterly","title":"Quarterly","text":"<ul> <li>Full knowledge base audit</li> <li>Review and update test cases</li> <li>Re-evaluate document sources</li> <li>Update this document</li> </ul>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#changelog","title":"Changelog","text":"<p>2025-10-01: - Initial knowledge base setup - Added 73 documents (3,943 chunks) - Configured HNSW indexing - Implemented caching layer</p>"},{"location":"ai_governance/RAG_KNOWLEDGE_BASE/#contact","title":"Contact","text":"<p>RAG Knowledge Base Maintainers: - AI Platform Team: ai-platform@sinergysolutions.ai - Slack: #rag-knowledge-base</p> <p>Request Document Addition: - Create GitHub issue with <code>rag-document</code> label - Include source, category, and justification - Tag AI platform team for review</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Review Cycle: Quarterly - Next Review: 2026-01-01 - Approvers: AI Platform Team</p>"},{"location":"architecture/","title":"Architecture","text":"<p>High-level topology and flows.</p> <p>```mermaid flowchart LR   User--&gt;Gateway   Gateway--&gt;Identity &amp; Validation &amp; Workflow &amp; Compliance &amp; Ledger &amp; OCR &amp; RAG   RAG--&gt;DB[(PostgreSQL + pgvector)]   Ledger--&gt;Evidence[(Immutable Chain)]</p>"},{"location":"contribute/","title":"Contribute","text":"<p>Follow <code>/templates</code> and contracts-first rules. Submit ADRs for architectural decisions and update ADR index.</p>"},{"location":"diagrams/dev_staging_prod_pipeline/","title":"Dev staging prod pipeline","text":"<pre><code>graph TD\n    subgraph CI/CD Pipeline\n        A[Development] --&gt; B{Git Push}\n        B --&gt; C[CI Server]\n        C --&gt; D{Build &amp; Test}\n        D -- Success --&gt; E{Deploy to Staging}\n        E --&gt; F{Manual Approval}\n        F -- Approved --&gt; G{Deploy to Production}\n    end\n</code></pre>"},{"location":"diagrams/hierarchical_rag_flow/","title":"Hierarchical rag flow","text":"<pre><code>graph TD\n    subgraph Hierarchical RAG\n        A(User Query) --&gt; B{RAG Service}\n\n        subgraph Knowledge Layers\n            C[Platform]\n            D[Suite]\n            E[Module]\n            F[Entity]\n        end\n\n        B --&gt; C\n        B --&gt; D\n        B --&gt; E\n        B --&gt; F\n\n        C --&gt; G{Retrieved Context}\n        D --&gt; G\n        E --&gt; G\n        F --&gt; G\n\n        G --&gt; H{AI Broker}\n        A --&gt; H\n\n        H --&gt; I(AI Response)\n    end\n</code></pre>"},{"location":"diagrams/ledger_append_verify/","title":"Ledger append verify","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant LedgerService\n    participant Database\n\n    Client-&gt;&gt;LedgerService: Append Event\n    LedgerService-&gt;&gt;Database: Get Latest Event Hash\n    Database--&gt;&gt;LedgerService: Latest Event Hash\n    LedgerService-&gt;&gt;LedgerService: Compute New Event Hash\n    LedgerService-&gt;&gt;Database: Store New Event\n    Database--&gt;&gt;LedgerService: Success\n    LedgerService--&gt;&gt;Client: Success\n\n    Client-&gt;&gt;LedgerService: Verify Ledger\n    LedgerService-&gt;&gt;Database: Get All Events\n    Database--&gt;&gt;LedgerService: All Events\n    LedgerService-&gt;&gt;LedgerService: Re-compute Hashes and Verify Chain\n    LedgerService--&gt;&gt;Client: Verification Result\n</code></pre>"},{"location":"diagrams/platform_topology/","title":"Platform topology","text":"<pre><code>graph TD\n    subgraph CORTX Ecosystem\n        subgraph Design Layer\n            A[BPM Designer]\n            B[AI Assistant]\n        end\n        subgraph Execution Layer\n            C[Gateway]\n            D[Identity]\n            E[Validation]\n            F[AI Broker]\n            G[Workflow]\n            H[Compliance]\n            I[Ledger]\n            J[OCR]\n            K[RAG]\n        end\n        subgraph Domain Layer\n            L[FedSuite]\n            M[CorpSuite]\n            N[MedSuite]\n            O[GovSuite]\n        end\n        subgraph Infrastructure Layer\n            P[GCP Cloud Run]\n            Q[PostgreSQL/Supabase]\n            R[Redis]\n            S[Cloud Storage]\n            T[Terraform]\n        end\n    end\n\n    A --&gt; C\n    B --&gt; F\n    C --&gt; D\n    C --&gt; E\n    C --&gt; F\n    C --&gt; G\n    C --&gt; H\n    C --&gt; I\n    C --&gt; J\n    C --&gt; K\n\n    G --&gt; E\n    G --&gt; F\n    G --&gt; H\n\n    L --&gt; C\n    M --&gt; C\n    N --&gt; C\n    O --&gt; C\n</code></pre>"},{"location":"marketplace/MARKETPLACE_VISION/","title":"CORTX Marketplace Vision","text":"<p>The CORTX Marketplace will allow: - Distribution of RulePacks and WorkflowPacks - Certification tiers (community, certified, official) - Licensing and pricing (free or paid) - Discovery by compliance domain (FedRAMP, HIPAA, GTAS, etc.)</p> <p>Future versions of this document will include: - Submission workflows - Certification process - Governance policies</p>"},{"location":"operations/","title":"Operations","text":"<p>Environments: dev \u2192 staging \u2192 prod. CI Gates: docs-ci, contracts-ci. Releases: semantic/changesets.</p>"},{"location":"overview/","title":"CORTX Overview","text":"<p>CORTX is the AI orchestration and compliance platform powering Sinergy\u2019s suites (Fed, Corp, Med, Gov). See the CORTX Platform FDD and Hierarchical RAG.</p>"},{"location":"packs/","title":"Packs","text":"<p>CORTX Packs include RulePacks (validation/edits) and WorkflowPacks (BPMN flows). See: Pack Governance, Authoring Guide.</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/","title":"Pack Authoring Guide","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: Platform Architecture Team Audience: Pack Authors, Compliance Officers, Developers Classification: Public</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#introduction","title":"Introduction","text":"<p>Welcome to the CORTX Pack Authoring Guide! This document provides comprehensive instructions for creating, testing, and deploying RulePacks and WorkflowPacks - the core building blocks of compliance automation in the CORTX Platform.</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#what-are-packs","title":"What are Packs?","text":"<p>RulePacks are JSON-based validation rule sets that define compliance policies, business rules, and data quality checks. They execute safely without code injection risks using a declarative rule syntax.</p> <p>WorkflowPacks are YAML-based process orchestration definitions that combine multiple steps (validation, calculations, AI inference, approvals, integrations) into automated workflows.</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#why-use-packs","title":"Why Use Packs?","text":"<ul> <li>Version Control: Packs are stored in Git, providing full audit history</li> <li>Reusability: Create once, use across multiple tenants and suites</li> <li>Compliance: Built-in regulatory framework tagging and documentation</li> <li>Marketplace: Share and monetize packs in the CORTX Marketplace</li> <li>Safety: Declarative syntax prevents code injection attacks</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#prerequisites","title":"Prerequisites","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#required-tools","title":"Required Tools","text":"<ul> <li>Git: Version control for pack repositories</li> <li>Text Editor: VS Code (recommended), Sublime, or similar</li> <li>YAML/JSON Validator: <code>check-jsonschema</code> or IDE plugins</li> <li>CORTX CLI: (Optional) For pack testing and deployment</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#required-knowledge","title":"Required Knowledge","text":"<ul> <li>Basic understanding of JSON and YAML syntax</li> <li>Familiarity with the compliance domain (HIPAA, FedRAMP, etc.)</li> <li>Understanding of the CORTX Platform architecture</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#access-requirements","title":"Access Requirements","text":"<ul> <li>GitHub Access: Write access to <code>cortx-packs</code> repository</li> <li>CORTX Platform: Account with <code>PACK_AUTHOR</code> role</li> <li>Development Environment: Access to dev/staging environments</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-1-creating-rulepacks","title":"Part 1: Creating RulePacks","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#rulepack-structure","title":"RulePack Structure","text":"<p>A RulePack consists of two main sections:</p> <ol> <li>Metadata: Information about the pack (ID, version, compliance tags)</li> <li>Rules: Array of validation rules to execute</li> </ol> <p>Minimal Example:</p> <pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"example-validation-v1\",\n    \"version\": \"1.0.0\",\n    \"compliance\": [\"NIST-800-53-AC-3\"],\n    \"created_by\": \"jane.doe@agency.gov\",\n    \"created_at\": \"2025-10-01T00:00:00Z\",\n    \"description\": \"Example validation rules for user account data\"\n  },\n  \"rules\": [\n    {\n      \"rule_id\": \"USER-001\",\n      \"type\": \"FATAL\",\n      \"field\": \"username\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[a-z0-9_-]{3,64}$\",\n      \"error_message\": \"Username must be 3-64 characters (lowercase, numbers, hyphens, underscores only)\"\n    }\n  ]\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#metadata-fields","title":"Metadata Fields","text":"Field Required Type Description <code>pack_id</code> Yes string Unique identifier (kebab-case, e.g., <code>federal-gtas-v1</code>) <code>version</code> Yes string Semantic version (e.g., <code>1.0.0</code>) <code>compliance</code> No array Regulatory frameworks (e.g., <code>[\"FedRAMP\", \"HIPAA\"]</code>) <code>created_by</code> Yes string Author email or identifier <code>created_at</code> Yes string ISO 8601 timestamp <code>description</code> Yes string Human-readable description of the pack <code>tags</code> No array Searchable tags for marketplace discovery <code>license</code> No string License (default: <code>MIT</code>)"},{"location":"packs/PACK_AUTHORING_GUIDE/#rule-fields","title":"Rule Fields","text":"Field Required Type Description <code>rule_id</code> Yes string Unique rule identifier (e.g., <code>GTAS-001</code>) <code>type</code> Yes enum Severity: <code>FATAL</code>, <code>WARNING</code>, or <code>INFO</code> <code>field</code> Yes string Data field to validate (dot notation supported) <code>operator</code> Yes enum Comparison operator (see operators below) <code>value</code> Conditional any Expected value (required for most operators) <code>pattern</code> Conditional string Regex pattern (for <code>matches</code> operator) <code>error_message</code> Yes string User-friendly error message <code>compliance_ref</code> No string Regulatory reference (e.g., <code>NIST-800-53-AC-2</code>) <code>remediation</code> No string How to fix the error"},{"location":"packs/PACK_AUTHORING_GUIDE/#supported-operators","title":"Supported Operators","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#comparison-operators","title":"Comparison Operators","text":"<ul> <li><code>==</code>: Equal to</li> <li><code>!=</code>: Not equal to</li> <li><code>&lt;</code>: Less than</li> <li><code>&lt;=</code>: Less than or equal to</li> <li><code>&gt;</code>: Greater than</li> <li><code>&gt;=</code>: Greater than or equal to</li> </ul> <p>Example:</p> <pre><code>{\n  \"rule_id\": \"AMOUNT-001\",\n  \"type\": \"FATAL\",\n  \"field\": \"transaction_amount\",\n  \"operator\": \"&gt;\",\n  \"value\": 0,\n  \"error_message\": \"Transaction amount must be positive\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#membership-operators","title":"Membership Operators","text":"<ul> <li><code>in</code>: Value is in list</li> <li><code>not_in</code>: Value is not in list</li> </ul> <p>Example:</p> <pre><code>{\n  \"rule_id\": \"STATUS-001\",\n  \"type\": \"FATAL\",\n  \"field\": \"account_status\",\n  \"operator\": \"in\",\n  \"value\": [\"active\", \"pending\", \"suspended\"],\n  \"error_message\": \"Account status must be active, pending, or suspended\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#string-operators","title":"String Operators","text":"<ul> <li><code>contains</code>: String contains substring</li> <li><code>starts_with</code>: String starts with prefix</li> <li><code>ends_with</code>: String ends with suffix</li> <li><code>matches</code>: String matches regex pattern</li> </ul> <p>Example:</p> <pre><code>{\n  \"rule_id\": \"EMAIL-001\",\n  \"type\": \"FATAL\",\n  \"field\": \"email\",\n  \"operator\": \"matches\",\n  \"pattern\": \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\",\n  \"error_message\": \"Invalid email format\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#null-check-operators","title":"Null Check Operators","text":"<ul> <li><code>is_null</code>: Field is null or undefined</li> <li><code>is_not_null</code>: Field has a value</li> </ul> <p>Example:</p> <pre><code>{\n  \"rule_id\": \"REQUIRED-001\",\n  \"type\": \"FATAL\",\n  \"field\": \"taxpayer_id\",\n  \"operator\": \"is_not_null\",\n  \"error_message\": \"Taxpayer ID is required\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#nested-field-access","title":"Nested Field Access","text":"<p>Use dot notation to access nested fields:</p> <pre><code>{\n  \"rule_id\": \"NESTED-001\",\n  \"type\": \"FATAL\",\n  \"field\": \"address.zip_code\",\n  \"operator\": \"matches\",\n  \"pattern\": \"^\\\\d{5}(-\\\\d{4})?$\",\n  \"error_message\": \"ZIP code must be 5 digits or 5+4 format\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#array-field-access","title":"Array Field Access","text":"<p>Use bracket notation for array elements:</p> <pre><code>{\n  \"rule_id\": \"ARRAY-001\",\n  \"type\": \"WARNING\",\n  \"field\": \"items[0].price\",\n  \"operator\": \"&gt;\",\n  \"value\": 0,\n  \"error_message\": \"First item must have positive price\"\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#severity-levels","title":"Severity Levels","text":"<p>FATAL: - Blocks processing: Data cannot proceed - Use for: Critical compliance violations, data corruption risks - Example: Missing required fields, invalid formats</p> <p>WARNING: - Allows processing: Data proceeds with warnings - Use for: Quality issues, potential problems - Example: Missing optional fields, unusual values</p> <p>INFO: - Informational only: No impact on processing - Use for: Audit trails, recommendations - Example: Data quality metrics, optimization suggestions</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#example-gtas-trial-balance-rulepack","title":"Example: GTAS Trial Balance RulePack","text":"<pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"federal-gtas-trial-balance-v1\",\n    \"version\": \"1.0.0\",\n    \"compliance\": [\"OMB-A-136\", \"GTAS-2024\"],\n    \"created_by\": \"treasury-validation-team\",\n    \"created_at\": \"2025-09-30T00:00:00Z\",\n    \"description\": \"Treasury GTAS trial balance validation rules for FY 2024\",\n    \"tags\": [\"federal\", \"treasury\", \"gtas\", \"trial-balance\"]\n  },\n  \"rules\": [\n    {\n      \"rule_id\": \"GTAS-001\",\n      \"type\": \"FATAL\",\n      \"field\": \"TAS\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[0-9]{3}-[0-9]{4}$\",\n      \"error_message\": \"TAS must be in format ###-#### (e.g., 012-3456)\",\n      \"compliance_ref\": \"GTAS Validation Rule #1\",\n      \"remediation\": \"Verify TAS with Treasury Account Symbol Directory\"\n    },\n    {\n      \"rule_id\": \"GTAS-002\",\n      \"type\": \"FATAL\",\n      \"field\": \"USSGL_account\",\n      \"operator\": \"matches\",\n      \"pattern\": \"^[0-9]{6}$\",\n      \"error_message\": \"USSGL account must be 6 digits\",\n      \"compliance_ref\": \"GTAS Validation Rule #2\",\n      \"remediation\": \"Use valid USSGL account from FY 2024 USSGL Crosswalk\"\n    },\n    {\n      \"rule_id\": \"GTAS-003\",\n      \"type\": \"FATAL\",\n      \"field\": \"debit_credit_indicator\",\n      \"operator\": \"in\",\n      \"value\": [\"D\", \"C\"],\n      \"error_message\": \"Debit/Credit indicator must be 'D' or 'C'\",\n      \"compliance_ref\": \"GTAS Validation Rule #3\"\n    },\n    {\n      \"rule_id\": \"GTAS-004\",\n      \"type\": \"FATAL\",\n      \"field\": \"amount\",\n      \"operator\": \"is_not_null\",\n      \"error_message\": \"Amount is required\",\n      \"compliance_ref\": \"GTAS Validation Rule #4\"\n    },\n    {\n      \"rule_id\": \"GTAS-005\",\n      \"type\": \"WARNING\",\n      \"field\": \"amount\",\n      \"operator\": \"&gt;=\",\n      \"value\": 0.01,\n      \"error_message\": \"Amount should be at least $0.01 (possible data quality issue)\",\n      \"compliance_ref\": \"GTAS Best Practice\"\n    },\n    {\n      \"rule_id\": \"GTAS-006\",\n      \"type\": \"FATAL\",\n      \"field\": \"fiscal_year\",\n      \"operator\": \"==\",\n      \"value\": 2024,\n      \"error_message\": \"Fiscal year must be 2024 for this submission\",\n      \"compliance_ref\": \"GTAS Validation Rule #6\"\n    }\n  ]\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-2-creating-workflowpacks","title":"Part 2: Creating WorkflowPacks","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#workflowpack-structure","title":"WorkflowPack Structure","text":"<p>A WorkflowPack consists of:</p> <ol> <li>Workflow Metadata: ID, version, description</li> <li>Steps: Ordered array of workflow steps</li> <li>Configurations: Step-specific settings</li> </ol> <p>Minimal Example:</p> <pre><code>workflow_id: example-workflow-v1\nversion: 1.0.0\ndescription: Simple workflow demonstrating basic steps\n\nmetadata:\n  compliance: [SOC2-CC6.1]\n  created_by: jane.doe@agency.gov\n  created_at: \"2025-10-01T00:00:00Z\"\n\nsteps:\n  - id: validate_data\n    type: validation\n    config:\n      rulepack: example-validation-v1\n      on_failure: halt\n\n  - id: send_notification\n    type: data-sink\n    config:\n      endpoint: https://api.example.com/notify\n      method: POST\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#workflow-metadata","title":"Workflow Metadata","text":"Field Required Type Description <code>workflow_id</code> Yes string Unique workflow identifier <code>version</code> Yes string Semantic version <code>description</code> Yes string Workflow description <code>metadata.compliance</code> No array Compliance frameworks <code>metadata.created_by</code> Yes string Author identifier <code>metadata.created_at</code> Yes string ISO 8601 timestamp <code>metadata.tags</code> No array Searchable tags"},{"location":"packs/PACK_AUTHORING_GUIDE/#step-types","title":"Step Types","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#1-data-source-data-source","title":"1. Data Source (<code>data-source</code>)","text":"<p>Purpose: Ingest data from external sources</p> <p>Config:</p> <pre><code>- id: ingest_csv\n  type: data-source\n  config:\n    format: csv  # csv, json, xml, api\n    source: s3://bucket/data.csv\n    schema: trial-balance-v1\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#2-validation-validation","title":"2. Validation (<code>validation</code>)","text":"<p>Purpose: Execute RulePack validation</p> <p>Config:</p> <pre><code>- id: validate_rules\n  type: validation\n  config:\n    rulepack: federal-gtas-v1\n    on_failure: halt  # halt, continue, retry\n    max_retries: 3\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#3-calculation-calculation","title":"3. Calculation (<code>calculation</code>)","text":"<p>Purpose: Perform data transformations and calculations</p> <p>Config:</p> <pre><code>- id: calculate_total\n  type: calculation\n  config:\n    formula: sum(input.debits) - sum(input.credits)\n    output_field: net_balance\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#4-decision-decision","title":"4. Decision (<code>decision</code>)","text":"<p>Purpose: Conditional branching</p> <p>Config:</p> <pre><code>- id: check_threshold\n  type: decision\n  config:\n    condition: input.amount &gt; 10000\n    on_true: escalate_approval\n    on_false: auto_approve\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#5-approval-approval","title":"5. Approval (<code>approval</code>)","text":"<p>Purpose: Human-in-the-loop review</p> <p>Config:</p> <pre><code>- id: manager_approval\n  type: approval\n  config:\n    role: COMPLIANCE_OFFICER\n    timeout_hours: 24\n    auto_approve_on_timeout: false\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#6-ai-inference-ai-inference","title":"6. AI Inference (<code>ai-inference</code>)","text":"<p>Purpose: LLM-powered analysis and recommendations</p> <p>Config:</p> <pre><code>- id: anomaly_detection\n  type: ai-inference\n  config:\n    model: gemini-1.5-flash\n    prompt: \"Analyze this transaction for anomalies: {{input}}\"\n    max_tokens: 500\n    temperature: 0.0\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#7-data-sink-data-sink","title":"7. Data Sink (<code>data-sink</code>)","text":"<p>Purpose: Output results to external systems</p> <p>Config:</p> <pre><code>- id: submit_gtas\n  type: data-sink\n  config:\n    endpoint: https://gtas.treasury.gov/api/submit\n    method: POST\n    headers:\n      Content-Type: application/json\n      Authorization: Bearer {{env.GTAS_API_KEY}}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#example-gtas-monthly-submission-workflow","title":"Example: GTAS Monthly Submission Workflow","text":"<pre><code>workflow_id: gtas-monthly-submission-v1\nversion: 1.0.0\ndescription: Monthly GTAS trial balance submission workflow for federal agencies\n\nmetadata:\n  compliance: [OMB-A-136, GTAS-2024, FISMA]\n  created_by: treasury-workflow-team\n  created_at: \"2025-09-30T00:00:00Z\"\n  tags: [federal, treasury, gtas, monthly-reporting]\n\nsteps:\n  # Step 1: Ingest trial balance data\n  - id: ingest_trial_balance\n    type: data-source\n    config:\n      format: csv\n      source: s3://agency-financial-data/trial-balance.csv\n      schema: gtas-trial-balance-v1\n\n  # Step 2: Validate GTAS rules\n  - id: validate_gtas_rules\n    type: validation\n    config:\n      rulepack: federal-gtas-trial-balance-v1\n      on_failure: halt\n      max_retries: 0\n\n  # Step 3: Calculate net balance\n  - id: calculate_net_balance\n    type: calculation\n    config:\n      formula: sum(debits) - sum(credits)\n      output_field: net_balance\n\n  # Step 4: Check if balance is zero\n  - id: check_balance\n    type: decision\n    config:\n      condition: abs(net_balance) &lt; 0.01\n      on_true: ai_review\n      on_false: flag_unbalanced\n\n  # Step 5: AI review for unusual patterns\n  - id: ai_review\n    type: ai-inference\n    config:\n      model: gemini-1.5-flash\n      prompt: |\n        Review this GTAS trial balance submission for unusual patterns or anomalies.\n        Data: {{input}}\n\n        Flag any:\n        - Unusually large amounts\n        - Unexpected USSGL account usage\n        - Missing TAS components\n      max_tokens: 1000\n      temperature: 0.0\n\n  # Step 6: Certifying official approval\n  - id: certifying_official_approval\n    type: approval\n    config:\n      role: CERTIFYING_OFFICIAL\n      timeout_hours: 48\n      auto_approve_on_timeout: false\n      notification:\n        email: certifying.official@agency.gov\n        subject: GTAS Submission Approval Required\n\n  # Step 7: Submit to GTAS\n  - id: submit_to_gtas\n    type: data-sink\n    config:\n      endpoint: https://gtas.treasury.gov/api/v2/submit\n      method: POST\n      headers:\n        Content-Type: application/json\n        Authorization: Bearer {{env.GTAS_API_KEY}}\n      payload:\n        agency_code: \"{{input.agency_code}}\"\n        fiscal_year: 2024\n        fiscal_period: \"{{input.fiscal_period}}\"\n        data: \"{{input.validated_data}}\"\n\n  # Step 8: Archive submission\n  - id: archive_submission\n    type: data-sink\n    config:\n      endpoint: s3://agency-gtas-archive/{{fiscal_year}}/{{fiscal_period}}/\n      format: json\n      retention_days: 2555  # 7 years\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#step-dependencies","title":"Step Dependencies","text":"<p>Steps execute in order by default. Use <code>depends_on</code> for explicit dependencies:</p> <pre><code>steps:\n  - id: step1\n    type: validation\n    config:\n      rulepack: pack-v1\n\n  - id: step2a\n    type: calculation\n    depends_on: [step1]\n    config:\n      formula: input.amount * 1.05\n\n  - id: step2b\n    type: ai-inference\n    depends_on: [step1]\n    config:\n      model: gemini-1.5-flash\n      prompt: \"Analyze {{input}}\"\n\n  # step2a and step2b run in parallel after step1\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#error-handling","title":"Error Handling","text":"<p>Define error handling strategies per step:</p> <pre><code>- id: external_api_call\n  type: data-sink\n  config:\n    endpoint: https://api.example.com\n    method: POST\n  error_handling:\n    on_failure: retry\n    max_retries: 3\n    retry_delay_seconds: 5\n    backoff_multiplier: 2  # Exponential backoff\n    fallback_step: log_failure\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#compensation-saga-pattern","title":"Compensation (Saga Pattern)","text":"<p>For distributed transactions, define compensation logic:</p> <pre><code>workflow_id: distributed-transaction-v1\nversion: 1.0.0\n\nsaga:\n  enabled: true\n  compensation_order: reverse  # Rollback in reverse order\n\nsteps:\n  - id: reserve_funds\n    type: data-sink\n    config:\n      endpoint: https://api.bank.com/reserve\n    compensate:\n      endpoint: https://api.bank.com/release\n      method: POST\n\n  - id: create_order\n    type: data-sink\n    config:\n      endpoint: https://api.orders.com/create\n    compensate:\n      endpoint: https://api.orders.com/cancel\n      method: DELETE\n\non_failure:\n  - execute_compensations: true\n  - notify: failure_alert\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-3-testing-packs","title":"Part 3: Testing Packs","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#local-testing","title":"Local Testing","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#rulepack-testing","title":"RulePack Testing","text":"<p>Test Data Structure:</p> <pre><code>{\n  \"rulepack_id\": \"federal-gtas-v1\",\n  \"test_cases\": [\n    {\n      \"name\": \"Valid TAS format\",\n      \"input\": {\n        \"TAS\": \"012-3456\",\n        \"USSGL_account\": \"101000\",\n        \"debit_credit_indicator\": \"D\",\n        \"amount\": 1000.00,\n        \"fiscal_year\": 2024\n      },\n      \"expected\": {\n        \"is_valid\": true,\n        \"violations\": []\n      }\n    },\n    {\n      \"name\": \"Invalid TAS format\",\n      \"input\": {\n        \"TAS\": \"12-3456\",\n        \"USSGL_account\": \"101000\",\n        \"debit_credit_indicator\": \"D\",\n        \"amount\": 1000.00,\n        \"fiscal_year\": 2024\n      },\n      \"expected\": {\n        \"is_valid\": false,\n        \"violations\": [\n          {\n            \"rule_id\": \"GTAS-001\",\n            \"field\": \"TAS\",\n            \"severity\": \"FATAL\"\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre> <p>Run Tests:</p> <pre><code># Using CORTX CLI\ncortx pack test rulepack ./federal-gtas-v1.json --test-data ./test-cases.json\n\n# Using Python\npython -m cortx.validation.test --rulepack federal-gtas-v1.json --data test-cases.json\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#workflowpack-testing","title":"WorkflowPack Testing","text":"<p>Simulation Mode:</p> <pre><code># Simulate workflow execution without external calls\ncortx pack test workflow ./gtas-workflow.yaml --simulate --input ./sample-data.json\n\n# Execute in dev environment\ncortx pack test workflow ./gtas-workflow.yaml --env dev --input ./sample-data.json\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#automated-testing-cicd","title":"Automated Testing (CI/CD)","text":"<p>GitHub Actions Workflow:</p> <pre><code>name: Test RulePacks\n\non:\n  pull_request:\n    paths:\n      - 'rulepacks/**/*.json'\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Validate JSON Schema\n        run: |\n          pip install check-jsonschema\n          check-jsonschema --schemafile schemas/rulepack-schema.json rulepacks/**/*.json\n\n      - name: Run RulePack Tests\n        run: |\n          python -m pytest tests/rulepacks/ --cov=rulepacks --cov-report=xml\n\n      - name: Upload Coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#performance-testing","title":"Performance Testing","text":"<p>Load Test Example:</p> <pre><code>import asyncio\nfrom cortx.validation import execute_rulepack\n\nasync def load_test():\n    \"\"\"Test RulePack with 1M records.\"\"\"\n    rulepack = load_json(\"federal-gtas-v1.json\")\n\n    # Generate 1M test records\n    records = [generate_test_record() for _ in range(1_000_000)]\n\n    start = time.time()\n    results = await execute_rulepack(rulepack, records)\n    duration = time.time() - start\n\n    print(f\"Processed 1M records in {duration:.2f}s\")\n    assert duration &lt; 30, \"Performance target: &lt;30s for 1M records\"\n\nasyncio.run(load_test())\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-4-versioning-deployment","title":"Part 4: Versioning &amp; Deployment","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#semantic-versioning","title":"Semantic Versioning","text":"<p>Follow semantic versioning (<code>MAJOR.MINOR.PATCH</code>):</p> <ul> <li>MAJOR: Breaking changes (requires re-certification)</li> <li>MINOR: Backward-compatible features (new rules, optional fields)</li> <li>PATCH: Bug fixes (error message updates, typos)</li> </ul> <p>Examples: - <code>1.0.0</code> \u2192 <code>1.0.1</code>: Fixed typo in error message - <code>1.0.1</code> \u2192 <code>1.1.0</code>: Added 5 new validation rules - <code>1.1.0</code> \u2192 <code>2.0.0</code>: Changed rule operator (breaking change)</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#changelog","title":"Changelog","text":"<p>Maintain a changelog for each pack:</p> <pre><code># Changelog: federal-gtas-v1\n\n## [1.2.0] - 2025-10-15\n### Added\n- GTAS-007: Validate fiscal period range (1-12)\n- GTAS-008: Check for duplicate TAS entries\n\n### Changed\n- GTAS-005: Updated warning threshold to $0.10\n\n## [1.1.0] - 2025-09-30\n### Added\n- GTAS-006: Fiscal year validation\n\n## [1.0.0] - 2025-09-01\n### Added\n- Initial release with 5 core validation rules\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#deployment-process","title":"Deployment Process","text":"<p>1. Development:</p> <pre><code># Create feature branch\ngit checkout -b feature/add-gtas-rule-007\n\n# Edit pack\nvim rulepacks/federal/gtas/federal-gtas-v1.json\n\n# Test locally\ncortx pack test rulepack ./federal-gtas-v1.json\n\n# Commit changes\ngit add rulepacks/federal/gtas/federal-gtas-v1.json\ngit commit -m \"feat(gtas): add fiscal period validation (GTAS-007)\"\n</code></pre> <p>2. Pull Request:</p> <pre><code># Push to GitHub\ngit push origin feature/add-gtas-rule-007\n\n# Create PR with description:\n# - What changed\n# - Why (compliance requirement, bug fix, etc.)\n# - Test results\n# - Breaking changes (if any)\n</code></pre> <p>3. Review &amp; Approval: - Automated Checks: Schema validation, unit tests - Human Review: Business analyst reviews functional correctness - Compliance Review: Compliance officer certifies regulatory alignment - Merge: Approved PRs merged to <code>main</code></p> <p>4. Deployment:</p> <pre><code># Tag release\ngit tag -a v1.2.0 -m \"Release v1.2.0: Add fiscal period validation\"\ngit push origin v1.2.0\n\n# Deploy to staging\ncortx pack deploy federal-gtas-v1 --env staging --version 1.2.0\n\n# Smoke test in staging\ncortx pack test workflow gtas-monthly-submission-v1 --env staging\n\n# Deploy to production\ncortx pack deploy federal-gtas-v1 --env prod --version 1.2.0\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-5-best-practices","title":"Part 5: Best Practices","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#rulepack-best-practices","title":"RulePack Best Practices","text":"<p>1. Use Descriptive Rule IDs:</p> <pre><code>// Good\n\"rule_id\": \"GTAS-TAS-FORMAT-001\"\n\n// Bad\n\"rule_id\": \"RULE1\"\n</code></pre> <p>2. Provide Actionable Error Messages:</p> <pre><code>// Good\n\"error_message\": \"TAS must be in format ###-#### (e.g., 012-3456). Found: {{value}}\"\n\n// Bad\n\"error_message\": \"Invalid TAS\"\n</code></pre> <p>3. Tag Compliance References:</p> <pre><code>{\n  \"rule_id\": \"HIPAA-ACCESS-001\",\n  \"compliance_ref\": \"HIPAA Security Rule \u00a7164.312(a)(1)\",\n  \"remediation\": \"Implement unique user identification per \u00a7164.312(a)(2)(i)\"\n}\n</code></pre> <p>4. Use Appropriate Severity: - FATAL: Missing required fields, data corruption risks - WARNING: Quality issues, potential problems - INFO: Audit trails, optimization suggestions</p> <p>5. Order Rules by Dependency:</p> <pre><code>{\n  \"rules\": [\n    // First: Check required fields exist\n    {\"rule_id\": \"REQ-001\", \"field\": \"amount\", \"operator\": \"is_not_null\"},\n\n    // Then: Validate field values\n    {\"rule_id\": \"VAL-001\", \"field\": \"amount\", \"operator\": \"&gt;\", \"value\": 0}\n  ]\n}\n</code></pre>"},{"location":"packs/PACK_AUTHORING_GUIDE/#workflowpack-best-practices","title":"WorkflowPack Best Practices","text":"<p>1. Use Meaningful Step IDs:</p> <pre><code># Good\n- id: validate_hipaa_compliance\n- id: certifying_official_approval\n- id: submit_to_gtas\n\n# Bad\n- id: step1\n- id: step2\n</code></pre> <p>2. Handle Errors Gracefully:</p> <pre><code>- id: external_api_call\n  type: data-sink\n  config:\n    endpoint: https://api.example.com\n  error_handling:\n    on_failure: retry\n    max_retries: 3\n    fallback_step: log_error_and_notify\n</code></pre> <p>3. Use Environment Variables for Secrets:</p> <pre><code>config:\n  headers:\n    Authorization: Bearer {{env.API_KEY}}  # Good\n    # Authorization: Bearer sk_live_abc123  # NEVER hardcode secrets\n</code></pre> <p>4. Document Complex Workflows:</p> <pre><code>workflow_id: complex-reconciliation-v1\nversion: 1.0.0\ndescription: |\n  Multi-step reconciliation workflow with the following stages:\n  1. Ingest trial balance from agency system\n  2. Validate against 204 GTAS rules\n  3. Perform 3-way reconciliation (GL, sub-ledger, GTAS)\n  4. AI-powered anomaly detection\n  5. Certifying official approval\n  6. Submit to Treasury GTAS system\n  7. Archive for 7-year retention\n</code></pre> <p>5. Test with Realistic Data: - Use production-like data volumes - Include edge cases (empty fields, special characters, etc.) - Test error scenarios (network failures, timeouts, etc.)</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#part-6-marketplace-submission","title":"Part 6: Marketplace Submission","text":""},{"location":"packs/PACK_AUTHORING_GUIDE/#preparing-for-marketplace","title":"Preparing for Marketplace","text":"<p>1. Complete Metadata:</p> <pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"healthcare-hipaa-audit-v1\",\n    \"version\": \"1.0.0\",\n    \"compliance\": [\"HIPAA-Security-Rule\", \"HIPAA-Privacy-Rule\"],\n    \"created_by\": \"healthcare-compliance-experts\",\n    \"created_at\": \"2025-10-01T00:00:00Z\",\n    \"description\": \"Comprehensive HIPAA compliance audit RulePack with 48 security controls\",\n    \"tags\": [\"healthcare\", \"hipaa\", \"audit\", \"security\", \"privacy\"],\n    \"license\": \"MIT\",\n    \"documentation_url\": \"https://docs.example.com/packs/hipaa-audit\",\n    \"support_email\": \"support@example.com\",\n    \"marketplace\": {\n      \"category\": \"Compliance\",\n      \"pricing\": \"free\",  // or \"paid\"\n      \"certification_tier\": \"certified\"  // official, certified, community\n    }\n  }\n}\n</code></pre> <p>2. Create Documentation: - README.md: Overview, use cases, installation - USAGE.md: Step-by-step guide with examples - TESTING.md: How to test the pack - CHANGELOG.md: Version history</p> <p>3. Add Examples:</p> <pre><code>packs/healthcare/hipaa-audit/\n\u251c\u2500\u2500 pack.json\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 USAGE.md\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 sample-input.json\n\u2502   \u251c\u2500\u2500 sample-output.json\n\u2502   \u2514\u2500\u2500 test-cases.json\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_hipaa_audit.py\n</code></pre> <p>4. Submit for Certification:</p> <pre><code># Submit to marketplace\ncortx marketplace submit healthcare-hipaa-audit-v1 \\\n  --tier certified \\\n  --category compliance \\\n  --pricing free\n\n# Certification process:\n# 1. Automated testing (schema, tests, security scan)\n# 2. Compliance review (regulatory alignment)\n# 3. Quality review (code quality, documentation)\n# 4. Approval (marketplace team)\n</code></pre> <p>5. Monitor Usage: - Track downloads and ratings - Respond to user feedback - Release updates based on user needs</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#resources","title":"Resources","text":"<p>Note: Use relative links for all internal docs to satisfy MkDocs strict validation.</p>"},{"location":"packs/PACK_AUTHORING_GUIDE/#documentation","title":"Documentation","text":"<ul> <li>RulePack Schema Reference</li> <li>WorkflowPack Schema Reference</li> <li>Pack Governance</li> <li>Marketplace Vision</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#tools","title":"Tools","text":"<ul> <li>CORTX CLI: <code>npm install -g @cortx/cli</code></li> <li>Schema Validator: <code>pip install check-jsonschema</code></li> <li>VS Code Extension: CORTX Pack Authoring (coming soon)</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#support","title":"Support","text":"<ul> <li>Slack: #pack-authoring</li> <li>Email: pack-support@sinergysolutions.ai</li> <li>Office Hours: Wednesdays 2-3 PM ET</li> </ul>"},{"location":"packs/PACK_AUTHORING_GUIDE/#appendix-complete-example","title":"Appendix: Complete Example","text":"<p>See the <code>cortx-packs</code> repository for complete examples: - <code>/rulepacks/federal/gtas/federal-gtas-v1.json</code> (204 rules) - <code>/workflowpacks/federal/gtas-submission/gtas-monthly-v1.yaml</code> - <code>/rulepacks/healthcare/hipaa/hipaa-security-v1.json</code> (48 rules)</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Review Cycle: Quarterly - Next Review: 2026-01-01 - Approvers: Platform Architecture Team</p>"},{"location":"packs/PACK_GOVERNANCE/","title":"Pack Governance &amp; Approval Process","text":"<p>Version: 1.0.0 Last Updated: 2025-10-01 Owner: Compliance &amp; Platform Governance Team Classification: Internal</p>"},{"location":"packs/PACK_GOVERNANCE/#purpose","title":"Purpose","text":"<p>This document establishes the governance framework for RulePacks and WorkflowPacks in the CORTX Platform, including approval workflows, versioning policies, certification tiers, and quality standards.</p>"},{"location":"packs/PACK_GOVERNANCE/#governance-principles","title":"Governance Principles","text":""},{"location":"packs/PACK_GOVERNANCE/#1-quality-over-speed","title":"1. Quality Over Speed","text":"<ul> <li>Thoroughly tested packs prevent downstream issues</li> <li>Quality gates cannot be bypassed</li> <li>Technical debt is addressed proactively</li> </ul>"},{"location":"packs/PACK_GOVERNANCE/#2-compliance-first","title":"2. Compliance First","text":"<ul> <li>All packs must align with regulatory requirements</li> <li>Compliance officer review is mandatory for regulated industries</li> <li>Audit trails for all changes</li> </ul>"},{"location":"packs/PACK_GOVERNANCE/#3-transparency","title":"3. Transparency","text":"<ul> <li>All pack changes are publicly visible in Git</li> <li>Review feedback is documented</li> <li>Rejection reasons are clear and actionable</li> </ul>"},{"location":"packs/PACK_GOVERNANCE/#4-community-collaboration","title":"4. Community Collaboration","text":"<ul> <li>Pack authors can be internal or external</li> <li>Community feedback drives improvements</li> <li>Knowledge sharing through documentation</li> </ul>"},{"location":"packs/PACK_GOVERNANCE/#pack-lifecycle","title":"Pack Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Draft   \u2502  Author creates pack\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Review  \u2502  Business analyst reviews\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Compliance\u2502  Compliance officer certifies\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Testing \u2502  QA validates with test data\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Approval \u2502  Admin approves for deployment\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Deployment\u2502  Pushed to production registry\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Active   \u2502  Available for use\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"packs/PACK_GOVERNANCE/#approval-workflow","title":"Approval Workflow","text":""},{"location":"packs/PACK_GOVERNANCE/#stage-1-draft","title":"Stage 1: Draft","text":"<p>Owner: Pack Author</p> <p>Activities: - Create pack (RulePack JSON or WorkflowPack YAML) - Write documentation (README, USAGE, CHANGELOG) - Create test cases - Validate against schema</p> <p>Quality Gates: - [ ] Schema validation passes - [ ] Basic test cases exist - [ ] Documentation complete</p> <p>Transition: Submit for review via Pull Request</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-2-business-review","title":"Stage 2: Business Review","text":"<p>Owner: Business Analyst / Functional Lead</p> <p>Activities: - Review functional correctness - Validate business rules align with requirements - Check error messages are clear and actionable - Verify test coverage is adequate</p> <p>Quality Gates: - [ ] Business requirements met - [ ] Rules/steps logically correct - [ ] Error messages user-friendly - [ ] Edge cases handled</p> <p>Duration: 2-3 business days</p> <p>Outcomes: - Approved: Move to compliance review - Needs Changes: Return to author with feedback - Rejected: Close PR with explanation</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-3-compliance-review","title":"Stage 3: Compliance Review","text":"<p>Owner: Compliance Officer</p> <p>Activities: - Verify regulatory alignment - Check compliance tags are accurate - Validate control mappings (NIST, HIPAA, etc.) - Ensure audit trail requirements met</p> <p>Quality Gates: - [ ] Compliance frameworks correctly tagged - [ ] Control references accurate - [ ] Regulatory requirements satisfied - [ ] Audit logging adequate</p> <p>Duration: 3-5 business days</p> <p>Outcomes: - Certified: Move to testing - Conditional Approval: Minor changes required - Rejected: Non-compliant, return to author</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-4-testing","title":"Stage 4: Testing","text":"<p>Owner: QA Lead</p> <p>Activities: - Execute test cases - Performance testing (RulePacks: 1M records &lt;30s) - Security scanning (no code injection, secrets) - Integration testing with platform</p> <p>Quality Gates: - [ ] All test cases pass - [ ] Performance benchmarks met - [ ] No security vulnerabilities - [ ] Integration tests successful</p> <p>Duration: 3-5 business days</p> <p>Outcomes: - Passed: Move to final approval - Failed: Return to author with test results</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-5-final-approval","title":"Stage 5: Final Approval","text":"<p>Owner: Platform Admin</p> <p>Activities: - Review all prior approvals - Verify pack metadata - Check versioning is correct - Approve deployment</p> <p>Quality Gates: - [ ] All prior stages approved - [ ] Version number correct - [ ] Deployment plan documented - [ ] Rollback plan exists</p> <p>Duration: 1-2 business days</p> <p>Outcomes: - Approved: Deploy to production - Rejected: Rare; address final concerns</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-6-deployment","title":"Stage 6: Deployment","text":"<p>Owner: DevOps / Platform Team</p> <p>Activities: - Tag release in Git - Deploy to production registry - Update documentation - Notify stakeholders</p> <p>Quality Gates: - [ ] Git tag created - [ ] Production registry updated - [ ] Documentation published - [ ] Announcement sent</p>"},{"location":"packs/PACK_GOVERNANCE/#stage-7-active","title":"Stage 7: Active","text":"<p>Owner: Pack Maintainers</p> <p>Ongoing Activities: - Monitor pack usage - Address bug reports - Plan future enhancements - Deprecate when obsolete</p>"},{"location":"packs/PACK_GOVERNANCE/#versioning-policy","title":"Versioning Policy","text":""},{"location":"packs/PACK_GOVERNANCE/#semantic-versioning","title":"Semantic Versioning","text":"<p>Format: <code>MAJOR.MINOR.PATCH</code></p> <p>MAJOR Version (X.0.0): - Breaking changes to pack structure - Rule operator changes - Workflow step type changes - Requires re-certification</p> <p>MINOR Version (x.Y.0): - Backward-compatible additions - New rules or workflow steps - Optional field additions - Standard review process</p> <p>PATCH Version (x.y.Z): - Bug fixes - Error message improvements - Documentation updates - Fast-track approval</p> <p>Examples:</p> <pre><code>1.0.0 \u2192 1.0.1: Fixed typo in error message (PATCH)\n1.0.1 \u2192 1.1.0: Added 5 new rules (MINOR)\n1.1.0 \u2192 2.0.0: Changed rule operator from '==' to 'matches' (MAJOR)\n</code></pre>"},{"location":"packs/PACK_GOVERNANCE/#version-compatibility","title":"Version Compatibility","text":"<p>Backward Compatibility: - MINOR and PATCH versions must be backward compatible - Existing integrations must not break - Default behavior unchanged</p> <p>Breaking Changes: - Require MAJOR version bump - Documented in CHANGELOG - Migration guide provided - Deprecation notice (if replacing older pack)</p>"},{"location":"packs/PACK_GOVERNANCE/#deprecation-policy","title":"Deprecation Policy","text":"<p>Deprecation Timeline: 1. Announce: Deprecation notice 90 days before removal 2. Mark: Tag pack as deprecated in metadata 3. Migrate: Provide migration guide to newer version 4. Remove: After 90 days, remove from active registry</p> <p>Example:</p> <pre><code>{\n  \"metadata\": {\n    \"pack_id\": \"legacy-gtas-v1\",\n    \"version\": \"1.0.0\",\n    \"deprecated\": true,\n    \"deprecated_at\": \"2025-10-01\",\n    \"replacement\": \"federal-gtas-v2\",\n    \"deprecation_reason\": \"Replaced by v2 with enhanced validation\"\n  }\n}\n</code></pre>"},{"location":"packs/PACK_GOVERNANCE/#certification-tiers","title":"Certification Tiers","text":""},{"location":"packs/PACK_GOVERNANCE/#tier-1-official-packs","title":"Tier 1: Official Packs","text":"<p>Definition: Created and maintained by regulatory authorities or Sinergy Solutions</p> <p>Criteria: - Source: Treasury, IRS, CMS, Sinergy platform team - Funding: Government contracts or platform core - Pricing: Free (publicly funded) - Support: Official support SLA</p> <p>Examples: - <code>federal-gtas-v1</code>: Treasury-verified GTAS rules - <code>hipaa-security-v1</code>: Official HIPAA compliance pack - <code>nist-800-53-ac</code>: NIST access control mapping</p> <p>Badge: \u2705 Official</p>"},{"location":"packs/PACK_GOVERNANCE/#tier-2-certified-packs","title":"Tier 2: Certified Packs","text":"<p>Definition: Community-created packs that passed rigorous certification</p> <p>Criteria: - Source: Third-party developers, consultancies - Testing: Comprehensive test suite (&gt;90% coverage) - Review: Passed all governance stages - Support: Author provides support - Pricing: Author-defined (70/30 revenue split)</p> <p>Certification Requirements: - [ ] All test cases pass - [ ] Documentation complete (README, USAGE, CHANGELOG) - [ ] Compliance review passed - [ ] Security scan clean - [ ] Performance benchmarks met - [ ] Author support commitment (email, SLA)</p> <p>Examples: - <code>healthcare-claims-verification-v1</code>: Third-party healthcare pack - <code>realestate-title-search-v1</code>: Certified title verification</p> <p>Badge: \ud83c\udfc6 Certified</p>"},{"location":"packs/PACK_GOVERNANCE/#tier-3-community-packs","title":"Tier 3: Community Packs","text":"<p>Definition: User-contributed packs, not certified</p> <p>Criteria: - Source: Any community member - Testing: Basic schema validation - Review: Automated checks only - Support: Best-effort by author - Pricing: Author-defined (70/30 split)</p> <p>Requirements: - [ ] Schema validation passes - [ ] Basic test cases exist - [ ] No critical security issues - [ ] Documentation present</p> <p>Examples: - <code>custom-agency-workflow-v1</code>: Agency-specific workflow - <code>experimental-ml-validation-v1</code>: Experimental features</p> <p>Badge: \ud83e\uddea Community</p>"},{"location":"packs/PACK_GOVERNANCE/#tier-4-private-packs","title":"Tier 4: Private Packs","text":"<p>Definition: Enterprise or agency-specific packs (not in public marketplace)</p> <p>Criteria: - Source: Enterprise customer or agency - Visibility: Private to tenant/agency - Pricing: Enterprise license - Support: Dedicated account team</p> <p>Use Cases: - Proprietary business logic - Sensitive compliance rules - Custom integrations - Trade secrets</p> <p>Badge: \ud83d\udd12 Private</p>"},{"location":"packs/PACK_GOVERNANCE/#quality-standards","title":"Quality Standards","text":""},{"location":"packs/PACK_GOVERNANCE/#rulepack-quality-standards","title":"RulePack Quality Standards","text":"<p>Schema Compliance: - [ ] Valid JSON format - [ ] Matches RulePack JSON Schema - [ ] All required fields present</p> <p>Rule Quality: - [ ] Unique rule IDs - [ ] Clear, actionable error messages - [ ] Appropriate severity levels (FATAL/WARNING/INFO) - [ ] Compliance references included - [ ] Safe operators only (no code injection)</p> <p>Testing: - [ ] Minimum 10 test cases per pack - [ ] Edge cases covered (null, empty, special chars) - [ ] Performance tested (1M records &lt;30s) - [ ] All test cases pass</p> <p>Documentation: - [ ] README with overview and use cases - [ ] USAGE guide with examples - [ ] CHANGELOG with version history</p>"},{"location":"packs/PACK_GOVERNANCE/#workflowpack-quality-standards","title":"WorkflowPack Quality Standards","text":"<p>Schema Compliance: - [ ] Valid YAML format - [ ] Matches WorkflowPack schema - [ ] All required fields present</p> <p>Workflow Quality: - [ ] Unique step IDs - [ ] Logical step ordering - [ ] Error handling defined - [ ] Compensation logic (for sagas) - [ ] Environment variables for secrets</p> <p>Testing: - [ ] Simulation tests pass - [ ] Integration tests pass (dev environment) - [ ] Error scenarios tested - [ ] Performance benchmarks met</p> <p>Documentation: - [ ] README with workflow description - [ ] Step-by-step USAGE guide - [ ] Architecture diagram (for complex workflows) - [ ] CHANGELOG with version history</p>"},{"location":"packs/PACK_GOVERNANCE/#review-guidelines","title":"Review Guidelines","text":""},{"location":"packs/PACK_GOVERNANCE/#for-business-analysts","title":"For Business Analysts","text":"<p>Focus Areas: - Functional correctness - Business rule accuracy - User experience (error messages) - Test coverage completeness</p> <p>Checklist: - [ ] Business requirements documented - [ ] Rules/steps match specifications - [ ] Error messages are clear - [ ] Edge cases identified and handled - [ ] Test cases validate requirements</p> <p>Approval Criteria: - All checklist items satisfied - No critical functional issues - Author responsive to feedback</p>"},{"location":"packs/PACK_GOVERNANCE/#for-compliance-officers","title":"For Compliance Officers","text":"<p>Focus Areas: - Regulatory alignment - Compliance tagging accuracy - Control mapping correctness - Audit trail adequacy</p> <p>Checklist: - [ ] Compliance frameworks correctly identified - [ ] Control references accurate (NIST, HIPAA, etc.) - [ ] Regulatory requirements satisfied - [ ] Audit logging implemented - [ ] Data privacy considerations addressed</p> <p>Approval Criteria: - Compliance requirements met - No regulatory risks - Adequate documentation</p>"},{"location":"packs/PACK_GOVERNANCE/#for-qa-leads","title":"For QA Leads","text":"<p>Focus Areas: - Test coverage - Performance - Security - Integration</p> <p>Checklist: - [ ] All test cases pass - [ ] Code coverage &gt;80% - [ ] Performance benchmarks met - [ ] No security vulnerabilities - [ ] Integration tests successful</p> <p>Approval Criteria: - All tests pass - No critical issues - Performance acceptable</p>"},{"location":"packs/PACK_GOVERNANCE/#marketplace-governance","title":"Marketplace Governance","text":""},{"location":"packs/PACK_GOVERNANCE/#submission-process","title":"Submission Process","text":"<p>1. Prepare Pack: - Complete all documentation - Add examples and test cases - Ensure quality standards met</p> <p>2. Submit for Review:</p> <pre><code>cortx marketplace submit &lt;pack-id&gt; \\\n  --tier certified \\\n  --category compliance \\\n  --pricing free\n</code></pre> <p>3. Automated Checks: - Schema validation - Security scanning - Test execution - Documentation completeness</p> <p>4. Human Review: - Compliance certification (if applicable) - Quality review - Pricing review</p> <p>5. Approval/Rejection: - Approved: Published to marketplace - Rejected: Feedback provided, resubmit allowed</p>"},{"location":"packs/PACK_GOVERNANCE/#revenue-model","title":"Revenue Model","text":"<p>Certified Packs (Paid): - Author: 70% of revenue - Platform: 30% of revenue</p> <p>Free Packs: - No revenue (official or free certified packs)</p> <p>Private Packs: - Enterprise licensing (custom pricing)</p> <p>Payment Schedule: - Monthly payouts for authors - Minimum payout threshold: $100 - Payment via Stripe, PayPal, or ACH</p>"},{"location":"packs/PACK_GOVERNANCE/#monitoring-metrics","title":"Monitoring &amp; Metrics","text":""},{"location":"packs/PACK_GOVERNANCE/#pack-health-metrics","title":"Pack Health Metrics","text":"<p>Usage: - Downloads per month - Active installations - Execution count - Error rate</p> <p>Quality: - User ratings (1-5 stars) - Bug reports - Support tickets - Test pass rate</p> <p>Performance: - Average execution time - p95/p99 latency - Resource consumption</p>"},{"location":"packs/PACK_GOVERNANCE/#dashboards","title":"Dashboards","text":"<p>Pack Author Dashboard: - Usage analytics - Revenue tracking (if paid) - User feedback - Issue tracker</p> <p>Platform Dashboard: - Total packs by tier - Certification pipeline status - Quality metrics across all packs - Security vulnerability trends</p>"},{"location":"packs/PACK_GOVERNANCE/#incident-response","title":"Incident Response","text":""},{"location":"packs/PACK_GOVERNANCE/#security-vulnerability","title":"Security Vulnerability","text":"<p>Process: 1. Report: User or security scan detects vulnerability 2. Triage: Security team assesses severity 3. Notify: Author notified within 24 hours 4. Fix: Author provides patch within SLA 5. Redeploy: Patched version deployed 6. Communicate: Users notified of update</p> <p>SLA: - Critical: 24-hour patch - High: 3-day patch - Medium: 7-day patch - Low: 30-day patch</p>"},{"location":"packs/PACK_GOVERNANCE/#pack-failure","title":"Pack Failure","text":"<p>Process: 1. Detect: Monitoring alerts on high error rate 2. Investigate: Root cause analysis 3. Mitigate: Rollback or hotfix 4. Communicate: Users notified 5. Postmortem: Document lessons learned</p>"},{"location":"packs/PACK_GOVERNANCE/#appeals-process","title":"Appeals Process","text":"<p>If Pack Rejected: 1. Review rejection reason 2. Address feedback 3. Resubmit with changes documented 4. Escalate to governance committee (if disagreement)</p> <p>Governance Committee: - Platform architect - Compliance officer - QA lead - Product manager</p>"},{"location":"packs/PACK_GOVERNANCE/#contact","title":"Contact","text":"<p>Pack Governance Team: - Email: pack-governance@sinergysolutions.ai - Slack: #pack-governance - Office Hours: Fridays 1-2 PM ET</p> <p>Document Control - Version: 1.0.0 - Last Updated: 2025-10-01 - Review Cycle: Quarterly - Next Review: 2026-01-01 - Approvers: Compliance &amp; Platform Governance Team</p>"},{"location":"packs/RULEPACK_SCHEMA/","title":"RulePack Schema Reference","text":"<p>This document defines the JSON schema for RulePacks in CORTX.</p> <p>```json {   \"$schema\": \"http://json-schema.org/draft-07/schema#\",   \"title\": \"RulePack\",   \"type\": \"object\",   \"required\": [\"metadata\", \"rules\"],   \"properties\": {     \"metadata\": {       \"type\": \"object\",       \"properties\": {         \"pack_id\": {\"type\": \"string\"},         \"version\": {\"type\": \"string\"},         \"created_by\": {\"type\": \"string\"},         \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"}       }     },     \"rules\": {       \"type\": \"array\",       \"items\": {\"$ref\": \"#/definitions/rule\"}     }   },   \"definitions\": {     \"rule\": {       \"type\": \"object\",       \"properties\": {         \"rule_id\": {\"type\": \"string\"},         \"type\": {\"enum\": [\"FATAL\", \"WARNING\", \"INFO\"]},         \"field\": {\"type\": \"string\"},         \"operator\": {\"type\": \"string\"},         \"error_message\": {\"type\": \"string\"}       },       \"required\": [\"rule_id\", \"type\", \"field\", \"operator\", \"error_message\"]     }   } }</p>"},{"location":"packs/WORKFLOWPACK_SCHEMA/","title":"WorkflowPack Schema Reference","text":"<p>This document defines the YAML schema for WorkflowPacks in CORTX.</p> <p>```yaml workflow_id: string  # Unique identifier version: string      # Semantic version description: string metadata:   compliance: [string]   created_by: string   created_at: datetime steps:   - id: string     type: one_of [data-source, validation, calculation, decision, approval, ai-inference, data-sink]     config: object   # Step-specific config     depends_on: [string]  # Optional</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/","title":"FINAL REPO SETUP PROMPT","text":"<p>Goal: Implement the 6 follow-ups:     1.  Commit &amp; push current changes     2.  Add Redoc pages to render each service\u2019s OpenAPI inline (no extra MkDocs plugin)     3.  Add nav entries to expose OpenAPI (YAML) and OpenAPI (Redoc) for each service     4.  Add a Makefile for common tasks     5.  Add spec linting to contracts CI (Redocly CLI)     6.  Add a guard against accidental edits to published OpenAPI copies in docs/</p> <p>Pre-flight     \u2022   Fail if mkdocs.yml, docs/, services/ are not present.</p> <p>\u2e3b</p> <p>1) Commit &amp; (optionally) push set -euo pipefail</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#ensure-we-are-in-repo-root","title":"Ensure we are in repo root","text":"<p>cd /Users/michael/Development/sinergysolutionsllc test -f mkdocs.yml &amp;&amp; test -d docs &amp;&amp; test -d services || (echo \"Missing mkdocs.yml/docs/services\" &amp;&amp; exit 1)</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#stage-current-changes-if-any","title":"Stage current changes if any","text":"<p>git add -A if ! git diff --cached --quiet; then   git commit -m \"chore(docs): publish OpenAPI copies, sync guard, docs+contracts CI\" fi</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#optional-push-safe-to-skip-if-not-configured","title":"Optional push (safe to skip if not configured)","text":"<p>if git rev-parse --abbrev-ref --symbolic-full-name @{u} &gt;/dev/null 2&gt;&amp;1; then   git push else   echo \"No upstream configured; skipping push.\" fi</p> <p>2) Generate Redoc pages per service</p> <p>Create openapi.html per service that renders ./openapi.yaml with Redoc (CDN script). Services list: gateway identity validation ai-broker workflow compliance ledger ocr rag.</p> <p>set -e</p> <p>SERVICES=(gateway identity validation ai-broker workflow compliance ledger ocr rag)</p> <p>for s in \"${SERVICES[@]}\"; do   mkdir -p \"docs/services/$s\"   cat &gt; \"docs/services/$s/openapi.html\" &lt;&lt;'HTML'</p> OpenAPI <p>HTML   echo \"Wrote docs/services/$s/openapi.html\" done</p> <p>3) Update mkdocs.yml nav to include YAML + Redoc entries     \u2022   Under nav: - Services:, ensure each service section has:     \u2022   /README.md     \u2022   OpenAPI (YAML): services//openapi.yaml     \u2022   OpenAPI (Redoc): services//openapi.html <p>This patch keeps existing structure and replaces any flat paths.</p> <p>python3 - &lt;&lt;'PY' import io, re, sys, pathlib, yaml</p> <p>repo = pathlib.Path(\".\") mk = repo/\"mkdocs.yml\" data = yaml.safe_load(mk.read_text())</p> <p>def ensure_services_nav(d):     nav = d.get(\"nav\", [])     # find Services block     for item in nav:         if isinstance(item, dict) and \"Services\" in item:             svc = item[\"Services\"]             # Normalize services index             try:                 idx = next(i for i, v in enumerate(svc) if (v == \"services/index.md\" or (isinstance(v, dict) and \"services/index.md\" in v.values())))             except StopIteration:                 svc.insert(0, \"services/index.md\")             # Map of expected entries             services = [                 (\"Gateway\",\"gateway\"),                 (\"Identity\",\"identity\"),                 (\"Validation\",\"validation\"),                 (\"AI Broker\",\"ai-broker\"),                 (\"Workflow\",\"workflow\"),                 (\"Compliance\",\"compliance\"),                 (\"Ledger\",\"ledger\"),                 (\"OCR\",\"ocr\"),                 (\"RAG\",\"rag\"),             ]             new = [\"services/index.md\"]             # Keep any items before services if present             seen = set()             for name, folder in services:                 block = {                     name: [                         f\"services/{folder}/README.md\",                         { \"OpenAPI (YAML)\": f\"services/{folder}/openapi.yaml\" },                         { \"OpenAPI (Redoc)\": f\"services/{folder}/openapi.html\" },                     ]                 }                 new.append(block)                 seen.add(folder)             # Replace the full Services with our normalized list but preserve extra custom entries if any             item[\"Services\"] = new             return True     # If Services block not found, append it     data.setdefault(\"nav\", []).append({         \"Services\": [             \"services/index.md\",             {\"Gateway\": [                 \"services/gateway/README.md\",                 {\"OpenAPI (YAML)\": \"services/gateway/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/gateway/openapi.html\"},             ]},             {\"Identity\": [                 \"services/identity/README.md\",                 {\"OpenAPI (YAML)\": \"services/identity/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/identity/openapi.html\"},             ]},             {\"Validation\": [                 \"services/validation/README.md\",                 {\"OpenAPI (YAML)\": \"services/validation/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/validation/openapi.html\"},             ]},             {\"AI Broker\": [                 \"services/ai-broker/README.md\",                 {\"OpenAPI (YAML)\": \"services/ai-broker/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/ai-broker/openapi.html\"},             ]},             {\"Workflow\": [                 \"services/workflow/README.md\",                 {\"OpenAPI (YAML)\": \"services/workflow/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/workflow/openapi.html\"},             ]},             {\"Compliance\": [                 \"services/compliance/README.md\",                 {\"OpenAPI (YAML)\": \"services/compliance/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/compliance/openapi.html\"},             ]},             {\"Ledger\": [                 \"services/ledger/README.md\",                 {\"OpenAPI (YAML)\": \"services/ledger/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/ledger/openapi.html\"},             ]},             {\"OCR\": [                 \"services/ocr/README.md\",                 {\"OpenAPI (YAML)\": \"services/ocr/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/ocr/openapi.html\"},             ]},             {\"RAG\": [                 \"services/rag/README.md\",                 {\"OpenAPI (YAML)\": \"services/rag/openapi.yaml\"},                 {\"OpenAPI (Redoc)\": \"services/rag/openapi.html\"},             ]},         ]     })     return True</p> <p>ensure_services_nav(data) mk.write_text(yaml.safe_dump(data, sort_keys=False)) print(\"Updated mkdocs.yml nav with YAML + Redoc entries.\") PY</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#validate-build","title":"Validate build","text":"<p>mkdocs build --strict</p> <p>4) Add a Makefile</p> <p>cat &gt; Makefile &lt;&lt;'MK' .PHONY: docs verify contracts ci publish-openapi</p> <p>docs: \\tmkdocs build --strict</p> <p>verify: \\tpython3 scripts/verify_openapi_sync.py</p> <p>contracts: \\t@echo \"OpenAPI specs:\" \\t@find services -name openapi.yaml -print</p> <p>publish-openapi: \\t@echo \"Publishing authoritative OpenAPI to docs...\" \\t@SERVICES=\"gateway identity validation ai-broker workflow compliance ledger ocr rag\"; \\ \\tfor s in $$SERVICES; do \\ \\t  mkdir -p docs/services/$$s; \\ \\t  cp services/$$s/openapi.yaml docs/services/$$s/openapi.yaml; \\ \\techo \"Published $$s\"; \\ \\tdone</p> <p>ci: verify docs MK</p> <p>5) Add spec linting (Redocly) to contracts-ci     \u2022   Inject Redocly CLI install + lint step.</p> <pre><code>python3 - &lt;&lt;'PY'\n</code></pre> <p>from pathlib import Path wf = Path(\".github/workflows/contracts-ci.yml\") y = wf.read_text() if \"redocly\" not in y:     y = y.rstrip() + \"\"\"</p> <p>lint-openapi:     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v4       - name: Install Redocly CLI         run: npm i -g @redocly/cli       - name: Lint OpenAPI         run: redocly lint \"services/**/openapi.yaml\" \"\"\"     wf.write_text(y)     print(\"Enhanced contracts-ci.yml with Redocly lint.\") else:     print(\"contracts-ci.yml already has Redocly lint.\") PY</p> <p>6) Guard against accidental edits to published copies</p> <p>Keep the SHA sync guard, and add a PR-time check that fails if docs copies were changed without matching authoritative changes.</p> <p>python3 - &lt;&lt;'PY' from pathlib import Path wf = Path(\".github/workflows/docs-ci.yml\") content = wf.read_text() if \"Docs copies changed\" not in content:     content = content.rstrip() + \"\"\"</p> <p>check-docs-copies-changes:     runs-on: ubuntu-latest     if: github.event_name == 'pull_request'     steps:       - uses: actions/checkout@v4       - name: Detect changes to docs OpenAPI copies without service changes         run: |           set -e           # List changed files           CHANGED=$(jq -r '.pull_request.base.sha + \" \" + .pull_request.head.sha' &lt;(echo \"${{ toJson(github.event) }}\") | xargs -n2 sh -c 'git fetch origin \"$0\" &amp;&amp; git diff --name-only \"$0\"..\"$1\"' | sort -u)           echo \"$CHANGED\" &gt; changed.txt || true           echo \"Changed files:\"           cat changed.txt || true           # Flags           DOCS_CHANGED=$(grep -E '^docs/services/.+/openapi.yaml$' changed.txt || true)           SRV_CHANGED=$(grep -E '^services/.+/openapi.yaml$' changed.txt || true)           if [ -n \"$DOCS_CHANGED\" ] &amp;&amp; [ -z \"$SRV_CHANGED\" ]; then             echo \"Docs copies changed but authoritative service specs did not. Please edit only services//openapi.yaml and run 'make publish-openapi'.\"; exit 1           fi           echo \"Change policy OK.\" \"\"\"     wf.write_text(content)     print(\"Augmented docs-ci.yml with PR change guard.\") else:     print(\"Change guard already present.\") PY <p>Final validation</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#re-publish-to-ensure-copies-are-aligned-idempotent","title":"Re-publish to ensure copies are aligned (idempotent)","text":"<p>make publish-openapi python3 scripts/verify_openapi_sync.py</p>"},{"location":"prompts/FINAL_REPO_SETUP_PROMPT/#strict-docs-build","title":"Strict docs build","text":"<p>mkdocs build --strict</p> <p>Commit &amp; (optional) push</p> <p>git add -A git commit -m \"docs(openapi): add Redoc pages, nav entries, Makefile, Redocly lint, PR change guard\" if git rev-parse --abbrev-ref --symbolic-full-name @{u} &gt;/dev/null 2&gt;&amp;1; then   git push else   echo \"No upstream configured; skipping push.\" fi</p>"},{"location":"prompts/REPO_ORG_PROMPT/","title":"CORTX Docs \u2022 Templates \u2022 Governance \u2014 Full Repository Audit, De-Dup &amp; Patch Plan","text":"<p>Role: You are the Docs, Templates &amp; Governance Automation Architect for CORTX by Sinergy. Objective: Audit the repository against the CORTX documentation &amp; governance standard and produce: 1) a concise scorecard, 2) a concrete gap list, 3) a patch set (unified diffs/new files), 4) a deprecation &amp; delete list for unnecessary/duplicative docs, and 5) a merge/canonicalization plan. Context: Compliance-first (FedRAMP, NIST 800-53, SOC 2 Type II, HIPAA, GDPR). Platform services/ports: Gateway 8080, Identity 8082, Validation 8083, AI Broker 8085, Workflow 8130, Compliance 8135, Ledger 8136, OCR 8137, RAG 8138.</p>"},{"location":"prompts/REPO_ORG_PROMPT/#what-to-analyze-from-repo-root","title":"What to Analyze (from repo root)","text":"<p>Perform a deterministic scan and summarize:</p> <p>1) Templates (required at <code>/templates/</code>)    - <code>README.repo.template.md</code>    - <code>README.service.template.md</code>    - <code>README.module.template.md</code>    - <code>FDD.template.md</code>  (modeled on CORTX_PLATFORM_FDD.md)    - <code>ADR.template.md</code>  (match ADR 0001\u20130003: Context \u2192 Options \u2192 Decision \u2192 Consequences \u2192 References)    - <code>AgentRoles.template.md</code> (align with Agents.md / Claude.md / Gemini.md)    - <code>CHANGELOG.template.md</code> (Keep a Changelog + SemVer)</p> <p>2) Docs Site (MkDocs Material)    - <code>mkdocs.yml</code> at repo root    - <code>/docs/</code> IA folders: <code>overview/</code>, <code>architecture/</code>, <code>services/</code>, <code>suites/</code>, <code>packs/</code>, <code>sdks/</code>, <code>security/</code>, <code>operations/</code>, <code>contribute/</code>, <code>adr/</code>, <code>rfcs/</code>, <code>diagrams/</code>    - Mermaid blocks compile; internal links resolve; ADR index exists: <code>/docs/adr/ADR-000-index.md</code></p> <p>3) Repo Standards    - Root governance: <code>CONTRIBUTING.md</code>, <code>CODE_OF_CONDUCT.md</code>, <code>SECURITY.md</code>, <code>CODEOWNERS</code>, <code>SUPPORT.md</code>    - <code>.github/</code>:      - <code>PULL_REQUEST_TEMPLATE.md</code>      - <code>ISSUE_TEMPLATE/bug.md</code>, <code>feature.md</code>, <code>rfc.md</code>, <code>doc_request.md</code>      - <code>workflows/</code>:        - <code>docs-ci.yml</code> (lint MD + links, build docs, validate Mermaid)        - <code>contracts-ci.yml</code> (validate OpenAPI + JSON Schema)        - <code>release.yml</code> (semantic releases for SDKs/Packs)  </p> <p>4) Contracts-First Artifacts    - <code>services/**/openapi.yaml</code> (or <code>.yml</code>) present/valid    - <code>/schemas/**</code> JSON Schemas present/valid    - SDK generation hooks/pipelines (documented or CI-backed)</p> <p>5) ADRs &amp; RFCs    - <code>/docs/adr/</code> populated + indexed    - <code>/rfcs/NNNN-title/</code> present if RFCs exist; linked from docs</p> <p>6) Readme Consistency    - Org, repo, service, and module READMEs follow templates    - Service ports correct; env strategy (dev\u2192staging\u2192prod) and provider policy (Vertex primary, OpenAI dev-only) referenced</p> <p>7) Redundancy / Bloat / Stale Docs (NEW)    - Identify duplicates or near-duplicates (\u226585% textual similarity, same or highly similar titles/headings).    - Identify stale (no edits &gt; 12 months) that are not referenced by any README, mkdocs nav, or docs pages.    - Identify orphaned files (not linked anywhere and not in mkdocs nav).    - Identify conflicting versions (e.g., multiple FDDs or ADRs for the same service/decision without index references).    - Identify binary/document bloat: PDFs/images in non-canonical paths or &gt;5MB that aren\u2019t used by docs.    - Identify generated artifacts committed to source (should be ignored).</p>"},{"location":"prompts/REPO_ORG_PROMPT/#how-to-perform-the-scan","title":"How to Perform the Scan","text":"<p>Use deterministic, repo-local steps (no network):</p> <ul> <li>Walk the tree (ignore <code>node_modules</code>, <code>.venv</code>, <code>.tox</code>, <code>dist</code>, <code>build</code>, <code>.next</code>, <code>__pycache__</code>, <code>.git</code>).</li> <li>Record existence and minimal content rules:</li> <li>Templates: required headings/sections present.</li> <li><code>mkdocs.yml</code>: includes Material theme and nav entries for IA sections above.</li> <li>Workflows: run on <code>pull_request</code>(/<code>push</code>), correct paths, sensible defaults.</li> <li>OpenAPI &amp; JSON Schema sanity: YAML/JSON parseable; <code>openapi:</code> key present for OAS3; <code>$schema</code> present for JSON Schema.</li> <li>Mermaid: grep ```mermaid blocks; check for typical keywords (graph/flow/sequence/class/state) and codefence closure.</li> <li>Redundancy detection:</li> <li>Flag files with the same basename in different locations (e.g., multiple <code>README.md</code> or <code>FDD.md</code> variants).</li> <li>Compute simple similarity (title + top-level headings + paragraph hashes) to flag near-duplicates.</li> <li>Check whether each doc is referenced by: any README, mkdocs nav, or other docs (grep links).</li> <li>Consider timestamps (older than 12 months) + zero references \u21d2 stale candidate.</li> </ul>"},{"location":"prompts/REPO_ORG_PROMPT/#output-format-strict","title":"Output Format (strict)","text":"<p>Return five sections, in this order:</p>"},{"location":"prompts/REPO_ORG_PROMPT/#1-scorecard","title":"1) SCORECARD","text":"<p>Table: Area | Status (\u2705/\u26a0\ufe0f/\u274c) | Notes Areas: Templates, Docs Site, Repo Standards, Contracts-First, ADRs/RFCs, Readmes, Env/Security, Redundancy/Bloat</p>"},{"location":"prompts/REPO_ORG_PROMPT/#2-gaps-drift","title":"2) GAPS &amp; DRIFT","text":"<p>Bullet list with exact paths and one-line fixes. Examples: - <code>\u274c /templates/README.service.template.md</code> \u2014 missing \u2192 create from established service style - <code>\u26a0\ufe0f /docs/adr/ADR-000-index.md</code> \u2014 missing index \u2192 generate linking 0001\u2013000N</p>"},{"location":"prompts/REPO_ORG_PROMPT/#3-patch-set-unified-diffs-or-new-files","title":"3) PATCH SET (UNIFIED DIFFS OR NEW FILES)","text":"<ul> <li>Provide ready-to-apply patches.  </li> <li>New files: include full content (start with <code>--- /dev/null</code> \u2192 <code>+++ &lt;path&gt;</code>).  </li> <li>Modifications: unified diff.  </li> <li>Keep patches minimal and self-contained.</li> </ul>"},{"location":"prompts/REPO_ORG_PROMPT/#4-deprecation-delete-list-safe-cleanup","title":"4) DEPRECATION &amp; DELETE LIST (SAFE CLEANUP)","text":"<p>For each candidate, list: - Path - Category (duplicate/near-duplicate, stale, orphaned, conflicting, bloat/generated) - Rationale (e.g., \u201cduplicate of X; not referenced; older by 14 months\u201d) - Action: delete, keep, or merge into canonical - Canonical target (if merge)  </p> <p>Important: Do not propose deleting source code. Limit to docs/assets. Prefer merge over delete when a doc has partial unique value.</p>"},{"location":"prompts/REPO_ORG_PROMPT/#5-merge-canonicalization-plan","title":"5) MERGE &amp; CANONICALIZATION PLAN","text":"<ul> <li>For duplicates: specify which file becomes canonical and provide a merged version (unified diff) that retains any unique content from the duplicate(s).</li> <li>For ADR conflicts: unify into one ADR or add an \u201cAmended by ADR-XXXX\u201d note; update ADR-000-index.md.</li> <li>For large assets: move to <code>/docs/assets/</code> (or <code>/docs/diagrams/</code>, <code>/docs/reference/</code>) and update links in affected pages.</li> </ul>"},{"location":"prompts/REPO_ORG_PROMPT/#generation-rules","title":"Generation Rules","text":"<ul> <li>Mirror established styles in:</li> <li><code>CORTX_PLATFORM_FDD.md</code> (for FDD.template.md)</li> <li><code>docs/ADRs/0001-*.md</code>, <code>0002-*.md</code>, <code>0003-*.md</code> (ADR template)</li> <li><code>Agents.md</code>, <code>Claude.md</code>, <code>Gemini.md</code> (AgentRoles template)</li> <li><code>CHANGELOG.md</code> (CHANGELOG template)</li> <li>Voice: compliance-first, production-ready; no TODO/placeholder text.</li> <li>Include Mermaid snippets where useful (platform topology, hierarchical RAG).</li> <li>Default docs engine: MkDocs Material.</li> <li>Respect CORTX service ports; include environment strategy table in repo README template.</li> <li>Never delete code; only propose cleanup for docs/assets that are redundant/unreferenced.</li> </ul>"},{"location":"prompts/REPO_ORG_PROMPT/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Scorecard clearly signals readiness.</li> <li>Gaps list is actionable/exhaustive.</li> <li>Patch set compiles (Markdown/YAML), sensible CI defaults.</li> <li>Deletion proposals include rationale + canonical target where applicable.</li> <li>Merge plan yields a single, clean, organized docs set.</li> </ul>"},{"location":"prompts/REPO_ORG_PROMPT/#optional-commands-if-shell-is-allowed","title":"Optional Commands (if shell is allowed)","text":"<p>Do not fail if shell is blocked; treat as guidance only: ```bash</p>"},{"location":"prompts/REPO_ORG_PROMPT/#tree-top-two-levels","title":"Tree (top two levels)","text":"<p>find . -maxdepth 2 -type d -not -path '/node_modules/' -not -path '/.git/' | sort</p>"},{"location":"prompts/REPO_ORG_PROMPT/#templates-mkdocs","title":"Templates &amp; mkdocs","text":"<p>ls -la templates || true test -f mkdocs.yml &amp;&amp; head -n 40 mkdocs.yml || true</p>"},{"location":"prompts/REPO_ORG_PROMPT/#openapi-quick-check","title":"OpenAPI quick check","text":"<p>grep -R --include='.yml' -n '^openapi:' services 2&gt;/dev/null || true</p>"},{"location":"prompts/REPO_ORG_PROMPT/#mermaid-blocks","title":"Mermaid blocks","text":"<p>grep -R --include='*.md' -n '```mermaid' docs 2&gt;/dev/null || true</p>"},{"location":"prompts/REPO_ORG_PROMPT/#inbound-links-to-a-file-example","title":"Inbound links to a file (example)","text":"<p>grep -R --include='*.md' -n 'docs/old_fdd.md' . 2&gt;/dev/null || true</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/","title":"Prompt: Generate CORTX Service Docs","text":"<p>Role: You are the Docs Automation Agent for CORTX by Sinergy. Objective: Create the full <code>/docs/services/</code> section with Markdown pages for each platform service, modeled on the given structure and tone. Include Mermaid diagrams and align with OpenAPI/Schema templates. At the end, output the optional nav tweak for <code>mkdocs.yml</code>.</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#instructions","title":"Instructions","text":"<ol> <li>Create the following files under <code>/docs/services/</code>:</li> <li><code>index.md</code></li> <li><code>gateway.md</code></li> <li><code>identity.md</code></li> <li><code>validation.md</code></li> <li><code>ai-broker.md</code></li> <li><code>workflow.md</code></li> <li><code>compliance.md</code></li> <li><code>ledger.md</code></li> <li><code>ocr.md</code></li> <li> <p><code>rag.md</code></p> </li> <li> <p>For each file:</p> </li> <li>Start with a top-level heading: <code># &lt;Service Name&gt; (Port)</code></li> <li>Provide Purpose, Responsibilities, Authentication.</li> <li>List Sample endpoints with <code>GET/POST</code> routes.</li> <li>Include a Mermaid diagram showing that service in context.</li> <li> <p>End with an OpenAPI reference (path to stub under <code>services/&lt;svc&gt;/openapi.yaml</code>) and, if relevant, JSON Schema example path from <code>/templates/</code>.</p> </li> <li> <p>Use the exact examples provided in the draft content. Preserve Markdown and Mermaid formatting.</p> </li> </ol>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#expected-output","title":"Expected Output","text":""},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesindexmd","title":"<code>docs/services/index.md</code>","text":"<p>```md</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#platform-services","title":"Platform Services","text":"<p>CORTX centralizes core capabilities as microservices behind the Gateway:</p> Service Port Purpose Gateway 8080 Entry point, routing, policy enforcement Identity 8082 JWT/OIDC, RBAC, session management Validation 8083 JSON Schema + RulePack validation AI Broker 8085 Provider routing (Vertex/OpenAI), PII redaction, embeddings Workflow 8130 Workflow orchestration, Pack execution Compliance 8135 Compliance logs &amp; reporting Ledger 8136 Append-only, SHA-256 chain evidence (tamper-evident) OCR 8137 Document \u2192 text/fields extraction RAG 8138 Hierarchical retrieval (Platform/Suite/Module/Entity) <p>```mermaid flowchart LR   User--&gt;Gateway   Gateway--&gt;Identity   Gateway--&gt;Validation   Gateway--&gt;Workflow   Gateway--&gt;Compliance   Gateway--&gt;Ledger   Gateway--&gt;OCR   Gateway--&gt;RAG   RAG--&gt;DB[(PostgreSQL + pgvector)]   Ledger--&gt;Evidence[(Immutable Chain)]</p> <p>### <code>docs/services/gateway.md</code> \u2026 (include full Gateway doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesidentitymd","title":"<code>docs/services/identity.md</code>","text":"<p>\u2026 (include full Identity doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesvalidationmd","title":"<code>docs/services/validation.md</code>","text":"<p>\u2026 (include full Validation doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesai-brokermd","title":"<code>docs/services/ai-broker.md</code>","text":"<p>\u2026 (include full AI Broker doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesworkflowmd","title":"<code>docs/services/workflow.md</code>","text":"<p>\u2026 (include full Workflow doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicescompliancemd","title":"<code>docs/services/compliance.md</code>","text":"<p>\u2026 (include full Compliance doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesledgermd","title":"<code>docs/services/ledger.md</code>","text":"<p>\u2026 (include full Ledger doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesocrmd","title":"<code>docs/services/ocr.md</code>","text":"<p>\u2026 (include full OCR doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#docsservicesragmd","title":"<code>docs/services/rag.md</code>","text":"<p>\u2026 (include full RAG doc as drafted)</p>"},{"location":"prompts/SERVICES_SETUP_PROMPT/#optional-nav-tweak-if-you-want-sub-entries-in-mkdocsyml","title":"Optional nav tweak (if you want sub-entries in <code>mkdocs.yml</code>)","text":"<p>```yaml nav:   - Services:     - services/index.md     - Gateway: services/gateway.md     - Identity: services/identity.md     - Validation: services/validation.md     - AI Broker: services/ai-broker.md     - Workflow: services/workflow.md     - Compliance: services/compliance.md     - Ledger: services/ledger.md     - OCR: services/ocr.md     - RAG: services/rag.md</p> <pre><code>Output Rules\n\u2022   Output each file content with correct headings, sections, and diagrams.\n\u2022   Do not shorten or omit; use the full draft content for each service.\n\u2022   Keep the MkDocs nav tweak at the end.\n</code></pre>"},{"location":"rfcs/","title":"RFCs","text":"<p>Propose substantial changes under <code>/rfcs/NNNN-title/</code> and link to resulting ADR(s).</p>"},{"location":"sdks/","title":"SDKs","text":"<p>Auto-generated Python/TS SDKs from OpenAPI. See service OpenAPI files under <code>services/*/openapi.yaml</code>.</p>"},{"location":"security/","title":"Security &amp; Compliance","text":"<p>FedRAMP, NIST 800-53, SOC2, HIPAA, GDPR. RLS + pgvector, provider policy (Vertex primary).</p>"},{"location":"services/","title":"Platform Services","text":"<p>CORTX centralizes core capabilities as microservices behind the Gateway:</p> Service Port Purpose Gateway 8080 Entry point, routing, policy enforcement Identity 8082 JWT/OIDC, RBAC, session management Validation 8083 JSON Schema + RulePack validation AI Broker 8085 Provider routing (Vertex/OpenAI), PII redaction, embeddings Workflow 8130 Workflow orchestration, Pack execution Compliance 8135 Compliance logs &amp; reporting Ledger 8136 Append-only, SHA-256 chain evidence (tamper-evident) OCR 8137 Document \u2192 text/fields extraction RAG 8138 Hierarchical retrieval (Platform/Suite/Module/Entity) <pre><code>flowchart LR\n  User--&gt;Gateway\n  Gateway--&gt;Identity\n  Gateway--&gt;Validation\n  Gateway--&gt;Workflow\n  Gateway--&gt;Compliance\n  Gateway--&gt;Ledger\n  Gateway--&gt;OCR\n  Gateway--&gt;RAG\n  RAG--&gt;DB[(PostgreSQL + pgvector)]\n  Ledger--&gt;Evidence[(Immutable Chain)]\n</code></pre>"},{"location":"services/ai-broker/","title":"AI Broker (8085)","text":"<p>Purpose: The AI Broker service provides a unified interface to various AI models and handles AI-related tasks like PII redaction and RAG.</p> <p>Responsibilities: - Route requests to the optimal AI model (cost, speed, compliance). - Manage prompts and templates. - Perform Retrieval-Augmented Generation (RAG) using the RAG service. - Redact Personally Identifiable Information (PII) from prompts before sending them to AI models.</p> <p>Authentication: This service is internal to the platform and is called by the Gateway or other services.</p> <p>Sample endpoints: - <code>POST /api/ai/inference</code>: Generate an AI response. - <code>POST /api/ai/explain</code>: Explain a rule failure. - <code>POST /api/ai/generate-workflow</code>: Generate a WorkflowPack from natural language. - <code>GET /api/ai/models</code>: Get a list of available AI models.</p> <pre><code>flowchart LR\n    Gateway--&gt;AIBroker\n    AIBroker--&gt;RAG\n    AIBroker--&gt;ExternalAI[External AI Models]\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/compliance/","title":"Compliance (8135)","text":"<p>Purpose: The Compliance service is responsible for audit logging and compliance reporting.</p> <p>Responsibilities: - Maintain an immutable audit trail of all platform events. - Generate compliance reports for various regulatory frameworks (FISMA, FedRAMP, HIPAA). - Collect evidence for NIST 800-53 controls. - Enforce data retention policies.</p> <p>Authentication: This service is internal to the platform and is called by other services to log events.</p> <p>Sample endpoints: - <code>POST /log</code>: Log an event to the audit trail. - <code>GET /report</code>: Generate a compliance report.</p> <pre><code>flowchart LR\n    Workflow--&gt;Compliance\n    Gateway--&gt;Compliance\n    Compliance--&gt;Ledger\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/gateway/","title":"Gateway (8080)","text":"<p>Purpose: The Gateway service is the single entry point for all external traffic into the CORTX platform. It handles routing, rate limiting, and policy enforcement.</p> <p>Responsibilities: - Reverse proxy to all platform services. - Rate limiting (100 req/sec per tenant, burst 200). - Request authentication (JWT validation). - CORS handling. - Request/response logging. - Circuit breaker for downstream services.</p> <p>Authentication: All requests to the Gateway must include a valid JWT in the <code>Authorization</code> header.</p> <p>Sample endpoints: - <code>GET /health</code>: Health check - <code>POST /api/v1/rulepacks/execute</code>: Execute a RulePack - <code>POST /api/v1/workflows/execute</code>: Execute a WorkflowPack - <code>GET /api/v1/services</code>: Service discovery</p> <pre><code>flowchart LR\n    User--&gt;Gateway\n    Gateway--&gt;Identity\n    Gateway--&gt;Validation\n    Gateway--&gt;Workflow\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/identity/","title":"Identity (8082)","text":"<p>Purpose: The Identity service manages authentication, authorization, and user roles for the CORTX platform.</p> <p>Responsibilities: - OAuth 2.0 / OpenID Connect support. - Multi-factor authentication (MFA). - JWT token issuance (15min access, 7day refresh). - Role-Based Access Control (RBAC). - Tenant onboarding automation.</p> <p>Authentication: This service is internal to the platform and is called by the Gateway to validate JWTs and get user permissions.</p> <p>Sample endpoints: - <code>POST /oauth/token</code>: Issue a new JWT. - <code>GET /userinfo</code>: Get information about the current user. - <code>GET /roles</code>: Get a list of available roles.</p> <pre><code>flowchart LR\n    Gateway--&gt;Identity\n    Identity--&gt;DB[(PostgreSQL)]\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/ledger/","title":"Ledger (8136)","text":"<p>Purpose: The Ledger service provides a tamper-evident, append-only event log for compliance and audit purposes.</p> <p>Responsibilities: - Store events in a SHA-256 hash-chained ledger for immutability. - Provide an append-only API for adding new events. - Periodically verify the integrity of the ledger. - Allow for the export of ledger data for external audits.</p> <p>Authentication: This service is internal to the platform and is called by the Compliance service.</p> <p>Sample endpoints: - <code>POST /append</code>: Append a new event to the ledger. - <code>GET /verify</code>: Verify the integrity of the ledger. - <code>GET /events</code>: Get a list of events from the ledger.</p> <pre><code>flowchart LR\n    Compliance--&gt;Ledger\n    Ledger--&gt;DB[(Immutable Chain)]\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/ocr/","title":"OCR (8137)","text":"<p>Purpose: The OCR service extracts structured data and text from scanned documents and images.</p> <p>Responsibilities: - Support multiple OCR engines (Tesseract, Google DocAI). - Extract text and map document zones to schema fields. - Handle batch processing of large volumes of documents. - Provide confidence scores for extracted data. - Redact PII/PHI from the output if enabled.</p> <p>Authentication: This service is internal to the platform and is called by the Gateway or other services.</p> <p>Sample endpoints: - <code>POST /extract</code>: Extract text and data from a document. - <code>GET /results/{job_id}</code>: Get the results of an OCR job.</p> <pre><code>flowchart LR\n    Gateway--&gt;OCR\n    OCR--&gt;ExternalOCR[External OCR Engines]\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/rag/","title":"RAG (8138)","text":"<p>Purpose: The RAG (Retrieval-Augmented Generation) service provides contextual, compliance-aware knowledge retrieval for AI and UI workflows.</p> <p>Responsibilities: - Implement a 4-level hierarchical knowledge store (Platform, Suite, Module, Entity). - Index and embed documents for semantic search. - Provide a scoped search API to retrieve relevant knowledge. - Manage the RAG knowledge base through an admin UI.</p> <p>Authentication: This service is internal to the platform and is called by the AI Broker and other services.</p> <p>Sample endpoints: - <code>POST /query</code>: Query the knowledge base. - <code>POST /index</code>: Index a new document. - <code>GET /docs</code>: Get a list of documents in the knowledge base.</p> <pre><code>flowchart LR\n    AIBroker--&gt;RAG\n    RAG--&gt;DB[(PostgreSQL + pgvector)]\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"services/validation/","title":"Validation (8083)","text":"<p>Purpose: The Validation service is responsible for executing RulePacks and validating data against JSON schemas.</p> <p>Responsibilities: - Execute validation rules and compliance policies from RulePacks. - Use safe operators to prevent code injection. - Provide detailed error messages for validation failures. - Support batch processing of large datasets.</p> <p>Authentication: This service is internal to the platform and is called by the Gateway or other services.</p> <p>Sample endpoints: - <code>POST /validate</code>: Validate a data payload against a RulePack.</p> <pre><code>flowchart LR\n    Gateway--&gt;Validation\n    Workflow--&gt;Validation\n</code></pre> <p>OpenAPI: openapi.yaml JSON Schema Example: <code>templates/MODULE.schema.template.json</code></p>"},{"location":"services/workflow/","title":"Workflow (8130)","text":"<p>Purpose: The Workflow service orchestrates the execution of multi-step business processes defined in WorkflowPacks.</p> <p>Responsibilities: - Execute WorkflowPacks sequentially or in parallel. - Handle conditional branching and decision nodes. - Manage human-in-the-loop approval gates. - Implement the Saga pattern for distributed transactions with automatic compensation on failures.</p> <p>Authentication: This service is internal to the platform and is called by the Gateway.</p> <p>Sample endpoints: - <code>POST /execute</code>: Execute a WorkflowPack. - <code>GET /status/{workflow_id}</code>: Get the status of a running workflow.</p> <pre><code>flowchart LR\n    Gateway--&gt;Workflow\n    Workflow--&gt;Validation\n    Workflow--&gt;AIBroker\n    Workflow--&gt;Compliance\n</code></pre> <p>OpenAPI: openapi.yaml</p>"},{"location":"suites/","title":"Suites","text":"<p><code>docs/suites/index.md</code> ```md</p>"},{"location":"suites/#suites","title":"Suites","text":"<ul> <li>FedSuite: FedReconcile, FedTransform</li> <li>CorpSuite: PropVerify, Greenlight, InvestmAit</li> <li>MedSuite: ClaimsVerify, HIPAAAudit</li> <li>GovSuite: TBD All suites leverage centralized OCR, Ledger, RAG.</li> </ul>"}]}